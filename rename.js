// Generated by Haxe 4.3.4
(function ($global) { "use strict";
var $estr = function() { return js_Boot.__string_rec(this,''); },$hxEnums = $hxEnums || {},$_;
class EReg {
	constructor(r,opt) {
		this.r = new RegExp(r,opt.split("u").join(""));
	}
	match(s) {
		if(this.r.global) {
			this.r.lastIndex = 0;
		}
		this.r.m = this.r.exec(s);
		this.r.s = s;
		return this.r.m != null;
	}
	matched(n) {
		if(this.r.m != null && n >= 0 && n < this.r.m.length) {
			return this.r.m[n];
		} else {
			throw haxe_Exception.thrown("EReg::matched");
		}
	}
}
EReg.__name__ = true;
class HxOverrides {
	static cca(s,index) {
		let x = s.charCodeAt(index);
		if(x != x) {
			return undefined;
		}
		return x;
	}
	static substr(s,pos,len) {
		if(len == null) {
			len = s.length;
		} else if(len < 0) {
			if(pos == 0) {
				len = s.length + len;
			} else {
				return "";
			}
		}
		return s.substr(pos,len);
	}
	static remove(a,obj) {
		let i = a.indexOf(obj);
		if(i == -1) {
			return false;
		}
		a.splice(i,1);
		return true;
	}
	static now() {
		return Date.now();
	}
}
HxOverrides.__name__ = true;
class Lambda {
	static exists(it,f) {
		let x = $getIterator(it);
		while(x.hasNext()) {
			let x1 = x.next();
			if(f(x1)) {
				return true;
			}
		}
		return false;
	}
}
Lambda.__name__ = true;
Math.__name__ = true;
class RenameVersion {
}
RenameVersion.__name__ = true;
class Std {
	static string(s) {
		return js_Boot.__string_rec(s,"");
	}
	static parseInt(x) {
		let v = parseInt(x);
		if(isNaN(v)) {
			return null;
		}
		return v;
	}
}
Std.__name__ = true;
class StringBuf {
	constructor() {
		this.b = "";
	}
}
StringBuf.__name__ = true;
class StringTools {
	static isSpace(s,pos) {
		let c = HxOverrides.cca(s,pos);
		if(!(c > 8 && c < 14)) {
			return c == 32;
		} else {
			return true;
		}
	}
	static ltrim(s) {
		let l = s.length;
		let r = 0;
		while(r < l && StringTools.isSpace(s,r)) ++r;
		if(r > 0) {
			return HxOverrides.substr(s,r,l - r);
		} else {
			return s;
		}
	}
	static rtrim(s) {
		let l = s.length;
		let r = 0;
		while(r < l && StringTools.isSpace(s,l - r - 1)) ++r;
		if(r > 0) {
			return HxOverrides.substr(s,0,l - r);
		} else {
			return s;
		}
	}
	static trim(s) {
		return StringTools.ltrim(StringTools.rtrim(s));
	}
	static replace(s,sub,by) {
		return s.split(sub).join(by);
	}
}
StringTools.__name__ = true;
class haxe_io_Output {
	writeByte(c) {
		throw new haxe_exceptions_NotImplementedException(null,null,{ fileName : "haxe/io/Output.hx", lineNumber : 47, className : "haxe.io.Output", methodName : "writeByte"});
	}
	writeBytes(s,pos,len) {
		if(pos < 0 || len < 0 || pos + len > s.length) {
			throw haxe_Exception.thrown(haxe_io_Error.OutsideBounds);
		}
		let b = s.b;
		let k = len;
		while(k > 0) {
			this.writeByte(b[pos]);
			++pos;
			--k;
		}
		return len;
	}
	writeFullBytes(s,pos,len) {
		while(len > 0) {
			let k = this.writeBytes(s,pos,len);
			pos += k;
			len -= k;
		}
	}
	writeString(s,encoding) {
		let b = haxe_io_Bytes.ofString(s,encoding);
		this.writeFullBytes(b,0,b.length);
	}
}
haxe_io_Output.__name__ = true;
class _$Sys_FileOutput extends haxe_io_Output {
	constructor(fd) {
		super();
		this.fd = fd;
	}
	writeByte(c) {
		js_node_Fs.writeSync(this.fd,String.fromCodePoint(c));
	}
	writeBytes(s,pos,len) {
		let data = s.b;
		return js_node_Fs.writeSync(this.fd,js_node_buffer_Buffer.from(data.buffer,data.byteOffset,s.length),pos,len);
	}
	writeString(s,encoding) {
		js_node_Fs.writeSync(this.fd,s);
	}
	flush() {
		js_node_Fs.fsyncSync(this.fd);
	}
	close() {
		js_node_Fs.closeSync(this.fd);
	}
}
_$Sys_FileOutput.__name__ = true;
class haxe_io_Input {
}
haxe_io_Input.__name__ = true;
class _$Sys_FileInput extends haxe_io_Input {
	constructor(fd) {
		super();
		this.fd = fd;
	}
	readByte() {
		let buf = js_node_buffer_Buffer.alloc(1);
		try {
			js_node_Fs.readSync(this.fd,buf,0,1,null);
		} catch( _g ) {
			let e = haxe_Exception.caught(_g).unwrap();
			if(e.code == "EOF") {
				throw haxe_Exception.thrown(new haxe_io_Eof());
			} else {
				throw haxe_Exception.thrown(haxe_io_Error.Custom(e));
			}
		}
		return buf[0];
	}
	readBytes(s,pos,len) {
		let data = s.b;
		let buf = js_node_buffer_Buffer.from(data.buffer,data.byteOffset,s.length);
		try {
			return js_node_Fs.readSync(this.fd,buf,pos,len,null);
		} catch( _g ) {
			let e = haxe_Exception.caught(_g).unwrap();
			if(e.code == "EOF") {
				throw haxe_Exception.thrown(new haxe_io_Eof());
			} else {
				throw haxe_Exception.thrown(haxe_io_Error.Custom(e));
			}
		}
	}
	close() {
		js_node_Fs.closeSync(this.fd);
	}
}
_$Sys_FileInput.__name__ = true;
class Type {
	static enumEq(a,b) {
		if(a == b) {
			return true;
		}
		try {
			let e = a.__enum__;
			if(e == null || e != b.__enum__) {
				return false;
			}
			if(a._hx_index != b._hx_index) {
				return false;
			}
			let enm = $hxEnums[e];
			let params = enm.__constructs__[a._hx_index].__params__;
			let _g = 0;
			while(_g < params.length) {
				let f = params[_g];
				++_g;
				if(!Type.enumEq(a[f],b[f])) {
					return false;
				}
			}
		} catch( _g ) {
			return false;
		}
		return true;
	}
}
Type.__name__ = true;
class byte_ByteData {
	static get_length(this1) {
		return this1.length;
	}
	static readByte(this1,i) {
		return this1.b[i];
	}
	static _new(data) {
		return data;
	}
	static ofString(s) {
		return haxe_io_Bytes.ofString(s);
	}
	static ofBytes(b) {
		return b;
	}
	static readString(this1,pos,len) {
		return this1.getString(pos,len);
	}
}
var haxe_StackItem = $hxEnums["haxe.StackItem"] = { __ename__:true,__constructs__:null
	,CFunction: {_hx_name:"CFunction",_hx_index:0,__enum__:"haxe.StackItem",toString:$estr}
	,Module: ($_=function(m) { return {_hx_index:1,m:m,__enum__:"haxe.StackItem",toString:$estr}; },$_._hx_name="Module",$_.__params__ = ["m"],$_)
	,FilePos: ($_=function(s,file,line,column) { return {_hx_index:2,s:s,file:file,line:line,column:column,__enum__:"haxe.StackItem",toString:$estr}; },$_._hx_name="FilePos",$_.__params__ = ["s","file","line","column"],$_)
	,Method: ($_=function(classname,method) { return {_hx_index:3,classname:classname,method:method,__enum__:"haxe.StackItem",toString:$estr}; },$_._hx_name="Method",$_.__params__ = ["classname","method"],$_)
	,LocalFunction: ($_=function(v) { return {_hx_index:4,v:v,__enum__:"haxe.StackItem",toString:$estr}; },$_._hx_name="LocalFunction",$_.__params__ = ["v"],$_)
};
haxe_StackItem.__constructs__ = [haxe_StackItem.CFunction,haxe_StackItem.Module,haxe_StackItem.FilePos,haxe_StackItem.Method,haxe_StackItem.LocalFunction];
class haxe_CallStack {
	static toString(stack) {
		let b = new StringBuf();
		let _g = 0;
		let _g1 = stack;
		while(_g < _g1.length) {
			let s = _g1[_g];
			++_g;
			b.b += "\nCalled from ";
			haxe_CallStack.itemToString(b,s);
		}
		return b.b;
	}
	static subtract(this1,stack) {
		let startIndex = -1;
		let i = -1;
		while(++i < this1.length) {
			let _g = 0;
			let _g1 = stack.length;
			while(_g < _g1) {
				let j = _g++;
				if(haxe_CallStack.equalItems(this1[i],stack[j])) {
					if(startIndex < 0) {
						startIndex = i;
					}
					++i;
					if(i >= this1.length) {
						break;
					}
				} else {
					startIndex = -1;
				}
			}
			if(startIndex >= 0) {
				break;
			}
		}
		if(startIndex >= 0) {
			return this1.slice(0,startIndex);
		} else {
			return this1;
		}
	}
	static equalItems(item1,item2) {
		if(item1 == null) {
			if(item2 == null) {
				return true;
			} else {
				return false;
			}
		} else {
			switch(item1._hx_index) {
			case 0:
				if(item2 == null) {
					return false;
				} else if(item2._hx_index == 0) {
					return true;
				} else {
					return false;
				}
				break;
			case 1:
				if(item2 == null) {
					return false;
				} else if(item2._hx_index == 1) {
					let m2 = item2.m;
					let m1 = item1.m;
					return m1 == m2;
				} else {
					return false;
				}
				break;
			case 2:
				if(item2 == null) {
					return false;
				} else if(item2._hx_index == 2) {
					let item21 = item2.s;
					let file2 = item2.file;
					let line2 = item2.line;
					let col2 = item2.column;
					let col1 = item1.column;
					let line1 = item1.line;
					let file1 = item1.file;
					let item11 = item1.s;
					if(file1 == file2 && line1 == line2 && col1 == col2) {
						return haxe_CallStack.equalItems(item11,item21);
					} else {
						return false;
					}
				} else {
					return false;
				}
				break;
			case 3:
				if(item2 == null) {
					return false;
				} else if(item2._hx_index == 3) {
					let class2 = item2.classname;
					let method2 = item2.method;
					let method1 = item1.method;
					let class1 = item1.classname;
					if(class1 == class2) {
						return method1 == method2;
					} else {
						return false;
					}
				} else {
					return false;
				}
				break;
			case 4:
				if(item2 == null) {
					return false;
				} else if(item2._hx_index == 4) {
					let v2 = item2.v;
					let v1 = item1.v;
					return v1 == v2;
				} else {
					return false;
				}
				break;
			}
		}
	}
	static itemToString(b,s) {
		switch(s._hx_index) {
		case 0:
			b.b += "a C function";
			break;
		case 1:
			let m = s.m;
			b.b += "module ";
			b.b += m == null ? "null" : "" + m;
			break;
		case 2:
			let s1 = s.s;
			let file = s.file;
			let line = s.line;
			let col = s.column;
			if(s1 != null) {
				haxe_CallStack.itemToString(b,s1);
				b.b += " (";
			}
			b.b += file == null ? "null" : "" + file;
			b.b += " line ";
			b.b += line == null ? "null" : "" + line;
			if(col != null) {
				b.b += " column ";
				b.b += col == null ? "null" : "" + col;
			}
			if(s1 != null) {
				b.b += ")";
			}
			break;
		case 3:
			let cname = s.classname;
			let meth = s.method;
			b.b += Std.string(cname == null ? "<unknown>" : cname);
			b.b += ".";
			b.b += meth == null ? "null" : "" + meth;
			break;
		case 4:
			let n = s.v;
			b.b += "local function #";
			b.b += n == null ? "null" : "" + n;
			break;
		}
	}
}
class haxe_Exception extends Error {
	constructor(message,previous,native) {
		super(message);
		this.message = message;
		this.__previousException = previous;
		this.__nativeException = native != null ? native : this;
		this.__skipStack = 0;
		let old = Error.prepareStackTrace;
		Error.prepareStackTrace = function(e) { return e.stack; }
		if(((native) instanceof Error)) {
			this.stack = native.stack;
		} else {
			let e = null;
			if(Error.captureStackTrace) {
				Error.captureStackTrace(this,haxe_Exception);
				e = this;
			} else {
				e = new Error();
				if(typeof(e.stack) == "undefined") {
					try { throw e; } catch(_) {}
					this.__skipStack++;
				}
			}
			this.stack = e.stack;
		}
		Error.prepareStackTrace = old;
	}
	unwrap() {
		return this.__nativeException;
	}
	toString() {
		return this.get_message();
	}
	details() {
		if(this.get_previous() == null) {
			let tmp = "Exception: " + this.toString();
			let tmp1 = this.get_stack();
			return tmp + (tmp1 == null ? "null" : haxe_CallStack.toString(tmp1));
		} else {
			let result = "";
			let e = this;
			let prev = null;
			while(e != null) {
				if(prev == null) {
					let result1 = "Exception: " + e.get_message();
					let tmp = e.get_stack();
					result = result1 + (tmp == null ? "null" : haxe_CallStack.toString(tmp)) + result;
				} else {
					let prevStack = haxe_CallStack.subtract(e.get_stack(),prev.get_stack());
					result = "Exception: " + e.get_message() + (prevStack == null ? "null" : haxe_CallStack.toString(prevStack)) + "\n\nNext " + result;
				}
				prev = e;
				e = e.get_previous();
			}
			return result;
		}
	}
	__shiftStack() {
		this.__skipStack++;
	}
	get_message() {
		return this.message;
	}
	get_previous() {
		return this.__previousException;
	}
	get_native() {
		return this.__nativeException;
	}
	get_stack() {
		let _g = this.__exceptionStack;
		if(_g == null) {
			let value = haxe_NativeStackTrace.toHaxe(haxe_NativeStackTrace.normalize(this.stack),this.__skipStack);
			this.setProperty("__exceptionStack",value);
			return value;
		} else {
			let s = _g;
			return s;
		}
	}
	setProperty(name,value) {
		try {
			Object.defineProperty(this,name,{ value : value});
		} catch( _g ) {
			this[name] = value;
		}
	}
	static caught(value) {
		if(((value) instanceof haxe_Exception)) {
			return value;
		} else if(((value) instanceof Error)) {
			return new haxe_Exception(value.message,null,value);
		} else {
			return new haxe_ValueException(value,null,value);
		}
	}
	static thrown(value) {
		if(((value) instanceof haxe_Exception)) {
			return value.get_native();
		} else if(((value) instanceof Error)) {
			return value;
		} else {
			let e = new haxe_ValueException(value);
			e.__skipStack++;
			return e;
		}
	}
}
haxe_Exception.__name__ = true;
class haxe_NativeStackTrace {
	static toHaxe(s,skip) {
		if(skip == null) {
			skip = 0;
		}
		if(s == null) {
			return [];
		} else if(typeof(s) == "string") {
			let stack = s.split("\n");
			if(stack[0] == "Error") {
				stack.shift();
			}
			let m = [];
			let _g = 0;
			let _g1 = stack.length;
			while(_g < _g1) {
				let i = _g++;
				if(skip > i) {
					continue;
				}
				let line = stack[i];
				let matched = line.match(/^    at ([$A-Za-z0-9_. ]+) \(([^)]+):([0-9]+):([0-9]+)\)$/);
				if(matched != null) {
					let path = matched[1].split(".");
					if(path[0] == "$hxClasses") {
						path.shift();
					}
					let meth = path.pop();
					let file = matched[2];
					let line = Std.parseInt(matched[3]);
					let column = Std.parseInt(matched[4]);
					m.push(haxe_StackItem.FilePos(meth == "Anonymous function" ? haxe_StackItem.LocalFunction() : meth == "Global code" ? null : haxe_StackItem.Method(path.join("."),meth),file,line,column));
				} else {
					m.push(haxe_StackItem.Module(StringTools.trim(line)));
				}
			}
			return m;
		} else if(skip > 0 && Array.isArray(s)) {
			return s.slice(skip);
		} else {
			return s;
		}
	}
	static normalize(stack,skipItems) {
		if(skipItems == null) {
			skipItems = 0;
		}
		if(Array.isArray(stack) && skipItems > 0) {
			return stack.slice(skipItems);
		} else if(typeof(stack) == "string") {
			switch(stack.substring(0,6)) {
			case "Error\n":case "Error:":
				++skipItems;
				break;
			default:
			}
			return haxe_NativeStackTrace.skipLines(stack,skipItems);
		} else {
			return stack;
		}
	}
	static skipLines(stack,skip,pos) {
		if(pos == null) {
			pos = 0;
		}
		if(skip > 0) {
			pos = stack.indexOf("\n",pos);
			if(pos < 0) {
				return "";
			} else {
				return haxe_NativeStackTrace.skipLines(stack,--skip,pos + 1);
			}
		} else {
			return stack.substring(pos);
		}
	}
}
haxe_NativeStackTrace.__name__ = true;
class haxe_ValueException extends haxe_Exception {
	constructor(value,previous,native) {
		super(String(value),previous,native);
		this.value = value;
		this.__skipStack++;
	}
	unwrap() {
		return this.value;
	}
}
haxe_ValueException.__name__ = true;
class haxe_ds_List {
	constructor() {
		this.length = 0;
	}
	push(item) {
		let x = new haxe_ds__$List_ListNode(item,this.h);
		this.h = x;
		if(this.q == null) {
			this.q = x;
		}
		this.length++;
	}
	remove(v) {
		let prev = null;
		let l = this.h;
		while(l != null) {
			if(l.item == v) {
				if(prev == null) {
					this.h = l.next;
				} else {
					prev.next = l.next;
				}
				if(this.q == l) {
					this.q = prev;
				}
				this.length--;
				return true;
			}
			prev = l;
			l = l.next;
		}
		return false;
	}
}
haxe_ds_List.__name__ = true;
class haxe_ds__$List_ListNode {
	constructor(item,next) {
		this.item = item;
		this.next = next;
	}
}
haxe_ds__$List_ListNode.__name__ = true;
class haxe_ds_StringMap {
	constructor() {
		this.h = Object.create(null);
	}
}
haxe_ds_StringMap.__name__ = true;
class haxe_exceptions_PosException extends haxe_Exception {
	constructor(message,previous,pos) {
		super(message,previous);
		if(pos == null) {
			this.posInfos = { fileName : "(unknown)", lineNumber : 0, className : "(unknown)", methodName : "(unknown)"};
		} else {
			this.posInfos = pos;
		}
		this.__skipStack++;
	}
	toString() {
		return "" + super.toString() + " in " + this.posInfos.className + "." + this.posInfos.methodName + " at " + this.posInfos.fileName + ":" + this.posInfos.lineNumber;
	}
}
haxe_exceptions_PosException.__name__ = true;
class haxe_exceptions_NotImplementedException extends haxe_exceptions_PosException {
	constructor(message,previous,pos) {
		if(message == null) {
			message = "Not implemented";
		}
		super(message,previous,pos);
		this.__skipStack++;
	}
}
haxe_exceptions_NotImplementedException.__name__ = true;
class haxe_io_Bytes {
	constructor(data) {
		this.length = data.byteLength;
		this.b = new Uint8Array(data);
		this.b.bufferValue = data;
		data.hxBytes = this;
		data.bytes = this.b;
	}
	getString(pos,len,encoding) {
		if(pos < 0 || len < 0 || pos + len > this.length) {
			throw haxe_Exception.thrown(haxe_io_Error.OutsideBounds);
		}
		if(encoding == null) {
			encoding = haxe_io_Encoding.UTF8;
		}
		let s = "";
		let b = this.b;
		let i = pos;
		let max = pos + len;
		switch(encoding._hx_index) {
		case 0:
			let debug = pos > 0;
			while(i < max) {
				let c = b[i++];
				if(c < 128) {
					if(c == 0) {
						break;
					}
					s += String.fromCodePoint(c);
				} else if(c < 224) {
					let code = (c & 63) << 6 | b[i++] & 127;
					s += String.fromCodePoint(code);
				} else if(c < 240) {
					let c2 = b[i++];
					let code = (c & 31) << 12 | (c2 & 127) << 6 | b[i++] & 127;
					s += String.fromCodePoint(code);
				} else {
					let c2 = b[i++];
					let c3 = b[i++];
					let u = (c & 15) << 18 | (c2 & 127) << 12 | (c3 & 127) << 6 | b[i++] & 127;
					s += String.fromCodePoint(u);
				}
			}
			break;
		case 1:
			while(i < max) {
				let c = b[i++] | b[i++] << 8;
				s += String.fromCodePoint(c);
			}
			break;
		}
		return s;
	}
	toString() {
		return this.getString(0,this.length);
	}
	static ofString(s,encoding) {
		if(encoding == haxe_io_Encoding.RawNative) {
			let buf = new Uint8Array(s.length << 1);
			let _g = 0;
			let _g1 = s.length;
			while(_g < _g1) {
				let i = _g++;
				let c = s.charCodeAt(i);
				buf[i << 1] = c & 255;
				buf[i << 1 | 1] = c >> 8;
			}
			return new haxe_io_Bytes(buf.buffer);
		}
		let a = [];
		let i = 0;
		while(i < s.length) {
			let c = s.charCodeAt(i++);
			if(55296 <= c && c <= 56319) {
				c = c - 55232 << 10 | s.charCodeAt(i++) & 1023;
			}
			if(c <= 127) {
				a.push(c);
			} else if(c <= 2047) {
				a.push(192 | c >> 6);
				a.push(128 | c & 63);
			} else if(c <= 65535) {
				a.push(224 | c >> 12);
				a.push(128 | c >> 6 & 63);
				a.push(128 | c & 63);
			} else {
				a.push(240 | c >> 18);
				a.push(128 | c >> 12 & 63);
				a.push(128 | c >> 6 & 63);
				a.push(128 | c & 63);
			}
		}
		return new haxe_io_Bytes(new Uint8Array(a).buffer);
	}
}
haxe_io_Bytes.__name__ = true;
var haxe_io_Encoding = $hxEnums["haxe.io.Encoding"] = { __ename__:true,__constructs__:null
	,UTF8: {_hx_name:"UTF8",_hx_index:0,__enum__:"haxe.io.Encoding",toString:$estr}
	,RawNative: {_hx_name:"RawNative",_hx_index:1,__enum__:"haxe.io.Encoding",toString:$estr}
};
haxe_io_Encoding.__constructs__ = [haxe_io_Encoding.UTF8,haxe_io_Encoding.RawNative];
class haxe_io_Eof {
	constructor() {
	}
	toString() {
		return "Eof";
	}
}
haxe_io_Eof.__name__ = true;
var haxe_io_Error = $hxEnums["haxe.io.Error"] = { __ename__:true,__constructs__:null
	,Blocked: {_hx_name:"Blocked",_hx_index:0,__enum__:"haxe.io.Error",toString:$estr}
	,Overflow: {_hx_name:"Overflow",_hx_index:1,__enum__:"haxe.io.Error",toString:$estr}
	,OutsideBounds: {_hx_name:"OutsideBounds",_hx_index:2,__enum__:"haxe.io.Error",toString:$estr}
	,Custom: ($_=function(e) { return {_hx_index:3,e:e,__enum__:"haxe.io.Error",toString:$estr}; },$_._hx_name="Custom",$_.__params__ = ["e"],$_)
};
haxe_io_Error.__constructs__ = [haxe_io_Error.Blocked,haxe_io_Error.Overflow,haxe_io_Error.OutsideBounds,haxe_io_Error.Custom];
class haxe_io_Path {
	constructor(path) {
		switch(path) {
		case ".":case "..":
			this.dir = path;
			this.file = "";
			return;
		}
		let c1 = path.lastIndexOf("/");
		let c2 = path.lastIndexOf("\\");
		if(c1 < c2) {
			this.dir = HxOverrides.substr(path,0,c2);
			path = HxOverrides.substr(path,c2 + 1,null);
			this.backslash = true;
		} else if(c2 < c1) {
			this.dir = HxOverrides.substr(path,0,c1);
			path = HxOverrides.substr(path,c1 + 1,null);
		} else {
			this.dir = null;
		}
		let cp = path.lastIndexOf(".");
		if(cp != -1) {
			this.ext = HxOverrides.substr(path,cp + 1,null);
			this.file = HxOverrides.substr(path,0,cp);
		} else {
			this.ext = null;
			this.file = path;
		}
	}
	static directory(path) {
		let s = new haxe_io_Path(path);
		if(s.dir == null) {
			return "";
		}
		return s.dir;
	}
	static join(paths) {
		let _g = [];
		let _g1 = 0;
		let _g2 = paths;
		while(_g1 < _g2.length) {
			let v = _g2[_g1];
			++_g1;
			if(v != null && v != "") {
				_g.push(v);
			}
		}
		let paths1 = _g;
		if(paths1.length == 0) {
			return "";
		}
		let path = paths1[0];
		let _g3 = 1;
		let _g4 = paths1.length;
		while(_g3 < _g4) {
			let i = _g3++;
			path = haxe_io_Path.addTrailingSlash(path);
			path += paths1[i];
		}
		return haxe_io_Path.normalize(path);
	}
	static normalize(path) {
		let slash = "/";
		path = path.split("\\").join(slash);
		if(path == slash) {
			return slash;
		}
		let target = [];
		let _g = 0;
		let _g1 = path.split(slash);
		while(_g < _g1.length) {
			let token = _g1[_g];
			++_g;
			if(token == ".." && target.length > 0 && target[target.length - 1] != "..") {
				target.pop();
			} else if(token == "") {
				if(target.length > 0 || HxOverrides.cca(path,0) == 47) {
					target.push(token);
				}
			} else if(token != ".") {
				target.push(token);
			}
		}
		let tmp = target.join(slash);
		let acc_b = "";
		let colon = false;
		let slashes = false;
		let _g_offset = 0;
		let _g_s = tmp;
		while(_g_offset < _g_s.length) {
			let s = _g_s;
			let index = _g_offset++;
			let c = s.charCodeAt(index);
			if(c >= 55296 && c <= 56319) {
				c = c - 55232 << 10 | s.charCodeAt(index + 1) & 1023;
			}
			let c1 = c;
			if(c1 >= 65536) {
				++_g_offset;
			}
			let c2 = c1;
			switch(c2) {
			case 47:
				if(!colon) {
					slashes = true;
				} else {
					let i = c2;
					colon = false;
					if(slashes) {
						acc_b += "/";
						slashes = false;
					}
					acc_b += String.fromCodePoint(i);
				}
				break;
			case 58:
				acc_b += ":";
				colon = true;
				break;
			default:
				let i = c2;
				colon = false;
				if(slashes) {
					acc_b += "/";
					slashes = false;
				}
				acc_b += String.fromCodePoint(i);
			}
		}
		return acc_b;
	}
	static addTrailingSlash(path) {
		if(path.length == 0) {
			return "/";
		}
		let c1 = path.lastIndexOf("/");
		let c2 = path.lastIndexOf("\\");
		if(c1 < c2) {
			if(c2 != path.length - 1) {
				return path + "\\";
			} else {
				return path;
			}
		} else if(c1 != path.length - 1) {
			return path + "/";
		} else {
			return path;
		}
	}
	static removeTrailingSlashes(path) {
		_hx_loop1: while(true) {
			let _g = HxOverrides.cca(path,path.length - 1);
			if(_g == null) {
				break;
			} else {
				switch(_g) {
				case 47:case 92:
					path = HxOverrides.substr(path,0,-1);
					break;
				default:
					break _hx_loop1;
				}
			}
		}
		return path;
	}
}
haxe_io_Path.__name__ = true;
class haxe_iterators_ArrayIterator {
	constructor(array) {
		this.current = 0;
		this.array = array;
	}
	hasNext() {
		return this.current < this.array.length;
	}
	next() {
		return this.array[this.current++];
	}
}
haxe_iterators_ArrayIterator.__name__ = true;
var haxe_macro_StringLiteralKind = $hxEnums["haxe.macro.StringLiteralKind"] = { __ename__:true,__constructs__:null
	,DoubleQuotes: {_hx_name:"DoubleQuotes",_hx_index:0,__enum__:"haxe.macro.StringLiteralKind",toString:$estr}
	,SingleQuotes: {_hx_name:"SingleQuotes",_hx_index:1,__enum__:"haxe.macro.StringLiteralKind",toString:$estr}
};
haxe_macro_StringLiteralKind.__constructs__ = [haxe_macro_StringLiteralKind.DoubleQuotes,haxe_macro_StringLiteralKind.SingleQuotes];
var haxe_macro_Binop = $hxEnums["haxe.macro.Binop"] = { __ename__:true,__constructs__:null
	,OpAdd: {_hx_name:"OpAdd",_hx_index:0,__enum__:"haxe.macro.Binop",toString:$estr}
	,OpMult: {_hx_name:"OpMult",_hx_index:1,__enum__:"haxe.macro.Binop",toString:$estr}
	,OpDiv: {_hx_name:"OpDiv",_hx_index:2,__enum__:"haxe.macro.Binop",toString:$estr}
	,OpSub: {_hx_name:"OpSub",_hx_index:3,__enum__:"haxe.macro.Binop",toString:$estr}
	,OpAssign: {_hx_name:"OpAssign",_hx_index:4,__enum__:"haxe.macro.Binop",toString:$estr}
	,OpEq: {_hx_name:"OpEq",_hx_index:5,__enum__:"haxe.macro.Binop",toString:$estr}
	,OpNotEq: {_hx_name:"OpNotEq",_hx_index:6,__enum__:"haxe.macro.Binop",toString:$estr}
	,OpGt: {_hx_name:"OpGt",_hx_index:7,__enum__:"haxe.macro.Binop",toString:$estr}
	,OpGte: {_hx_name:"OpGte",_hx_index:8,__enum__:"haxe.macro.Binop",toString:$estr}
	,OpLt: {_hx_name:"OpLt",_hx_index:9,__enum__:"haxe.macro.Binop",toString:$estr}
	,OpLte: {_hx_name:"OpLte",_hx_index:10,__enum__:"haxe.macro.Binop",toString:$estr}
	,OpAnd: {_hx_name:"OpAnd",_hx_index:11,__enum__:"haxe.macro.Binop",toString:$estr}
	,OpOr: {_hx_name:"OpOr",_hx_index:12,__enum__:"haxe.macro.Binop",toString:$estr}
	,OpXor: {_hx_name:"OpXor",_hx_index:13,__enum__:"haxe.macro.Binop",toString:$estr}
	,OpBoolAnd: {_hx_name:"OpBoolAnd",_hx_index:14,__enum__:"haxe.macro.Binop",toString:$estr}
	,OpBoolOr: {_hx_name:"OpBoolOr",_hx_index:15,__enum__:"haxe.macro.Binop",toString:$estr}
	,OpShl: {_hx_name:"OpShl",_hx_index:16,__enum__:"haxe.macro.Binop",toString:$estr}
	,OpShr: {_hx_name:"OpShr",_hx_index:17,__enum__:"haxe.macro.Binop",toString:$estr}
	,OpUShr: {_hx_name:"OpUShr",_hx_index:18,__enum__:"haxe.macro.Binop",toString:$estr}
	,OpMod: {_hx_name:"OpMod",_hx_index:19,__enum__:"haxe.macro.Binop",toString:$estr}
	,OpAssignOp: ($_=function(op) { return {_hx_index:20,op:op,__enum__:"haxe.macro.Binop",toString:$estr}; },$_._hx_name="OpAssignOp",$_.__params__ = ["op"],$_)
	,OpInterval: {_hx_name:"OpInterval",_hx_index:21,__enum__:"haxe.macro.Binop",toString:$estr}
	,OpArrow: {_hx_name:"OpArrow",_hx_index:22,__enum__:"haxe.macro.Binop",toString:$estr}
	,OpIn: {_hx_name:"OpIn",_hx_index:23,__enum__:"haxe.macro.Binop",toString:$estr}
	,OpNullCoal: {_hx_name:"OpNullCoal",_hx_index:24,__enum__:"haxe.macro.Binop",toString:$estr}
};
haxe_macro_Binop.__constructs__ = [haxe_macro_Binop.OpAdd,haxe_macro_Binop.OpMult,haxe_macro_Binop.OpDiv,haxe_macro_Binop.OpSub,haxe_macro_Binop.OpAssign,haxe_macro_Binop.OpEq,haxe_macro_Binop.OpNotEq,haxe_macro_Binop.OpGt,haxe_macro_Binop.OpGte,haxe_macro_Binop.OpLt,haxe_macro_Binop.OpLte,haxe_macro_Binop.OpAnd,haxe_macro_Binop.OpOr,haxe_macro_Binop.OpXor,haxe_macro_Binop.OpBoolAnd,haxe_macro_Binop.OpBoolOr,haxe_macro_Binop.OpShl,haxe_macro_Binop.OpShr,haxe_macro_Binop.OpUShr,haxe_macro_Binop.OpMod,haxe_macro_Binop.OpAssignOp,haxe_macro_Binop.OpInterval,haxe_macro_Binop.OpArrow,haxe_macro_Binop.OpIn,haxe_macro_Binop.OpNullCoal];
var haxe_macro_Unop = $hxEnums["haxe.macro.Unop"] = { __ename__:true,__constructs__:null
	,OpIncrement: {_hx_name:"OpIncrement",_hx_index:0,__enum__:"haxe.macro.Unop",toString:$estr}
	,OpDecrement: {_hx_name:"OpDecrement",_hx_index:1,__enum__:"haxe.macro.Unop",toString:$estr}
	,OpNot: {_hx_name:"OpNot",_hx_index:2,__enum__:"haxe.macro.Unop",toString:$estr}
	,OpNeg: {_hx_name:"OpNeg",_hx_index:3,__enum__:"haxe.macro.Unop",toString:$estr}
	,OpNegBits: {_hx_name:"OpNegBits",_hx_index:4,__enum__:"haxe.macro.Unop",toString:$estr}
	,OpSpread: {_hx_name:"OpSpread",_hx_index:5,__enum__:"haxe.macro.Unop",toString:$estr}
};
haxe_macro_Unop.__constructs__ = [haxe_macro_Unop.OpIncrement,haxe_macro_Unop.OpDecrement,haxe_macro_Unop.OpNot,haxe_macro_Unop.OpNeg,haxe_macro_Unop.OpNegBits,haxe_macro_Unop.OpSpread];
var haxe_macro_ComplexType = $hxEnums["haxe.macro.ComplexType"] = { __ename__:true,__constructs__:null
	,TPath: ($_=function(p) { return {_hx_index:0,p:p,__enum__:"haxe.macro.ComplexType",toString:$estr}; },$_._hx_name="TPath",$_.__params__ = ["p"],$_)
	,TFunction: ($_=function(args,ret) { return {_hx_index:1,args:args,ret:ret,__enum__:"haxe.macro.ComplexType",toString:$estr}; },$_._hx_name="TFunction",$_.__params__ = ["args","ret"],$_)
	,TAnonymous: ($_=function(fields) { return {_hx_index:2,fields:fields,__enum__:"haxe.macro.ComplexType",toString:$estr}; },$_._hx_name="TAnonymous",$_.__params__ = ["fields"],$_)
	,TParent: ($_=function(t) { return {_hx_index:3,t:t,__enum__:"haxe.macro.ComplexType",toString:$estr}; },$_._hx_name="TParent",$_.__params__ = ["t"],$_)
	,TExtend: ($_=function(p,fields) { return {_hx_index:4,p:p,fields:fields,__enum__:"haxe.macro.ComplexType",toString:$estr}; },$_._hx_name="TExtend",$_.__params__ = ["p","fields"],$_)
	,TOptional: ($_=function(t) { return {_hx_index:5,t:t,__enum__:"haxe.macro.ComplexType",toString:$estr}; },$_._hx_name="TOptional",$_.__params__ = ["t"],$_)
	,TNamed: ($_=function(n,t) { return {_hx_index:6,n:n,t:t,__enum__:"haxe.macro.ComplexType",toString:$estr}; },$_._hx_name="TNamed",$_.__params__ = ["n","t"],$_)
	,TIntersection: ($_=function(tl) { return {_hx_index:7,tl:tl,__enum__:"haxe.macro.ComplexType",toString:$estr}; },$_._hx_name="TIntersection",$_.__params__ = ["tl"],$_)
};
haxe_macro_ComplexType.__constructs__ = [haxe_macro_ComplexType.TPath,haxe_macro_ComplexType.TFunction,haxe_macro_ComplexType.TAnonymous,haxe_macro_ComplexType.TParent,haxe_macro_ComplexType.TExtend,haxe_macro_ComplexType.TOptional,haxe_macro_ComplexType.TNamed,haxe_macro_ComplexType.TIntersection];
class haxe_macro_Printer {
	constructor(tabString) {
		if(tabString == null) {
			tabString = "\t";
		}
		this.tabs = "";
		this.tabString = tabString;
	}
	printUnop(op) {
		switch(op._hx_index) {
		case 0:
			return "++";
		case 1:
			return "--";
		case 2:
			return "!";
		case 3:
			return "-";
		case 4:
			return "~";
		case 5:
			return "...";
		}
	}
	printBinop(op) {
		switch(op._hx_index) {
		case 0:
			return "+";
		case 1:
			return "*";
		case 2:
			return "/";
		case 3:
			return "-";
		case 4:
			return "=";
		case 5:
			return "==";
		case 6:
			return "!=";
		case 7:
			return ">";
		case 8:
			return ">=";
		case 9:
			return "<";
		case 10:
			return "<=";
		case 11:
			return "&";
		case 12:
			return "|";
		case 13:
			return "^";
		case 14:
			return "&&";
		case 15:
			return "||";
		case 16:
			return "<<";
		case 17:
			return ">>";
		case 18:
			return ">>>";
		case 19:
			return "%";
		case 20:
			let op1 = op.op;
			return this.printBinop(op1) + "=";
		case 21:
			return "...";
		case 22:
			return "=>";
		case 23:
			return "in";
		case 24:
			return "??";
		}
	}
}
haxe_macro_Printer.__name__ = true;
var haxeparser_Keyword = $hxEnums["haxeparser.Keyword"] = { __ename__:true,__constructs__:null
	,KwdFunction: {_hx_name:"KwdFunction",_hx_index:0,__enum__:"haxeparser.Keyword",toString:$estr}
	,KwdClass: {_hx_name:"KwdClass",_hx_index:1,__enum__:"haxeparser.Keyword",toString:$estr}
	,KwdVar: {_hx_name:"KwdVar",_hx_index:2,__enum__:"haxeparser.Keyword",toString:$estr}
	,KwdIf: {_hx_name:"KwdIf",_hx_index:3,__enum__:"haxeparser.Keyword",toString:$estr}
	,KwdElse: {_hx_name:"KwdElse",_hx_index:4,__enum__:"haxeparser.Keyword",toString:$estr}
	,KwdWhile: {_hx_name:"KwdWhile",_hx_index:5,__enum__:"haxeparser.Keyword",toString:$estr}
	,KwdDo: {_hx_name:"KwdDo",_hx_index:6,__enum__:"haxeparser.Keyword",toString:$estr}
	,KwdFor: {_hx_name:"KwdFor",_hx_index:7,__enum__:"haxeparser.Keyword",toString:$estr}
	,KwdBreak: {_hx_name:"KwdBreak",_hx_index:8,__enum__:"haxeparser.Keyword",toString:$estr}
	,KwdContinue: {_hx_name:"KwdContinue",_hx_index:9,__enum__:"haxeparser.Keyword",toString:$estr}
	,KwdReturn: {_hx_name:"KwdReturn",_hx_index:10,__enum__:"haxeparser.Keyword",toString:$estr}
	,KwdExtends: {_hx_name:"KwdExtends",_hx_index:11,__enum__:"haxeparser.Keyword",toString:$estr}
	,KwdImplements: {_hx_name:"KwdImplements",_hx_index:12,__enum__:"haxeparser.Keyword",toString:$estr}
	,KwdImport: {_hx_name:"KwdImport",_hx_index:13,__enum__:"haxeparser.Keyword",toString:$estr}
	,KwdSwitch: {_hx_name:"KwdSwitch",_hx_index:14,__enum__:"haxeparser.Keyword",toString:$estr}
	,KwdCase: {_hx_name:"KwdCase",_hx_index:15,__enum__:"haxeparser.Keyword",toString:$estr}
	,KwdDefault: {_hx_name:"KwdDefault",_hx_index:16,__enum__:"haxeparser.Keyword",toString:$estr}
	,KwdStatic: {_hx_name:"KwdStatic",_hx_index:17,__enum__:"haxeparser.Keyword",toString:$estr}
	,KwdPublic: {_hx_name:"KwdPublic",_hx_index:18,__enum__:"haxeparser.Keyword",toString:$estr}
	,KwdPrivate: {_hx_name:"KwdPrivate",_hx_index:19,__enum__:"haxeparser.Keyword",toString:$estr}
	,KwdTry: {_hx_name:"KwdTry",_hx_index:20,__enum__:"haxeparser.Keyword",toString:$estr}
	,KwdCatch: {_hx_name:"KwdCatch",_hx_index:21,__enum__:"haxeparser.Keyword",toString:$estr}
	,KwdNew: {_hx_name:"KwdNew",_hx_index:22,__enum__:"haxeparser.Keyword",toString:$estr}
	,KwdThis: {_hx_name:"KwdThis",_hx_index:23,__enum__:"haxeparser.Keyword",toString:$estr}
	,KwdThrow: {_hx_name:"KwdThrow",_hx_index:24,__enum__:"haxeparser.Keyword",toString:$estr}
	,KwdExtern: {_hx_name:"KwdExtern",_hx_index:25,__enum__:"haxeparser.Keyword",toString:$estr}
	,KwdEnum: {_hx_name:"KwdEnum",_hx_index:26,__enum__:"haxeparser.Keyword",toString:$estr}
	,KwdIn: {_hx_name:"KwdIn",_hx_index:27,__enum__:"haxeparser.Keyword",toString:$estr}
	,KwdInterface: {_hx_name:"KwdInterface",_hx_index:28,__enum__:"haxeparser.Keyword",toString:$estr}
	,KwdUntyped: {_hx_name:"KwdUntyped",_hx_index:29,__enum__:"haxeparser.Keyword",toString:$estr}
	,KwdCast: {_hx_name:"KwdCast",_hx_index:30,__enum__:"haxeparser.Keyword",toString:$estr}
	,KwdOverride: {_hx_name:"KwdOverride",_hx_index:31,__enum__:"haxeparser.Keyword",toString:$estr}
	,KwdTypedef: {_hx_name:"KwdTypedef",_hx_index:32,__enum__:"haxeparser.Keyword",toString:$estr}
	,KwdDynamic: {_hx_name:"KwdDynamic",_hx_index:33,__enum__:"haxeparser.Keyword",toString:$estr}
	,KwdPackage: {_hx_name:"KwdPackage",_hx_index:34,__enum__:"haxeparser.Keyword",toString:$estr}
	,KwdInline: {_hx_name:"KwdInline",_hx_index:35,__enum__:"haxeparser.Keyword",toString:$estr}
	,KwdUsing: {_hx_name:"KwdUsing",_hx_index:36,__enum__:"haxeparser.Keyword",toString:$estr}
	,KwdNull: {_hx_name:"KwdNull",_hx_index:37,__enum__:"haxeparser.Keyword",toString:$estr}
	,KwdTrue: {_hx_name:"KwdTrue",_hx_index:38,__enum__:"haxeparser.Keyword",toString:$estr}
	,KwdFalse: {_hx_name:"KwdFalse",_hx_index:39,__enum__:"haxeparser.Keyword",toString:$estr}
	,KwdAbstract: {_hx_name:"KwdAbstract",_hx_index:40,__enum__:"haxeparser.Keyword",toString:$estr}
	,KwdMacro: {_hx_name:"KwdMacro",_hx_index:41,__enum__:"haxeparser.Keyword",toString:$estr}
	,KwdFinal: {_hx_name:"KwdFinal",_hx_index:42,__enum__:"haxeparser.Keyword",toString:$estr}
	,KwdOperator: {_hx_name:"KwdOperator",_hx_index:43,__enum__:"haxeparser.Keyword",toString:$estr}
	,KwdOverload: {_hx_name:"KwdOverload",_hx_index:44,__enum__:"haxeparser.Keyword",toString:$estr}
};
haxeparser_Keyword.__constructs__ = [haxeparser_Keyword.KwdFunction,haxeparser_Keyword.KwdClass,haxeparser_Keyword.KwdVar,haxeparser_Keyword.KwdIf,haxeparser_Keyword.KwdElse,haxeparser_Keyword.KwdWhile,haxeparser_Keyword.KwdDo,haxeparser_Keyword.KwdFor,haxeparser_Keyword.KwdBreak,haxeparser_Keyword.KwdContinue,haxeparser_Keyword.KwdReturn,haxeparser_Keyword.KwdExtends,haxeparser_Keyword.KwdImplements,haxeparser_Keyword.KwdImport,haxeparser_Keyword.KwdSwitch,haxeparser_Keyword.KwdCase,haxeparser_Keyword.KwdDefault,haxeparser_Keyword.KwdStatic,haxeparser_Keyword.KwdPublic,haxeparser_Keyword.KwdPrivate,haxeparser_Keyword.KwdTry,haxeparser_Keyword.KwdCatch,haxeparser_Keyword.KwdNew,haxeparser_Keyword.KwdThis,haxeparser_Keyword.KwdThrow,haxeparser_Keyword.KwdExtern,haxeparser_Keyword.KwdEnum,haxeparser_Keyword.KwdIn,haxeparser_Keyword.KwdInterface,haxeparser_Keyword.KwdUntyped,haxeparser_Keyword.KwdCast,haxeparser_Keyword.KwdOverride,haxeparser_Keyword.KwdTypedef,haxeparser_Keyword.KwdDynamic,haxeparser_Keyword.KwdPackage,haxeparser_Keyword.KwdInline,haxeparser_Keyword.KwdUsing,haxeparser_Keyword.KwdNull,haxeparser_Keyword.KwdTrue,haxeparser_Keyword.KwdFalse,haxeparser_Keyword.KwdAbstract,haxeparser_Keyword.KwdMacro,haxeparser_Keyword.KwdFinal,haxeparser_Keyword.KwdOperator,haxeparser_Keyword.KwdOverload];
class haxeparser_KeywordPrinter {
	static toString(kwd) {
		switch(kwd._hx_index) {
		case 0:
			return "function";
		case 1:
			return "class";
		case 2:
			return "var";
		case 3:
			return "if";
		case 4:
			return "else";
		case 5:
			return "while";
		case 6:
			return "do";
		case 7:
			return "for";
		case 8:
			return "break";
		case 9:
			return "continue";
		case 10:
			return "return";
		case 11:
			return "extends";
		case 12:
			return "implements";
		case 13:
			return "import";
		case 14:
			return "switch";
		case 15:
			return "case";
		case 16:
			return "default";
		case 17:
			return "static";
		case 18:
			return "public";
		case 19:
			return "private";
		case 20:
			return "try";
		case 21:
			return "catch";
		case 22:
			return "new";
		case 23:
			return "this";
		case 24:
			return "throw";
		case 25:
			return "extern";
		case 26:
			return "enum";
		case 27:
			return "in";
		case 28:
			return "interface";
		case 29:
			return "untyped";
		case 30:
			return "cast";
		case 31:
			return "override";
		case 32:
			return "typedef";
		case 33:
			return "dynamic";
		case 34:
			return "package";
		case 35:
			return "inline";
		case 36:
			return "using";
		case 37:
			return "null";
		case 38:
			return "true";
		case 39:
			return "false";
		case 40:
			return "abstract";
		case 41:
			return "macro";
		case 42:
			return "final";
		case 43:
			return "operator";
		case 44:
			return "overload";
		}
	}
}
haxeparser_KeywordPrinter.__name__ = true;
var haxeparser_TokenDef = $hxEnums["haxeparser.TokenDef"] = { __ename__:true,__constructs__:null
	,Eof: {_hx_name:"Eof",_hx_index:0,__enum__:"haxeparser.TokenDef",toString:$estr}
	,Const: ($_=function(c) { return {_hx_index:1,c:c,__enum__:"haxeparser.TokenDef",toString:$estr}; },$_._hx_name="Const",$_.__params__ = ["c"],$_)
	,Kwd: ($_=function(k) { return {_hx_index:2,k:k,__enum__:"haxeparser.TokenDef",toString:$estr}; },$_._hx_name="Kwd",$_.__params__ = ["k"],$_)
	,Comment: ($_=function(s) { return {_hx_index:3,s:s,__enum__:"haxeparser.TokenDef",toString:$estr}; },$_._hx_name="Comment",$_.__params__ = ["s"],$_)
	,CommentLine: ($_=function(s) { return {_hx_index:4,s:s,__enum__:"haxeparser.TokenDef",toString:$estr}; },$_._hx_name="CommentLine",$_.__params__ = ["s"],$_)
	,Binop: ($_=function(op) { return {_hx_index:5,op:op,__enum__:"haxeparser.TokenDef",toString:$estr}; },$_._hx_name="Binop",$_.__params__ = ["op"],$_)
	,Unop: ($_=function(op) { return {_hx_index:6,op:op,__enum__:"haxeparser.TokenDef",toString:$estr}; },$_._hx_name="Unop",$_.__params__ = ["op"],$_)
	,Semicolon: {_hx_name:"Semicolon",_hx_index:7,__enum__:"haxeparser.TokenDef",toString:$estr}
	,Comma: {_hx_name:"Comma",_hx_index:8,__enum__:"haxeparser.TokenDef",toString:$estr}
	,BrOpen: {_hx_name:"BrOpen",_hx_index:9,__enum__:"haxeparser.TokenDef",toString:$estr}
	,BrClose: {_hx_name:"BrClose",_hx_index:10,__enum__:"haxeparser.TokenDef",toString:$estr}
	,BkOpen: {_hx_name:"BkOpen",_hx_index:11,__enum__:"haxeparser.TokenDef",toString:$estr}
	,BkClose: {_hx_name:"BkClose",_hx_index:12,__enum__:"haxeparser.TokenDef",toString:$estr}
	,POpen: {_hx_name:"POpen",_hx_index:13,__enum__:"haxeparser.TokenDef",toString:$estr}
	,PClose: {_hx_name:"PClose",_hx_index:14,__enum__:"haxeparser.TokenDef",toString:$estr}
	,Dot: {_hx_name:"Dot",_hx_index:15,__enum__:"haxeparser.TokenDef",toString:$estr}
	,DblDot: {_hx_name:"DblDot",_hx_index:16,__enum__:"haxeparser.TokenDef",toString:$estr}
	,QuestionDot: {_hx_name:"QuestionDot",_hx_index:17,__enum__:"haxeparser.TokenDef",toString:$estr}
	,Arrow: {_hx_name:"Arrow",_hx_index:18,__enum__:"haxeparser.TokenDef",toString:$estr}
	,IntInterval: ($_=function(s) { return {_hx_index:19,s:s,__enum__:"haxeparser.TokenDef",toString:$estr}; },$_._hx_name="IntInterval",$_.__params__ = ["s"],$_)
	,Sharp: ($_=function(s) { return {_hx_index:20,s:s,__enum__:"haxeparser.TokenDef",toString:$estr}; },$_._hx_name="Sharp",$_.__params__ = ["s"],$_)
	,Question: {_hx_name:"Question",_hx_index:21,__enum__:"haxeparser.TokenDef",toString:$estr}
	,At: {_hx_name:"At",_hx_index:22,__enum__:"haxeparser.TokenDef",toString:$estr}
	,Dollar: ($_=function(s) { return {_hx_index:23,s:s,__enum__:"haxeparser.TokenDef",toString:$estr}; },$_._hx_name="Dollar",$_.__params__ = ["s"],$_)
	,Spread: {_hx_name:"Spread",_hx_index:24,__enum__:"haxeparser.TokenDef",toString:$estr}
};
haxeparser_TokenDef.__constructs__ = [haxeparser_TokenDef.Eof,haxeparser_TokenDef.Const,haxeparser_TokenDef.Kwd,haxeparser_TokenDef.Comment,haxeparser_TokenDef.CommentLine,haxeparser_TokenDef.Binop,haxeparser_TokenDef.Unop,haxeparser_TokenDef.Semicolon,haxeparser_TokenDef.Comma,haxeparser_TokenDef.BrOpen,haxeparser_TokenDef.BrClose,haxeparser_TokenDef.BkOpen,haxeparser_TokenDef.BkClose,haxeparser_TokenDef.POpen,haxeparser_TokenDef.PClose,haxeparser_TokenDef.Dot,haxeparser_TokenDef.DblDot,haxeparser_TokenDef.QuestionDot,haxeparser_TokenDef.Arrow,haxeparser_TokenDef.IntInterval,haxeparser_TokenDef.Sharp,haxeparser_TokenDef.Question,haxeparser_TokenDef.At,haxeparser_TokenDef.Dollar,haxeparser_TokenDef.Spread];
var haxeparser_Constant = $hxEnums["haxeparser.Constant"] = { __ename__:true,__constructs__:null
	,CInt: ($_=function(v,s) { return {_hx_index:0,v:v,s:s,__enum__:"haxeparser.Constant",toString:$estr}; },$_._hx_name="CInt",$_.__params__ = ["v","s"],$_)
	,CFloat: ($_=function(f,s) { return {_hx_index:1,f:f,s:s,__enum__:"haxeparser.Constant",toString:$estr}; },$_._hx_name="CFloat",$_.__params__ = ["f","s"],$_)
	,CString: ($_=function(s,kind) { return {_hx_index:2,s:s,kind:kind,__enum__:"haxeparser.Constant",toString:$estr}; },$_._hx_name="CString",$_.__params__ = ["s","kind"],$_)
	,CIdent: ($_=function(s) { return {_hx_index:3,s:s,__enum__:"haxeparser.Constant",toString:$estr}; },$_._hx_name="CIdent",$_.__params__ = ["s"],$_)
	,CRegexp: ($_=function(r,opt) { return {_hx_index:4,r:r,opt:opt,__enum__:"haxeparser.Constant",toString:$estr}; },$_._hx_name="CRegexp",$_.__params__ = ["r","opt"],$_)
	,CMarkup: ($_=function(s) { return {_hx_index:5,s:s,__enum__:"haxeparser.Constant",toString:$estr}; },$_._hx_name="CMarkup",$_.__params__ = ["s"],$_)
};
haxeparser_Constant.__constructs__ = [haxeparser_Constant.CInt,haxeparser_Constant.CFloat,haxeparser_Constant.CString,haxeparser_Constant.CIdent,haxeparser_Constant.CRegexp,haxeparser_Constant.CMarkup];
class haxeparser_TokenDefPrinter {
	static toString(def) {
		switch(def._hx_index) {
		case 0:
			return "<eof>";
		case 1:
			let $const = def.c;
			return haxeparser_TokenDefPrinter.constToString($const);
		case 2:
			let k = def.k;
			return HxOverrides.substr($hxEnums[k.__enum__].__constructs__[k._hx_index]._hx_name,3,null).toLowerCase();
		case 3:
			let s = def.s;
			return "/*" + s + "*/";
		case 4:
			let s1 = def.s;
			return "//" + s1;
		case 5:
			let op = def.op;
			return new haxe_macro_Printer("").printBinop(op);
		case 6:
			let op1 = def.op;
			return new haxe_macro_Printer("").printUnop(op1);
		case 7:
			return ";";
		case 8:
			return ",";
		case 9:
			return "{";
		case 10:
			return "}";
		case 11:
			return "[";
		case 12:
			return "]";
		case 13:
			return "(";
		case 14:
			return ")";
		case 15:
			return ".";
		case 16:
			return ":";
		case 17:
			return "?.";
		case 18:
			return "->";
		case 19:
			let s2 = def.s;
			return "" + s2 + "...";
		case 20:
			let s3 = def.s;
			return "#" + s3;
		case 21:
			return "?";
		case 22:
			return "@";
		case 23:
			let s4 = def.s;
			return "$" + s4;
		case 24:
			return "...";
		}
	}
	static constToString($const) {
		switch($const._hx_index) {
		case 0:
			let _g = $const.v;
			let _g1 = $const.s;
			if(_g1 == null) {
				let v = _g;
				return v;
			} else {
				let s = _g1;
				let v = _g;
				return "" + v + s;
			}
			break;
		case 1:
			let _g2 = $const.f;
			let _g3 = $const.s;
			if(_g3 == null) {
				let f = _g2;
				return f;
			} else {
				let s = _g3;
				let f = _g2;
				return "" + f + s;
			}
			break;
		case 2:
			let s = $const.s;
			let kind = $const.kind;
			if(kind == null) {
				return "\"" + s + "\"";
			} else {
				switch(kind._hx_index) {
				case 0:
					return "\"" + s + "\"";
				case 1:
					return "'" + s + "'";
				}
			}
			break;
		case 3:
			let s1 = $const.s;
			return s1;
		case 4:
			let r = $const.r;
			let opt = $const.opt;
			return "~/" + r + "/" + opt;
		case 5:
			let s2 = $const.s;
			return s2;
		}
	}
	static print(def) {
		return haxeparser_TokenDefPrinter.toString(def);
	}
}
haxeparser_TokenDefPrinter.__name__ = true;
class haxeparser_Token {
	constructor(tok,pos) {
		this.tok = tok;
		this.pos = pos;
	}
	toString() {
		return haxeparser_TokenDefPrinter.toString(this.tok);
	}
}
haxeparser_Token.__name__ = true;
var haxeparser_TypeDef = $hxEnums["haxeparser.TypeDef"] = { __ename__:true,__constructs__:null
	,EClass: ($_=function(d) { return {_hx_index:0,d:d,__enum__:"haxeparser.TypeDef",toString:$estr}; },$_._hx_name="EClass",$_.__params__ = ["d"],$_)
	,EEnum: ($_=function(d) { return {_hx_index:1,d:d,__enum__:"haxeparser.TypeDef",toString:$estr}; },$_._hx_name="EEnum",$_.__params__ = ["d"],$_)
	,ETypedef: ($_=function(d) { return {_hx_index:2,d:d,__enum__:"haxeparser.TypeDef",toString:$estr}; },$_._hx_name="ETypedef",$_.__params__ = ["d"],$_)
	,EAbstract: ($_=function(a) { return {_hx_index:3,a:a,__enum__:"haxeparser.TypeDef",toString:$estr}; },$_._hx_name="EAbstract",$_.__params__ = ["a"],$_)
	,EStatic: ($_=function(s) { return {_hx_index:4,s:s,__enum__:"haxeparser.TypeDef",toString:$estr}; },$_._hx_name="EStatic",$_.__params__ = ["s"],$_)
	,EImport: ($_=function(sl,mode) { return {_hx_index:5,sl:sl,mode:mode,__enum__:"haxeparser.TypeDef",toString:$estr}; },$_._hx_name="EImport",$_.__params__ = ["sl","mode"],$_)
	,EUsing: ($_=function(path) { return {_hx_index:6,path:path,__enum__:"haxeparser.TypeDef",toString:$estr}; },$_._hx_name="EUsing",$_.__params__ = ["path"],$_)
};
haxeparser_TypeDef.__constructs__ = [haxeparser_TypeDef.EClass,haxeparser_TypeDef.EEnum,haxeparser_TypeDef.ETypedef,haxeparser_TypeDef.EAbstract,haxeparser_TypeDef.EStatic,haxeparser_TypeDef.EImport,haxeparser_TypeDef.EUsing];
var haxeparser_ClassFlag = $hxEnums["haxeparser.ClassFlag"] = { __ename__:true,__constructs__:null
	,HInterface: {_hx_name:"HInterface",_hx_index:0,__enum__:"haxeparser.ClassFlag",toString:$estr}
	,HExtern: {_hx_name:"HExtern",_hx_index:1,__enum__:"haxeparser.ClassFlag",toString:$estr}
	,HPrivate: {_hx_name:"HPrivate",_hx_index:2,__enum__:"haxeparser.ClassFlag",toString:$estr}
	,HExtends: ($_=function(t) { return {_hx_index:3,t:t,__enum__:"haxeparser.ClassFlag",toString:$estr}; },$_._hx_name="HExtends",$_.__params__ = ["t"],$_)
	,HImplements: ($_=function(t) { return {_hx_index:4,t:t,__enum__:"haxeparser.ClassFlag",toString:$estr}; },$_._hx_name="HImplements",$_.__params__ = ["t"],$_)
	,HFinal: {_hx_name:"HFinal",_hx_index:5,__enum__:"haxeparser.ClassFlag",toString:$estr}
	,HAbstract: {_hx_name:"HAbstract",_hx_index:6,__enum__:"haxeparser.ClassFlag",toString:$estr}
};
haxeparser_ClassFlag.__constructs__ = [haxeparser_ClassFlag.HInterface,haxeparser_ClassFlag.HExtern,haxeparser_ClassFlag.HPrivate,haxeparser_ClassFlag.HExtends,haxeparser_ClassFlag.HImplements,haxeparser_ClassFlag.HFinal,haxeparser_ClassFlag.HAbstract];
var haxeparser_AbstractFlag = $hxEnums["haxeparser.AbstractFlag"] = { __ename__:true,__constructs__:null
	,AbPrivate: {_hx_name:"AbPrivate",_hx_index:0,__enum__:"haxeparser.AbstractFlag",toString:$estr}
	,AbFrom: ($_=function(ct) { return {_hx_index:1,ct:ct,__enum__:"haxeparser.AbstractFlag",toString:$estr}; },$_._hx_name="AbFrom",$_.__params__ = ["ct"],$_)
	,AbTo: ($_=function(ct) { return {_hx_index:2,ct:ct,__enum__:"haxeparser.AbstractFlag",toString:$estr}; },$_._hx_name="AbTo",$_.__params__ = ["ct"],$_)
	,AbOver: ($_=function(ct) { return {_hx_index:3,ct:ct,__enum__:"haxeparser.AbstractFlag",toString:$estr}; },$_._hx_name="AbOver",$_.__params__ = ["ct"],$_)
	,AbExtern: {_hx_name:"AbExtern",_hx_index:4,__enum__:"haxeparser.AbstractFlag",toString:$estr}
	,AbEnum: {_hx_name:"AbEnum",_hx_index:5,__enum__:"haxeparser.AbstractFlag",toString:$estr}
};
haxeparser_AbstractFlag.__constructs__ = [haxeparser_AbstractFlag.AbPrivate,haxeparser_AbstractFlag.AbFrom,haxeparser_AbstractFlag.AbTo,haxeparser_AbstractFlag.AbOver,haxeparser_AbstractFlag.AbExtern,haxeparser_AbstractFlag.AbEnum];
var haxeparser_EnumFlag = $hxEnums["haxeparser.EnumFlag"] = { __ename__:true,__constructs__:null
	,EPrivate: {_hx_name:"EPrivate",_hx_index:0,__enum__:"haxeparser.EnumFlag",toString:$estr}
	,EExtern: {_hx_name:"EExtern",_hx_index:1,__enum__:"haxeparser.EnumFlag",toString:$estr}
};
haxeparser_EnumFlag.__constructs__ = [haxeparser_EnumFlag.EPrivate,haxeparser_EnumFlag.EExtern];
var haxeparser_TypedefFlag = $hxEnums["haxeparser.TypedefFlag"] = { __ename__:true,__constructs__:null
	,TDPrivate: {_hx_name:"TDPrivate",_hx_index:0,__enum__:"haxeparser.TypedefFlag",toString:$estr}
	,TDExtern: {_hx_name:"TDExtern",_hx_index:1,__enum__:"haxeparser.TypedefFlag",toString:$estr}
};
haxeparser_TypedefFlag.__constructs__ = [haxeparser_TypedefFlag.TDPrivate,haxeparser_TypedefFlag.TDExtern];
var haxeparser_StaticFlag = $hxEnums["haxeparser.StaticFlag"] = { __ename__:true,__constructs__:null
	,SDynamic: {_hx_name:"SDynamic",_hx_index:0,__enum__:"haxeparser.StaticFlag",toString:$estr}
	,SFinal: {_hx_name:"SFinal",_hx_index:1,__enum__:"haxeparser.StaticFlag",toString:$estr}
	,SInline: {_hx_name:"SInline",_hx_index:2,__enum__:"haxeparser.StaticFlag",toString:$estr}
	,SMacro: {_hx_name:"SMacro",_hx_index:3,__enum__:"haxeparser.StaticFlag",toString:$estr}
	,SPrivate: {_hx_name:"SPrivate",_hx_index:4,__enum__:"haxeparser.StaticFlag",toString:$estr}
	,SOverload: {_hx_name:"SOverload",_hx_index:5,__enum__:"haxeparser.StaticFlag",toString:$estr}
};
haxeparser_StaticFlag.__constructs__ = [haxeparser_StaticFlag.SDynamic,haxeparser_StaticFlag.SFinal,haxeparser_StaticFlag.SInline,haxeparser_StaticFlag.SMacro,haxeparser_StaticFlag.SPrivate,haxeparser_StaticFlag.SOverload];
var haxeparser_ImportMode = $hxEnums["haxeparser.ImportMode"] = { __ename__:true,__constructs__:null
	,INormal: {_hx_name:"INormal",_hx_index:0,__enum__:"haxeparser.ImportMode",toString:$estr}
	,IAsName: ($_=function(s) { return {_hx_index:1,s:s,__enum__:"haxeparser.ImportMode",toString:$estr}; },$_._hx_name="IAsName",$_.__params__ = ["s"],$_)
	,IAll: {_hx_name:"IAll",_hx_index:2,__enum__:"haxeparser.ImportMode",toString:$estr}
};
haxeparser_ImportMode.__constructs__ = [haxeparser_ImportMode.INormal,haxeparser_ImportMode.IAsName,haxeparser_ImportMode.IAll];
var haxeparser_LexerErrorMsg = $hxEnums["haxeparser.LexerErrorMsg"] = { __ename__:true,__constructs__:null
	,UnterminatedString: {_hx_name:"UnterminatedString",_hx_index:0,__enum__:"haxeparser.LexerErrorMsg",toString:$estr}
	,UnterminatedRegExp: {_hx_name:"UnterminatedRegExp",_hx_index:1,__enum__:"haxeparser.LexerErrorMsg",toString:$estr}
	,UnclosedComment: {_hx_name:"UnclosedComment",_hx_index:2,__enum__:"haxeparser.LexerErrorMsg",toString:$estr}
	,UnterminatedEscapeSequence: {_hx_name:"UnterminatedEscapeSequence",_hx_index:3,__enum__:"haxeparser.LexerErrorMsg",toString:$estr}
	,InvalidEscapeSequence: ($_=function(c) { return {_hx_index:4,c:c,__enum__:"haxeparser.LexerErrorMsg",toString:$estr}; },$_._hx_name="InvalidEscapeSequence",$_.__params__ = ["c"],$_)
	,UnknownEscapeSequence: ($_=function(c) { return {_hx_index:5,c:c,__enum__:"haxeparser.LexerErrorMsg",toString:$estr}; },$_._hx_name="UnknownEscapeSequence",$_.__params__ = ["c"],$_)
	,UnclosedCode: {_hx_name:"UnclosedCode",_hx_index:6,__enum__:"haxeparser.LexerErrorMsg",toString:$estr}
};
haxeparser_LexerErrorMsg.__constructs__ = [haxeparser_LexerErrorMsg.UnterminatedString,haxeparser_LexerErrorMsg.UnterminatedRegExp,haxeparser_LexerErrorMsg.UnclosedComment,haxeparser_LexerErrorMsg.UnterminatedEscapeSequence,haxeparser_LexerErrorMsg.InvalidEscapeSequence,haxeparser_LexerErrorMsg.UnknownEscapeSequence,haxeparser_LexerErrorMsg.UnclosedCode];
class haxeparser_LexerError {
	constructor(msg,pos) {
		this.msg = msg;
		this.pos = pos;
	}
}
haxeparser_LexerError.__name__ = true;
class hxparse_Lexer {
	constructor(input,sourceName) {
		if(sourceName == null) {
			sourceName = "<null>";
		}
		this.current = "";
		this.input = input;
		this.source = sourceName;
		this.pos = 0;
	}
	curPos() {
		return new hxparse_Position(this.source,this.pos - this.current.length,this.pos);
	}
	token(ruleset) {
		if(this.pos == this.input.length) {
			if(ruleset.eofFunction != null) {
				return ruleset.eofFunction(this);
			} else {
				throw haxe_Exception.thrown(new haxe_io_Eof());
			}
		}
		let state = ruleset.state;
		let lastMatch = null;
		let lastMatchPos = this.pos;
		let start = this.pos;
		do {
			if(state.finalId > -1) {
				lastMatch = state;
				lastMatchPos = this.pos;
			}
			if(this.pos == this.input.length) {
				break;
			}
			let i = this.input.b[this.pos];
			++this.pos;
			state = state.trans[i];
		} while(state != null);
		this.pos = lastMatchPos;
		this.current = this.input.getString(start,this.pos - start);
		if(lastMatch == null || lastMatch.finalId == -1) {
			let code = this.input.b[this.pos];
			throw haxe_Exception.thrown(new hxparse_UnexpectedChar(String.fromCodePoint(code),new hxparse_Position(this.source,this.pos - this.current.length,this.pos)));
		}
		return ruleset.functions[lastMatch.finalId](this);
	}
	static buildRuleset(rules,name) {
		if(name == null) {
			name = "";
		}
		let cases = [];
		let functions = [];
		let eofFunction = null;
		let _g = 0;
		while(_g < rules.length) {
			let rule = rules[_g];
			++_g;
			if(rule.rule == "") {
				eofFunction = rule.func;
			} else {
				cases.push(hxparse_LexEngine.parse(rule.rule));
				functions.push(rule.func);
			}
		}
		return new hxparse_Ruleset(new hxparse_LexEngine(cases).firstState(),functions,eofFunction,name);
	}
}
hxparse_Lexer.__name__ = true;
class hxparse__$LexEngine_CharRange {
	constructor(min,max) {
		this.min = min;
		this.max = max;
	}
}
hxparse__$LexEngine_CharRange.__name__ = true;
class hxparse_LexEngine {
	constructor(patterns) {
		this.nodes = [];
		this.finals = [];
		this.states = [];
		this.hstates = new haxe_ds_StringMap();
		this.uid = 0;
		let pid = 0;
		let _g = 0;
		while(_g < patterns.length) {
			let p = patterns[_g];
			++_g;
			let id = pid++;
			let f = new hxparse__$LexEngine_Node(this.uid++,id);
			let n = this.initNode(p,f,id);
			this.nodes.push(n);
			this.finals.push(f);
		}
		this.makeState(this.addNodes([],this.nodes));
	}
	firstState() {
		return this.states[0];
	}
	makeState(nodes) {
		let buf_b = "";
		let _g = 0;
		while(_g < nodes.length) {
			let n = nodes[_g];
			++_g;
			buf_b += Std.string(n.id);
			buf_b += String.fromCodePoint(45);
		}
		let key = buf_b;
		let s = this.hstates.h[key];
		if(s != null) {
			return s;
		}
		s = new hxparse_State();
		this.states.push(s);
		this.hstates.h[key] = s;
		let trans = this.getTransitions(nodes);
		let _g1 = 0;
		while(_g1 < trans.length) {
			let t = trans[_g1];
			++_g1;
			let target = this.makeState(t.n);
			let _g = 0;
			let _g2 = t.chars;
			while(_g < _g2.length) {
				let chr = _g2[_g];
				++_g;
				let _g1 = chr.min;
				let _g3 = chr.max + 1;
				while(_g1 < _g3) {
					let i = _g1++;
					s.trans[i] = target;
				}
			}
		}
		let _gthis = this;
		let setFinal = function() {
			let _g = 0;
			let _g1 = _gthis.finals;
			while(_g < _g1.length) {
				let f = _g1[_g];
				++_g;
				let _g2 = 0;
				while(_g2 < nodes.length) {
					let n = nodes[_g2];
					++_g2;
					if(n == f) {
						s.finalId = n.pid;
						return;
					}
				}
			}
		};
		if(s.finalId == -1) {
			setFinal();
		}
		return s;
	}
	getTransitions(nodes) {
		let tl = [];
		let _g = 0;
		while(_g < nodes.length) {
			let n = nodes[_g];
			++_g;
			let _g1 = 0;
			let _g2 = n.trans;
			while(_g1 < _g2.length) {
				let t = _g2[_g1];
				++_g1;
				tl.push(t);
			}
		}
		tl.sort(function(t1,t2) {
			return t1.n.id - t2.n.id;
		});
		let t0 = tl[0];
		let _g1 = 1;
		let _g2 = tl.length;
		while(_g1 < _g2) {
			let i = _g1++;
			let t1 = tl[i];
			if(t0.n == t1.n) {
				tl[i - 1] = null;
				t1 = { chars : hxparse_LexEngine.cunion(t0.chars,t1.chars), n : t1.n};
				tl[i] = t1;
			}
			t0 = t1;
		}
		while(HxOverrides.remove(tl,null)) {
		}
		let allChars = hxparse_LexEngine.EMPTY;
		let allStates = new haxe_ds_List();
		let _g3 = 0;
		while(_g3 < tl.length) {
			let t = tl[_g3];
			++_g3;
			let states = new haxe_ds_List();
			states.push({ chars : hxparse_LexEngine.cdiff(t.chars,allChars), n : [t.n]});
			let _g_head = allStates.h;
			while(_g_head != null) {
				let val = _g_head.item;
				_g_head = _g_head.next;
				let s = val;
				let nodes = s.n.slice();
				nodes.push(t.n);
				states.push({ chars : hxparse_LexEngine.cinter(s.chars,t.chars), n : nodes});
				states.push({ chars : hxparse_LexEngine.cdiff(s.chars,t.chars), n : s.n});
			}
			let _g_head1 = states.h;
			while(_g_head1 != null) {
				let val = _g_head1.item;
				_g_head1 = _g_head1.next;
				let s = val;
				if(s.chars.length == 0) {
					states.remove(s);
				}
			}
			allChars = hxparse_LexEngine.cunion(allChars,t.chars);
			allStates = states;
		}
		let states = [];
		let _g_head = allStates.h;
		while(_g_head != null) {
			let val = _g_head.item;
			_g_head = _g_head.next;
			let s = val;
			states.push({ chars : s.chars, n : this.addNodes([],s.n)});
		}
		states.sort(function(s1,s2) {
			let a = s1.chars.length;
			let b = s2.chars.length;
			let _g = 0;
			let _g1 = a < b ? a : b;
			while(_g < _g1) {
				let i = _g++;
				let a = s1.chars[i];
				let b = s2.chars[i];
				if(a.min != b.min) {
					return b.min - a.min;
				}
				if(a.max != b.max) {
					return b.max - a.max;
				}
			}
			if(a < b) {
				return b - a;
			}
			return 0;
		});
		return states;
	}
	addNode(nodes,n) {
		let _g = 0;
		while(_g < nodes.length) {
			let n2 = nodes[_g];
			++_g;
			if(n == n2) {
				return;
			}
		}
		nodes.push(n);
		this.addNodes(nodes,n.epsilon);
	}
	addNodes(nodes,add) {
		let _g = 0;
		while(_g < add.length) {
			let n = add[_g];
			++_g;
			this.addNode(nodes,n);
		}
		return nodes;
	}
	node(pid) {
		return new hxparse__$LexEngine_Node(this.uid++,pid);
	}
	initNode(p,finalId,pid) {
		switch(p._hx_index) {
		case 0:
			return finalId;
		case 1:
			let c = p.c;
			let n = new hxparse__$LexEngine_Node(this.uid++,pid);
			n.trans.push({ chars : c, n : finalId});
			return n;
		case 2:
			let p1 = p.p;
			let n1 = new hxparse__$LexEngine_Node(this.uid++,pid);
			let an = this.initNode(p1,n1,pid);
			n1.epsilon.push(an);
			n1.epsilon.push(finalId);
			return n1;
		case 3:
			let p2 = p.p;
			let n2 = new hxparse__$LexEngine_Node(this.uid++,pid);
			let an1 = this.initNode(p2,n2,pid);
			n2.epsilon.push(an1);
			n2.epsilon.push(finalId);
			return an1;
		case 4:
			let a = p.p1;
			let b = p.p2;
			return this.initNode(a,this.initNode(b,finalId,pid),pid);
		case 5:
			let a1 = p.p1;
			let b1 = p.p2;
			let n3 = new hxparse__$LexEngine_Node(this.uid++,pid);
			n3.epsilon.push(this.initNode(a1,finalId,pid));
			n3.epsilon.push(this.initNode(b1,finalId,pid));
			return n3;
		case 6:
			let p3 = p.p;
			return this.initNode(p3,finalId,pid);
		}
	}
	static single(c) {
		return [new hxparse__$LexEngine_CharRange(c,c)];
	}
	static parse(pattern) {
		let p = hxparse_LexEngine.parseInner(haxe_io_Bytes.ofString(pattern));
		if(p == null) {
			throw haxe_Exception.thrown("Invalid pattern '" + pattern + "'");
		}
		return p.pattern;
	}
	static next(a,b) {
		if(a == hxparse__$LexEngine_Pattern.Empty) {
			return b;
		} else {
			return hxparse__$LexEngine_Pattern.Next(a,b);
		}
	}
	static plus(r) {
		if(r._hx_index == 4) {
			let r1 = r.p1;
			let r2 = r.p2;
			return hxparse__$LexEngine_Pattern.Next(r1,hxparse_LexEngine.plus(r2));
		} else {
			return hxparse__$LexEngine_Pattern.Plus(r);
		}
	}
	static star(r) {
		if(r._hx_index == 4) {
			let r1 = r.p1;
			let r2 = r.p2;
			return hxparse__$LexEngine_Pattern.Next(r1,hxparse_LexEngine.star(r2));
		} else {
			return hxparse__$LexEngine_Pattern.Star(r);
		}
	}
	static opt(r) {
		if(r._hx_index == 4) {
			let r1 = r.p1;
			let r2 = r.p2;
			return hxparse__$LexEngine_Pattern.Next(r1,hxparse_LexEngine.opt(r2));
		} else {
			return hxparse__$LexEngine_Pattern.Choice(r,hxparse__$LexEngine_Pattern.Empty);
		}
	}
	static cinter(c1,c2) {
		return hxparse_LexEngine.ccomplement(hxparse_LexEngine.cunion(hxparse_LexEngine.ccomplement(c1),hxparse_LexEngine.ccomplement(c2)));
	}
	static cdiff(c1,c2) {
		return hxparse_LexEngine.ccomplement(hxparse_LexEngine.cunion(hxparse_LexEngine.ccomplement(c1),c2));
	}
	static ccomplement(c) {
		let first = c[0];
		let start = first != null && first.min == -1 ? c.shift().max + 1 : -1;
		let out = [];
		let _g = 0;
		while(_g < c.length) {
			let k = c[_g];
			++_g;
			out.push(new hxparse__$LexEngine_CharRange(start,k.min - 1));
			start = k.max + 1;
		}
		if(start <= 255) {
			out.push(new hxparse__$LexEngine_CharRange(start,255));
		}
		return out;
	}
	static cunion(ca,cb) {
		let i = 0;
		let j = 0;
		let out = [];
		let a = ca[i++];
		let b = cb[j++];
		while(true) {
			if(a == null) {
				out.push(b);
				while(j < cb.length) out.push(cb[j++]);
				break;
			}
			if(b == null) {
				out.push(a);
				while(i < ca.length) out.push(ca[i++]);
				break;
			}
			if(a.min <= b.min) {
				if(a.max + 1 < b.min) {
					out.push(a);
					a = ca[i++];
				} else if(a.max < b.max) {
					b = new hxparse__$LexEngine_CharRange(a.min,b.max);
					a = ca[i++];
				} else {
					b = cb[j++];
				}
			} else {
				let tmp = ca;
				ca = cb;
				cb = tmp;
				let tmp1 = j;
				j = i;
				i = tmp1;
				let tmp2 = a;
				a = b;
				b = tmp2;
			}
		}
		return out;
	}
	static parseInner(pattern,i,pDepth) {
		if(pDepth == null) {
			pDepth = 0;
		}
		if(i == null) {
			i = 0;
		}
		let readChar = function() {
			i += 1;
			let c = pattern.b[i - 1];
			if(c != c) {
				c = 92;
			} else if(c == 120) {
				c = Std.parseInt("0x" + pattern.getString(i,2));
				i += 2;
			} else if(c >= 48 && c <= 57) {
				let v = c - 48;
				while(true) {
					let cNext = pattern.b[i];
					if(cNext >= 48 && cNext <= 57) {
						v = v * 10 + (cNext - 48);
						i += 1;
					} else {
						break;
					}
				}
				c = v;
			}
			return c;
		};
		let r = hxparse__$LexEngine_Pattern.Empty;
		let l = pattern.length;
		while(i < l) {
			i += 1;
			let c = pattern.b[i - 1];
			if(c > 255) {
				throw haxe_Exception.thrown(c);
			}
			switch(c) {
			case 40:
				let r2 = hxparse_LexEngine.parseInner(pattern,i,pDepth + 1);
				i = r2.pos;
				r = hxparse_LexEngine.next(r,r2.pattern);
				break;
			case 41:
				if(r == hxparse__$LexEngine_Pattern.Empty) {
					throw haxe_Exception.thrown("Empty group");
				}
				return { pattern : hxparse__$LexEngine_Pattern.Group(r), pos : i};
			case 42:
				if(r != hxparse__$LexEngine_Pattern.Empty) {
					r = hxparse_LexEngine.star(r);
				} else {
					r = hxparse_LexEngine.next(r,hxparse__$LexEngine_Pattern.Match([new hxparse__$LexEngine_CharRange(c,c)]));
				}
				break;
			case 43:
				if(r != hxparse__$LexEngine_Pattern.Empty) {
					r = hxparse_LexEngine.plus(r);
				} else {
					r = hxparse_LexEngine.next(r,hxparse__$LexEngine_Pattern.Match([new hxparse__$LexEngine_CharRange(c,c)]));
				}
				break;
			case 46:
				r = hxparse_LexEngine.next(r,hxparse__$LexEngine_Pattern.Match(hxparse_LexEngine.ALL_CHARS));
				break;
			case 63:
				if(r != hxparse__$LexEngine_Pattern.Empty) {
					r = hxparse_LexEngine.opt(r);
				} else {
					r = hxparse_LexEngine.next(r,hxparse__$LexEngine_Pattern.Match([new hxparse__$LexEngine_CharRange(c,c)]));
				}
				break;
			case 91:
				if(pattern.length > 1) {
					let range = 0;
					let acc = [];
					let not = pattern.b[i] == 94;
					if(not) {
						i += 1;
					}
					while(true) {
						i += 1;
						let c = pattern.b[i - 1];
						if(c == 93) {
							if(range != 0) {
								return null;
							}
							break;
						} else if(c == 45) {
							if(range != 0) {
								return null;
							}
							let last = acc.pop();
							if(last == null) {
								acc.push(new hxparse__$LexEngine_CharRange(c,c));
							} else {
								if(last.min != last.max) {
									return null;
								}
								range = last.min;
							}
						} else {
							if(c == 92) {
								c = readChar();
							}
							if(range == 0) {
								acc.push(new hxparse__$LexEngine_CharRange(c,c));
							} else {
								acc.push(new hxparse__$LexEngine_CharRange(range,c));
								range = 0;
							}
						}
					}
					let g = [];
					let _g = 0;
					while(_g < acc.length) {
						let k = acc[_g];
						++_g;
						g = hxparse_LexEngine.cunion(g,[k]);
					}
					if(not) {
						g = hxparse_LexEngine.cdiff(hxparse_LexEngine.ALL_CHARS,g);
					}
					r = hxparse_LexEngine.next(r,hxparse__$LexEngine_Pattern.Match(g));
				} else {
					r = hxparse_LexEngine.next(r,hxparse__$LexEngine_Pattern.Match([new hxparse__$LexEngine_CharRange(c,c)]));
				}
				break;
			case 92:
				c = readChar();
				r = hxparse_LexEngine.next(r,hxparse__$LexEngine_Pattern.Match([new hxparse__$LexEngine_CharRange(c,c)]));
				break;
			case 124:
				if(r != hxparse__$LexEngine_Pattern.Empty) {
					let r2 = hxparse_LexEngine.parseInner(pattern,i);
					return { pattern : hxparse__$LexEngine_Pattern.Choice(r,r2.pattern), pos : r2.pos};
				} else {
					r = hxparse_LexEngine.next(r,hxparse__$LexEngine_Pattern.Match([new hxparse__$LexEngine_CharRange(c,c)]));
				}
				break;
			default:
				r = hxparse_LexEngine.next(r,hxparse__$LexEngine_Pattern.Match([new hxparse__$LexEngine_CharRange(c,c)]));
			}
		}
		if(pDepth != 0) {
			throw haxe_Exception.thrown("Found unclosed parenthesis while parsing \"" + Std.string(pattern) + "\"");
		}
		return { pattern : r, pos : i};
	}
}
hxparse_LexEngine.__name__ = true;
var hxparse__$LexEngine_Pattern = $hxEnums["hxparse._LexEngine.Pattern"] = { __ename__:true,__constructs__:null
	,Empty: {_hx_name:"Empty",_hx_index:0,__enum__:"hxparse._LexEngine.Pattern",toString:$estr}
	,Match: ($_=function(c) { return {_hx_index:1,c:c,__enum__:"hxparse._LexEngine.Pattern",toString:$estr}; },$_._hx_name="Match",$_.__params__ = ["c"],$_)
	,Star: ($_=function(p) { return {_hx_index:2,p:p,__enum__:"hxparse._LexEngine.Pattern",toString:$estr}; },$_._hx_name="Star",$_.__params__ = ["p"],$_)
	,Plus: ($_=function(p) { return {_hx_index:3,p:p,__enum__:"hxparse._LexEngine.Pattern",toString:$estr}; },$_._hx_name="Plus",$_.__params__ = ["p"],$_)
	,Next: ($_=function(p1,p2) { return {_hx_index:4,p1:p1,p2:p2,__enum__:"hxparse._LexEngine.Pattern",toString:$estr}; },$_._hx_name="Next",$_.__params__ = ["p1","p2"],$_)
	,Choice: ($_=function(p1,p2) { return {_hx_index:5,p1:p1,p2:p2,__enum__:"hxparse._LexEngine.Pattern",toString:$estr}; },$_._hx_name="Choice",$_.__params__ = ["p1","p2"],$_)
	,Group: ($_=function(p) { return {_hx_index:6,p:p,__enum__:"hxparse._LexEngine.Pattern",toString:$estr}; },$_._hx_name="Group",$_.__params__ = ["p"],$_)
};
hxparse__$LexEngine_Pattern.__constructs__ = [hxparse__$LexEngine_Pattern.Empty,hxparse__$LexEngine_Pattern.Match,hxparse__$LexEngine_Pattern.Star,hxparse__$LexEngine_Pattern.Plus,hxparse__$LexEngine_Pattern.Next,hxparse__$LexEngine_Pattern.Choice,hxparse__$LexEngine_Pattern.Group];
class js_Boot {
	static __string_rec(o,s) {
		if(o == null) {
			return "null";
		}
		if(s.length >= 5) {
			return "<...>";
		}
		let t = typeof(o);
		if(t == "function" && (o.__name__ || o.__ename__)) {
			t = "object";
		}
		switch(t) {
		case "function":
			return "<function>";
		case "object":
			if(o.__enum__) {
				let e = $hxEnums[o.__enum__];
				let con = e.__constructs__[o._hx_index];
				let n = con._hx_name;
				if(con.__params__) {
					s = s + "\t";
					return n + "(" + ((function($this) {
						var $r;
						let _g = [];
						{
							let _g1 = 0;
							let _g2 = con.__params__;
							while(true) {
								if(!(_g1 < _g2.length)) {
									break;
								}
								let p = _g2[_g1];
								_g1 = _g1 + 1;
								_g.push(js_Boot.__string_rec(o[p],s));
							}
						}
						$r = _g;
						return $r;
					}(this))).join(",") + ")";
				} else {
					return n;
				}
			}
			if(((o) instanceof Array)) {
				let str = "[";
				s += "\t";
				let _g = 0;
				let _g1 = o.length;
				while(_g < _g1) {
					let i = _g++;
					str += (i > 0 ? "," : "") + js_Boot.__string_rec(o[i],s);
				}
				str += "]";
				return str;
			}
			let tostr;
			try {
				tostr = o.toString;
			} catch( _g ) {
				return "???";
			}
			if(tostr != null && tostr != Object.toString && typeof(tostr) == "function") {
				let s2 = o.toString();
				if(s2 != "[object Object]") {
					return s2;
				}
			}
			let str = "{\n";
			s += "\t";
			let hasp = o.hasOwnProperty != null;
			let k = null;
			for( k in o ) {
			if(hasp && !o.hasOwnProperty(k)) {
				continue;
			}
			if(k == "prototype" || k == "__class__" || k == "__super__" || k == "__interfaces__" || k == "__properties__") {
				continue;
			}
			if(str.length != 2) {
				str += ", \n";
			}
			str += s + k + " : " + js_Boot.__string_rec(o[k],s);
			}
			s = s.substring(1);
			str += "\n" + s + "}";
			return str;
		case "string":
			return o;
		default:
			return String(o);
		}
	}
}
js_Boot.__name__ = true;
class hxparse__$LexEngine_Node {
	constructor(id,pid) {
		this.id = id;
		this.pid = pid;
		this.trans = [];
		this.epsilon = [];
	}
}
hxparse__$LexEngine_Node.__name__ = true;
class hxparse_Ruleset {
	constructor(state,functions,eofFunction,name) {
		if(name == null) {
			name = "";
		}
		this.state = state;
		this.functions = functions;
		this.eofFunction = eofFunction;
		this.name = name;
	}
}
hxparse_Ruleset.__name__ = true;
class hxparse_Position {
	constructor(source,min,max) {
		this.psource = source;
		this.pmin = min;
		this.pmax = max;
	}
	toString() {
		return "" + this.psource + ":characters " + this.pmin + "-" + this.pmax;
	}
	getLinePosition(input) {
		let lineMin = 1;
		let lineMax = 1;
		let posMin = 0;
		let posMax = 0;
		let cur = 0;
		while(cur < this.pmin) {
			if(input.b[cur] == 10) {
				++lineMin;
				posMin = cur + 1;
			}
			++cur;
		}
		lineMax = lineMin;
		posMax = posMin;
		posMin = cur - posMin;
		while(cur < this.pmax) {
			if(input.b[cur] == 10) {
				++lineMax;
				posMax = cur + 1;
			}
			++cur;
		}
		posMax = cur - posMax;
		return { lineMin : lineMin, lineMax : lineMax, posMin : posMin, posMax : posMax};
	}
	format(input) {
		let linePos = this.getLinePosition(input);
		if(linePos.lineMin != linePos.lineMax) {
			return "" + this.psource + ":lines " + linePos.lineMin + "-" + linePos.lineMax;
		} else {
			return "" + this.psource + ":" + linePos.lineMin + ": characters " + linePos.posMin + "-" + linePos.posMax;
		}
	}
	static union(p1,p2) {
		return new hxparse_Position(p1.psource,p1.pmin < p2.pmin ? p1.pmin : p2.pmin,p1.pmax > p2.pmax ? p1.pmax : p2.pmax);
	}
}
hxparse_Position.__name__ = true;
class haxeparser_HaxeLexer extends hxparse_Lexer {
	constructor(input,sourceName) {
		super(input,sourceName);
	}
	static mkPos(p) {
		return { file : p.psource, min : p.pmin, max : p.pmax};
	}
	static mk(lexer,td) {
		return new haxeparser_Token(td,haxeparser_HaxeLexer.mkPos(new hxparse_Position(lexer.source,lexer.pos - lexer.current.length,lexer.pos)));
	}
	static inlineMarkup(lexer) {
		let tagName = HxOverrides.substr(lexer.current,1,null);
		let startPos = lexer.pos - lexer.current.length;
		let text = lexer.input.getString(startPos,lexer.input.length - startPos);
		let startTag = "<" + tagName;
		let endTag = "</" + tagName + ">";
		let normalLt = function() {
			lexer.pos = startPos + 1;
			lexer.current = "<";
			return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Binop(haxe_macro_Binop.OpLt));
		};
		let depth = 0;
		let index = 0;
		while(true) {
			let indexStartTag = text.indexOf(startTag,index);
			let indexEndTag = text.indexOf(endTag,index);
			if(indexStartTag == -1 && indexEndTag == -1) {
				return normalLt();
			}
			if(indexStartTag == -1) {
				indexStartTag = indexEndTag + 1;
			}
			if(indexEndTag == -1) {
				indexEndTag = indexStartTag + 1;
			}
			if(indexStartTag < indexEndTag) {
				index = indexStartTag + startTag.length;
				switch(text.charAt(index)) {
				case " ":case "/":case ">":
					break;
				default:
					continue;
				}
				++depth;
				let indexSelfClosing = text.indexOf("/>",index);
				let indexTagClosing = text.indexOf(">",index);
				let indexOpenTag = text.indexOf("<",index);
				if(indexSelfClosing == -1 && indexTagClosing == -1 && indexOpenTag == -1) {
					return normalLt();
				}
				if(indexSelfClosing == -1) {
					indexSelfClosing = (Math.max(indexTagClosing,indexOpenTag) | 0) + 1;
				}
				if(indexTagClosing == -1) {
					indexTagClosing = (Math.max(indexSelfClosing,indexOpenTag) | 0) + 1;
				}
				if(indexOpenTag == -1) {
					indexOpenTag = (Math.max(indexSelfClosing,indexTagClosing) | 0) + 1;
				}
				if(indexSelfClosing < indexTagClosing && indexSelfClosing < indexOpenTag) {
					index = indexSelfClosing + 2;
					--depth;
				}
				if(indexTagClosing < indexSelfClosing && indexTagClosing < indexOpenTag) {
					index = indexTagClosing + 1;
				}
				if(indexOpenTag < indexSelfClosing && indexOpenTag < indexTagClosing) {
					index = indexOpenTag;
				}
			}
			if(indexEndTag < indexStartTag) {
				index = indexEndTag + endTag.length;
				--depth;
			}
			if(depth <= 0) {
				break;
			}
		}
		text = HxOverrides.substr(text,0,index);
		let textBytes = haxe_io_Bytes.ofString(text);
		let endPos = startPos + textBytes.length;
		lexer.current = text;
		lexer.pos = endPos;
		return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Const(haxeparser_Constant.CMarkup(text)));
	}
	static splitSuffix(value,pivot,isInt) {
		let literal = HxOverrides.substr(value,0,pivot);
		let suffix = HxOverrides.substr(value,pivot,null);
		if(literal.endsWith("_")) {
			literal = HxOverrides.substr(literal,0,literal.length - 1);
		}
		if(isInt) {
			return haxeparser_TokenDef.Const(haxeparser_Constant.CInt(literal,suffix));
		}
		return haxeparser_TokenDef.Const(haxeparser_Constant.CFloat(literal,suffix));
	}
	static splitIntSuffix(value) {
		let index = value.indexOf("i");
		if(index <= 0) {
			index = value.indexOf("u");
		}
		if(index <= 0) {
			return haxeparser_TokenDef.Const(haxeparser_Constant.CInt(value));
		}
		return haxeparser_HaxeLexer.splitSuffix(value,index,true);
	}
	static splitFloatSuffix(value) {
		let index = value.indexOf("f");
		if(index <= 0) {
			return haxeparser_TokenDef.Const(haxeparser_Constant.CFloat(value));
		}
		return haxeparser_HaxeLexer.splitSuffix(value,index,false);
	}
	static unescapePos(pos,index,length) {
		return { file : pos.file, min : pos.min + index, max : pos.min + index + length};
	}
	static unescape(s,pos) {
		let b_b = "";
		let i = 0;
		let esc = false;
		while(s.length != i) {
			let c = HxOverrides.cca(s,i);
			if(esc) {
				let iNext = i + 1;
				let _hx_tmp;
				if(c == null) {
					_hx_tmp = c >= 48 && c <= 51;
					if(_hx_tmp == true) {
						iNext += 2;
					} else {
						let c1 = c;
						throw haxe_Exception.thrown(new haxeparser_LexerError(haxeparser_LexerErrorMsg.UnknownEscapeSequence("\\" + String.fromCodePoint(c1)),{ file : pos.file, min : pos.min + i, max : pos.min + i + 1}));
					}
				} else {
					switch(c) {
					case 34:case 39:case 92:
						b_b += String.fromCodePoint(c);
						break;
					case 110:
						b_b += "\n";
						break;
					case 114:
						b_b += "\r";
						break;
					case 116:
						b_b += "\t";
						break;
					case 117:
						_hx_tmp = c >= 48 && c <= 51;
						if(_hx_tmp == true) {
							iNext += 2;
						} else {
							let c;
							if(s.charAt(i + 1) == "{") {
								let endIndex = s.indexOf("}",i + 3);
								if(endIndex == -1) {
									throw haxe_Exception.thrown(new haxeparser_LexerError(haxeparser_LexerErrorMsg.UnterminatedEscapeSequence,{ file : pos.file, min : pos.min + i, max : pos.min + i + 2}));
								}
								let l = endIndex - (i + 2);
								let chars = HxOverrides.substr(s,i + 2,l);
								if(!new EReg("^[0-9a-fA-F]+$","").match(chars)) {
									throw haxe_Exception.thrown(new haxeparser_LexerError(haxeparser_LexerErrorMsg.InvalidEscapeSequence("\\u{" + chars + "}"),{ file : pos.file, min : pos.min + i, max : pos.min + i + (3 + l)}));
								}
								c = Std.parseInt("0x" + chars);
								if(c > 1114111) {
									throw haxe_Exception.thrown(new haxeparser_LexerError(haxeparser_LexerErrorMsg.InvalidEscapeSequence("\\u{" + chars + "}"),{ file : pos.file, min : pos.min + i, max : pos.min + i + (3 + l)}));
								}
								iNext += 2 + l;
							} else {
								let chars = HxOverrides.substr(s,i + 1,4);
								if(!new EReg("^[0-9a-fA-F]{4}$","").match(chars)) {
									throw haxe_Exception.thrown(new haxeparser_LexerError(haxeparser_LexerErrorMsg.InvalidEscapeSequence("\\u" + chars),{ file : pos.file, min : pos.min + i, max : pos.min + i + 5}));
								}
								c = Std.parseInt("0x" + chars);
								iNext += 4;
							}
							b_b += String.fromCodePoint(c);
						}
						break;
					case 120:
						_hx_tmp = c >= 48 && c <= 51;
						if(_hx_tmp == true) {
							iNext += 2;
						} else {
							let chars = HxOverrides.substr(s,i + 1,2);
							if(!new EReg("^[0-9a-fA-F]{2}$","").match(chars)) {
								throw haxe_Exception.thrown(new haxeparser_LexerError(haxeparser_LexerErrorMsg.InvalidEscapeSequence("\\x" + chars),{ file : pos.file, min : pos.min + i, max : pos.min + i + 3}));
							}
							let c = Std.parseInt("0x" + chars);
							b_b += String.fromCodePoint(c);
							iNext += 2;
						}
						break;
					default:
						_hx_tmp = c >= 48 && c <= 51;
						if(_hx_tmp == true) {
							iNext += 2;
						} else {
							let c1 = c;
							throw haxe_Exception.thrown(new haxeparser_LexerError(haxeparser_LexerErrorMsg.UnknownEscapeSequence("\\" + String.fromCodePoint(c1)),{ file : pos.file, min : pos.min + i, max : pos.min + i + 1}));
						}
					}
				}
				esc = false;
				i = iNext;
			} else if(c == null) {
				b_b += String.fromCodePoint(c);
				++i;
			} else if(c == 92) {
				++i;
				esc = true;
			} else {
				b_b += String.fromCodePoint(c);
				++i;
			}
		}
		return b_b;
	}
}
haxeparser_HaxeLexer.__name__ = true;
class hxargs_Args {
}
hxargs_Args.__name__ = true;
class hxparse__$LexEngine_Transition {
	constructor(chars) {
		this.chars = chars;
	}
	toString() {
		return Std.string(this.chars);
	}
}
hxparse__$LexEngine_Transition.__name__ = true;
class hxparse_ParserError {
	constructor(pos) {
		this.pos = pos;
	}
	toString() {
		return "Parser error";
	}
}
hxparse_ParserError.__name__ = true;
class hxparse_RuleBuilderImpl {
}
hxparse_RuleBuilderImpl.__name__ = true;
class hxparse_State {
	constructor() {
		this.finalId = -1;
		this.trans = new Array(256);
	}
}
hxparse_State.__name__ = true;
class hxparse_UnexpectedChar extends hxparse_ParserError {
	constructor(char,pos) {
		super(pos);
		this.char = char;
	}
	toString() {
		return "Unexpected " + this.char;
	}
}
hxparse_UnexpectedChar.__name__ = true;
var js_node_Fs = require("fs");
class js_node_KeyValue {
	static get_key(this1) {
		return this1[0];
	}
	static get_value(this1) {
		return this1[1];
	}
}
var js_node_Path = require("path");
var js_node_buffer_Buffer = require("buffer").Buffer;
class js_node_buffer__$Buffer_Helper {
	static bytesOfBuffer(b) {
		let o = Object.create(haxe_io_Bytes.prototype);
		o.length = b.byteLength;
		o.b = b;
		b.bufferValue = b;
		b.hxBytes = o;
		b.bytes = b;
		return o;
	}
}
js_node_buffer__$Buffer_Helper.__name__ = true;
class js_node_stream_WritableNewOptionsAdapter {
	static from(options) {
		if(!Object.prototype.hasOwnProperty.call(options,"final")) {
			Object.defineProperty(options,"final",{ get : function() {
				return options.final_;
			}});
		}
		return options;
	}
}
class js_node_url_URLSearchParamsEntry {
	static _new(name,value) {
		return [name,value];
	}
	static get_name(this1) {
		return this1[0];
	}
	static get_value(this1) {
		return this1[1];
	}
}
class refactor_Cli {
	constructor() {
		this.exitCode = 0;
		this.forReal = false;
		this.verbose = false;
		let args = process.argv.slice(2);
		if(process.env["HAXELIB_RUN"] == "1") {
			if(args.length > 0) {
				let s = args.pop();
				process.chdir(s);
			}
		}
		let paths = [];
		let loc = "";
		let toName = "";
		let help = false;
		let execute = false;
		let verboseLog = function(text,pos) {
		};
		let _gthis = this;
		let argHandler_getDoc = function() {
			return "[-s | --source] <path> : file or directory with .hx files (multiple allowed)\n[-l] <location>        : location (path + filename and byte offset from beginning of file) of identifier to rename - <src/pack/Filename.hx@123>\n[-n] <newName>         : new name for all occurences of identifier\n[-v]                   : Print additional information\n[-x]                   : perform renaming operations\n[--i-have-backups]     : you have a backup and you really, really want to rename\n[-h | --help]          : display list of options";
		};
		let argHandler_parse = function(__args) {
			let __index = 0;
			while(__index < __args.length) {
				let _g = __args[__index++];
				switch(_g) {
				case "--help":case "-h":
					if(__index > __args.length) {
						if(![][__args.length - 1]) {
							throw haxe_Exception.thrown("Not enough arguments: " + Std.string(__args[__index - 1]) + " expects " + 0);
						}
					}
					help = true;
					__index += 0;
					break;
				case "--i-have-backups":
					if(__index > __args.length) {
						if(![][__args.length - 1]) {
							throw haxe_Exception.thrown("Not enough arguments: " + Std.string(__args[__index - 1]) + " expects " + 0);
						}
					}
					_gthis.forReal = true;
					__index += 0;
					break;
				case "--source":case "-s":
					if(__index + 1 > __args.length) {
						if(![false][__args.length - 1]) {
							throw haxe_Exception.thrown("Not enough arguments: " + Std.string(__args[__index - 1]) + " expects " + 1);
						}
					}
					paths.push(__args[__index]);
					++__index;
					break;
				case "-l":
					if(__index + 1 > __args.length) {
						if(![false][__args.length - 1]) {
							throw haxe_Exception.thrown("Not enough arguments: " + Std.string(__args[__index - 1]) + " expects " + 1);
						}
					}
					loc = __args[__index];
					++__index;
					break;
				case "-n":
					if(__index + 1 > __args.length) {
						if(![false][__args.length - 1]) {
							throw haxe_Exception.thrown("Not enough arguments: " + Std.string(__args[__index - 1]) + " expects " + 1);
						}
					}
					toName = __args[__index];
					++__index;
					break;
				case "-v":
					if(__index > __args.length) {
						if(![][__args.length - 1]) {
							throw haxe_Exception.thrown("Not enough arguments: " + Std.string(__args[__index - 1]) + " expects " + 0);
						}
					}
					verboseLog = $bind(_gthis,_gthis.logMessage);
					__index += 0;
					break;
				case "-x":
					if(__index > __args.length) {
						if(![][__args.length - 1]) {
							throw haxe_Exception.thrown("Not enough arguments: " + Std.string(__args[__index - 1]) + " expects " + 0);
						}
					}
					execute = true;
					__index += 0;
					break;
				default:
					let arg = _g;
					throw haxe_Exception.thrown("Unknown command: " + Std.string(arg));
				}
			}
		};
		let printHelp = function() {
			let version = "2.2.2";
			process.stdout.write(Std.string("Haxe Rename " + version));
			process.stdout.write("\n");
			let v = argHandler_getDoc();
			process.stdout.write(Std.string(v));
			process.stdout.write("\n");
		};
		try {
			argHandler_parse(args);
		} catch( _g ) {
			let e = haxe_Exception.caught(_g).unwrap();
			new _$Sys_FileOutput(2).writeString((e == null ? "null" : Std.string(e)) + "\n");
			printHelp();
			process.exit(1);
		}
		if(args.length == 0 || help) {
			printHelp();
			process.exit(0);
		}
		let what = this.makeWhat(loc,toName);
		if(what == null) {
			printHelp();
			process.exit(1);
		}
		let usageContext = { fileName : "", file : null, usageCollector : new refactor_discover_UsageCollector(), nameMap : new refactor_discover_NameMap(), fileList : new refactor_discover_FileList(), typeList : new refactor_discover_TypeList(), type : null, cache : null};
		let hrtime = process.hrtime();
		let startTime = hrtime[0] + hrtime[1] / 1e9;
		refactor_discover_TraverseSources.traverseSources(paths,usageContext);
		usageContext.usageCollector.updateImportHx(usageContext);
		let result = refactor_Refactor.rename({ nameMap : usageContext.nameMap, fileList : usageContext.fileList, typeList : usageContext.typeList, what : what, forRealExecute : execute && this.forReal, docFactory : function(fileName) {
			return new refactor_edits_EditableDocument(fileName);
		}, verboseLog : verboseLog, typer : null});
		result.then(function(result) {
			switch(result._hx_index) {
			case 0:
				process.stdout.write("nothing to do");
				process.stdout.write("\n");
				break;
			case 1:
				process.stdout.write(Std.string("could not find identifier at " + loc));
				process.stdout.write("\n");
				break;
			case 2:
				let name = result.name;
				process.stdout.write(Std.string("renaming not supported for " + name));
				process.stdout.write("\n");
				break;
			case 3:
				process.stdout.write("");
				process.stdout.write("\n");
				break;
			case 4:
				process.stdout.write("changes were made");
				process.stdout.write("\n");
				break;
			}
		}).catch(function(msg) {
			process.stdout.write(Std.string("renaming failed " + msg));
			process.stdout.write("\n");
		}).finally(function() {
			let hrtime = process.hrtime();
			let v = hrtime[0] + hrtime[1] / 1e9 - startTime;
			process.stdout.write(Std.string(v));
			process.stdout.write("\n");
			let code = _gthis.exitCode;
			process.exit(code);
		});
	}
	logMessage(text,pos) {
		process.stdout.write(Std.string(text));
		process.stdout.write("\n");
	}
	makeWhat(location,toName) {
		let parts = location.split("@");
		if(parts.length != 2) {
			return null;
		}
		if(parts[0].length <= 0) {
			return null;
		}
		let pos = Std.parseInt(parts[1]);
		if(pos == null) {
			return null;
		}
		return { fileName : parts[0], toName : toName, pos : pos};
	}
	static main() {
		new refactor_Cli();
	}
}
refactor_Cli.__name__ = true;
class refactor_PrintHelper {
	static typeToString(identType) {
		switch(identType._hx_index) {
		case 17:
			let isStatic = identType.isStatic;
			return "FieldVar(" + (isStatic == null ? "null" : "" + isStatic) + ")";
		case 18:
			let isStatic1 = identType.isStatic;
			return "Method(" + (isStatic1 == null ? "null" : "" + isStatic1) + ")";
		case 21:
			let fields = identType.fields;
			return "TypedefField(" + Std.string(fields) + ")";
		case 22:
			let fieldNames = identType.fieldNames;
			return "StructureField(" + Std.string(fieldNames) + ")";
		case 27:
			let params = identType.params;
			let result = new Array(params.length);
			let _g = 0;
			let _g1 = params.length;
			while(_g < _g1) {
				let i = _g++;
				result[i] = "\"" + params[i].name + "\"";
			}
			return "EnumField(" + Std.string(result) + ")";
		case 28:
			let switchIdentifier = identType.switchIdentifier;
			return "CaseLabel(" + switchIdentifier.name + ")";
		case 33:
			let scopeStart = identType.scopeStart;
			let scopeEnd = identType.scopeEnd;
			let scopeType = identType.scopeType;
			return "ScopedLocal(" + scopeStart + " - " + scopeEnd + ", " + refactor_PrintHelper.scopeTypeToString(scopeType) + ")";
		default:
			return "" + Std.string(identType);
		}
	}
	static scopeTypeToString(scopeType) {
		switch(scopeType._hx_index) {
		case 0:
			let params = scopeType.params;
			let result = new Array(params.length);
			let _g = 0;
			let _g1 = params.length;
			while(_g < _g1) {
				let i = _g++;
				result[i] = "\"" + params[i].name + "\"";
			}
			return "Parameter(" + Std.string(result) + ")";
		case 3:
			let loopIdentifiers = scopeType.loopIdentifiers;
			let result1 = new Array(loopIdentifiers.length);
			let _g2 = 0;
			let _g3 = loopIdentifiers.length;
			while(_g2 < _g3) {
				let i = _g2++;
				result1[i] = "\"" + loopIdentifiers[i].name + "\"";
			}
			return "ForLoop(" + Std.string(result1) + ")";
		default:
			return "" + Std.string(scopeType);
		}
	}
	static printTypeHint(hintType) {
		switch(hintType._hx_index) {
		case 0:
			let type = hintType.type;
			let params = hintType.typeParams;
			let tmp = "KnownType(" + type.name.name + ", ";
			let result = new Array(params.length);
			let _g = 0;
			let _g1 = params.length;
			while(_g < _g1) {
				let i = _g++;
				result[i] = params[i].name;
			}
			return tmp + Std.string(result) + ")";
		case 1:
			let name = hintType.name;
			let params1 = hintType.typeParams;
			let tmp1 = "UnknownType(" + name + ", ";
			let result1 = new Array(params1.length);
			let _g2 = 0;
			let _g3 = params1.length;
			while(_g2 < _g3) {
				let i = _g2++;
				result1[i] = params1[i].name;
			}
			return tmp1 + Std.string(result1) + ")";
		}
	}
	static printRefactorResult(result) {
		switch(result._hx_index) {
		case 0:
			return "nothing to do";
		case 1:
			return "could not find identifier to rename";
		case 2:
			let name = result.name;
			return "renaming not supported for " + name;
		case 3:
			return "dry run - no changes were made";
		case 4:
			return "rename successful";
		}
	}
}
refactor_PrintHelper.__name__ = true;
class refactor_Refactor {
	static canRename(context) {
		let file = context.fileList.getFile(context.what.fileName);
		if(file == null) {
			return Promise.reject(refactor_PrintHelper.printRefactorResult(refactor_RefactorResult.NotFound));
		}
		let identifier = file.getIdentifier(context.what.pos);
		if(identifier == null) {
			return Promise.reject(refactor_PrintHelper.printRefactorResult(refactor_RefactorResult.NotFound));
		}
		let _g = identifier.type;
		switch(_g._hx_index) {
		case 17:
			let _g1 = _g.isStatic;
			return Promise.resolve({ name : identifier.name, pos : identifier.pos});
		case 18:
			let _g2 = _g.isStatic;
			return Promise.resolve({ name : identifier.name, pos : identifier.pos});
		case 1:case 3:case 11:case 12:case 13:case 14:case 15:case 19:case 20:case 26:case 34:
			return Promise.reject(refactor_PrintHelper.printRefactorResult(refactor_RefactorResult.Unsupported(identifier.toString())));
		case 21:
			let _g3 = _g.fields;
			return Promise.resolve({ name : identifier.name, pos : identifier.pos});
		case 22:
			let _g4 = _g.fieldNames;
			return Promise.resolve({ name : identifier.name, pos : identifier.pos});
		case 0:case 2:case 4:case 5:case 6:case 7:case 8:case 9:case 10:case 16:case 23:case 24:case 25:
			return Promise.resolve({ name : identifier.name, pos : identifier.pos});
		case 27:
			let _g5 = _g.params;
			return Promise.resolve({ name : identifier.name, pos : identifier.pos});
		case 28:
			let _g6 = _g.switchIdentifier;
			return Promise.reject(refactor_PrintHelper.printRefactorResult(refactor_RefactorResult.Unsupported(identifier.toString())));
		case 29:
			if(_g.isNew) {
				return Promise.reject(refactor_PrintHelper.printRefactorResult(refactor_RefactorResult.Unsupported(identifier.toString())));
			} else {
				let candidate = refactor_Refactor.findActualWhat(context,file,identifier);
				if(candidate == null) {
					return Promise.reject(refactor_PrintHelper.printRefactorResult(refactor_RefactorResult.Unsupported(identifier.toString())));
				}
				if(identifier.name.startsWith(candidate.name)) {
					let pos = { fileName : identifier.pos.fileName, start : identifier.pos.start, end : identifier.pos.start + context.what.toName.length};
					return Promise.resolve({ name : candidate.name, pos : pos});
				}
				if(identifier.name.endsWith(candidate.name)) {
					let pos = { fileName : identifier.pos.fileName, start : identifier.pos.end - context.what.toName.length, end : identifier.pos.end};
					return Promise.resolve({ name : candidate.name, pos : pos});
				}
				return Promise.reject(refactor_PrintHelper.printRefactorResult(refactor_RefactorResult.Unsupported(identifier.toString())));
			}
			break;
		case 30:
			let _g7 = _g.posClosing;
			let candidate = refactor_Refactor.findActualWhat(context,file,identifier);
			if(candidate == null) {
				return Promise.reject(refactor_PrintHelper.printRefactorResult(refactor_RefactorResult.Unsupported(identifier.toString())));
			}
			if(identifier.name.startsWith(candidate.name)) {
				let pos = { fileName : identifier.pos.fileName, start : identifier.pos.start, end : identifier.pos.start + context.what.toName.length};
				return Promise.resolve({ name : candidate.name, pos : pos});
			}
			if(identifier.name.endsWith(candidate.name)) {
				let pos = { fileName : identifier.pos.fileName, start : identifier.pos.end - context.what.toName.length, end : identifier.pos.end};
				return Promise.resolve({ name : candidate.name, pos : pos});
			}
			return Promise.reject(refactor_PrintHelper.printRefactorResult(refactor_RefactorResult.Unsupported(identifier.toString())));
		case 31:case 32:
			let candidate1 = refactor_Refactor.findActualWhat(context,file,identifier);
			if(candidate1 == null) {
				return Promise.reject(refactor_PrintHelper.printRefactorResult(refactor_RefactorResult.Unsupported(identifier.toString())));
			}
			if(identifier.name.startsWith(candidate1.name)) {
				let pos = { fileName : identifier.pos.fileName, start : identifier.pos.start, end : identifier.pos.start + context.what.toName.length};
				return Promise.resolve({ name : candidate1.name, pos : pos});
			}
			if(identifier.name.endsWith(candidate1.name)) {
				let pos = { fileName : identifier.pos.fileName, start : identifier.pos.end - context.what.toName.length, end : identifier.pos.end};
				return Promise.resolve({ name : candidate1.name, pos : pos});
			}
			return Promise.reject(refactor_PrintHelper.printRefactorResult(refactor_RefactorResult.Unsupported(identifier.toString())));
		case 33:
			let _g8 = _g.scopeStart;
			let _g9 = _g.scopeEnd;
			let _g10 = _g.scopeType;
			return Promise.resolve({ name : identifier.name, pos : identifier.pos});
		}
	}
	static rename(context) {
		let file = context.fileList.getFile(context.what.fileName);
		if(file == null) {
			return Promise.reject(refactor_PrintHelper.printRefactorResult(refactor_RefactorResult.NotFound));
		}
		let identifier = file.getIdentifier(context.what.pos);
		if(identifier == null) {
			return Promise.reject(refactor_PrintHelper.printRefactorResult(refactor_RefactorResult.NotFound));
		}
		if(identifier.name == context.what.toName) {
			return Promise.reject(refactor_PrintHelper.printRefactorResult(refactor_RefactorResult.NotFound));
		}
		let _g = identifier.type;
		switch(_g._hx_index) {
		case 0:
			context.verboseLog("rename package name \"" + identifier.name + "\" to \"" + context.what.toName + "\"",{ fileName : "src/refactor/Refactor.hx", lineNumber : 72, className : "refactor.Refactor", methodName : "rename"});
			return refactor_rename_RenamePackage.refactorPackageName(context,file,identifier);
		case 2:
			context.verboseLog("rename import alias \"" + identifier.name + "\" to \"" + context.what.toName + "\"",{ fileName : "src/refactor/Refactor.hx", lineNumber : 77, className : "refactor.Refactor", methodName : "rename"});
			return refactor_rename_RenameImportAlias.refactorImportAlias(context,file,identifier);
		case 1:case 3:
			return Promise.reject(refactor_PrintHelper.printRefactorResult(refactor_RefactorResult.Unsupported(identifier.toString())));
		case 4:case 5:case 6:case 7:case 8:
			context.verboseLog("rename type name \"" + identifier.name + "\" to \"" + context.what.toName + "\"",{ fileName : "src/refactor/Refactor.hx", lineNumber : 80, className : "refactor.Refactor", methodName : "rename"});
			return refactor_rename_RenameTypeName.refactorTypeName(context,file,identifier);
		case 9:case 10:
			context.verboseLog("rename module level static \"" + identifier.name + "\" to \"" + context.what.toName + "\"",{ fileName : "src/refactor/Refactor.hx", lineNumber : 83, className : "refactor.Refactor", methodName : "rename"});
			return refactor_rename_RenameModuleLevelStatic.refactorModuleLevelStatic(context,file,identifier);
		case 16:
			context.verboseLog("rename property \"" + identifier.name + "\" to \"" + context.what.toName + "\"",{ fileName : "src/refactor/Refactor.hx", lineNumber : 88, className : "refactor.Refactor", methodName : "rename"});
			return refactor_rename_RenameField.refactorField(context,file,identifier,false);
		case 17:
			let isStatic = _g.isStatic;
			context.verboseLog("rename field \"" + identifier.name + "\" to \"" + context.what.toName + "\"",{ fileName : "src/refactor/Refactor.hx", lineNumber : 91, className : "refactor.Refactor", methodName : "rename"});
			return refactor_rename_RenameField.refactorField(context,file,identifier,isStatic);
		case 18:
			let isStatic1 = _g.isStatic;
			context.verboseLog("rename class method \"" + identifier.name + "\" to \"" + context.what.toName + "\"",{ fileName : "src/refactor/Refactor.hx", lineNumber : 94, className : "refactor.Refactor", methodName : "rename"});
			return refactor_rename_RenameField.refactorField(context,file,identifier,isStatic1);
		case 19:
			return Promise.reject(refactor_PrintHelper.printRefactorResult(refactor_RefactorResult.Unsupported(identifier.toString())));
		case 20:
			return Promise.reject(refactor_PrintHelper.printRefactorResult(refactor_RefactorResult.Unsupported(identifier.toString())));
		case 21:
			let fields = _g.fields;
			return refactor_rename_RenameAnonStructField.refactorAnonStructField(context,file,identifier,fields);
		case 22:
			let fields1 = _g.fieldNames;
			return refactor_rename_RenameAnonStructField.refactorStructureField(context,file,identifier,fields1);
		case 23:case 24:case 25:
			context.verboseLog("rename interface field \"" + identifier.name + "\" to \"" + context.what.toName + "\"",{ fileName : "src/refactor/Refactor.hx", lineNumber : 105, className : "refactor.Refactor", methodName : "rename"});
			return refactor_rename_RenameField.refactorField(context,file,identifier,false);
		case 27:
			let _g1 = _g.params;
			context.verboseLog("rename enum field \"" + identifier.name + "\" to \"" + context.what.toName + "\"",{ fileName : "src/refactor/Refactor.hx", lineNumber : 108, className : "refactor.Refactor", methodName : "rename"});
			return refactor_rename_RenameEnumField.refactorEnumField(context,file,identifier);
		case 28:
			let _g2 = _g.switchIdentifier;
			return Promise.reject(refactor_PrintHelper.printRefactorResult(refactor_RefactorResult.Unsupported(identifier.toString())));
		case 29:
			if(_g.isNew) {
				return Promise.reject(refactor_PrintHelper.printRefactorResult(refactor_RefactorResult.Unsupported(identifier.toString())));
			} else {
				context.verboseLog("rename \"" + identifier.name + "\" at call/access location - trying to find definition",{ fileName : "src/refactor/Refactor.hx", lineNumber : 113, className : "refactor.Refactor", methodName : "rename"});
				let candidate = refactor_Refactor.findActualWhat(context,file,identifier);
				if(candidate == null) {
					return Promise.reject(refactor_PrintHelper.printRefactorResult(refactor_RefactorResult.Unsupported(identifier.toString())));
				}
				context.what.pos = candidate.pos.start;
				return refactor_Refactor.rename(context);
			}
			break;
		case 30:
			let _g3 = _g.posClosing;
			context.verboseLog("rename \"" + identifier.name + "\" at call/access location - trying to find definition",{ fileName : "src/refactor/Refactor.hx", lineNumber : 113, className : "refactor.Refactor", methodName : "rename"});
			let candidate = refactor_Refactor.findActualWhat(context,file,identifier);
			if(candidate == null) {
				return Promise.reject(refactor_PrintHelper.printRefactorResult(refactor_RefactorResult.Unsupported(identifier.toString())));
			}
			context.what.pos = candidate.pos.start;
			return refactor_Refactor.rename(context);
		case 31:case 32:
			context.verboseLog("rename \"" + identifier.name + "\" at call/access location - trying to find definition",{ fileName : "src/refactor/Refactor.hx", lineNumber : 113, className : "refactor.Refactor", methodName : "rename"});
			let candidate1 = refactor_Refactor.findActualWhat(context,file,identifier);
			if(candidate1 == null) {
				return Promise.reject(refactor_PrintHelper.printRefactorResult(refactor_RefactorResult.Unsupported(identifier.toString())));
			}
			context.what.pos = candidate1.pos.start;
			return refactor_Refactor.rename(context);
		case 33:
			let scopeStart = _g.scopeStart;
			let scopeEnd = _g.scopeEnd;
			let type = _g.scopeType;
			let tmp = "rename scoped local \"" + identifier.name + "\" (" + refactor_PrintHelper.scopeTypeToString(type) + ") to \"" + context.what.toName + "\"";
			context.verboseLog(tmp,{ fileName : "src/refactor/Refactor.hx", lineNumber : 123, className : "refactor.Refactor", methodName : "rename"});
			return refactor_rename_RenameScopedLocal.refactorScopedLocal(context,file,identifier,scopeStart,scopeEnd);
		case 11:case 12:case 13:case 14:case 15:case 26:case 34:
			return Promise.reject(refactor_PrintHelper.printRefactorResult(refactor_RefactorResult.Unsupported(identifier.toString())));
		}
	}
	static findActualWhat(context,file,identifier) {
		let parts = identifier.name.split(".");
		if(parts.length <= 0) {
			return null;
		}
		let firstPart = parts.shift();
		let onlyFields = false;
		let offset = 0;
		if(firstPart == "this") {
			firstPart = parts.shift();
			onlyFields = true;
			offset = 5;
		}
		if(context.what.pos > identifier.pos.start + firstPart.length + offset) {
			return null;
		}
		let allUses = file.findAllIdentifiers(function(i) {
			return i.name == firstPart;
		});
		let candidate = null;
		let _g = 0;
		while(_g < allUses.length) {
			let use = allUses[_g];
			++_g;
			let _g1 = use.type;
			switch(_g1._hx_index) {
			case 16:
				if(identifier.defineType.name != use.defineType.name) {
					continue;
				}
				if(candidate == null) {
					candidate = use;
				}
				break;
			case 17:
				let _g2 = _g1.isStatic;
				if(identifier.defineType.name != use.defineType.name) {
					continue;
				}
				if(candidate == null) {
					candidate = use;
				}
				break;
			case 18:
				let _g3 = _g1.isStatic;
				if(identifier.defineType.name != use.defineType.name) {
					continue;
				}
				if(candidate == null) {
					candidate = use;
				}
				break;
			case 33:
				let _g4 = _g1.scopeStart;
				let _g5 = _g1.scopeEnd;
				let _g6 = _g1.scopeType;
				if(_g6._hx_index == 3) {
					let _g = _g6.loopIdentifiers;
					let scopeEnd = _g5;
					let scopeStart = _g4;
					if(!onlyFields) {
						if(scopeStart < identifier.pos.start && identifier.pos.start < scopeEnd) {
							candidate = use;
						}
					} else {
						let scopeEnd = _g5;
						let scopeStart = _g4;
						if(!onlyFields) {
							if(scopeStart < identifier.pos.start && identifier.pos.start < scopeEnd) {
								candidate = use;
							}
						}
					}
				} else {
					let scopeEnd = _g5;
					let scopeStart = _g4;
					if(!onlyFields) {
						if(scopeStart < identifier.pos.start && identifier.pos.start < scopeEnd) {
							candidate = use;
						}
					}
				}
				break;
			default:
			}
		}
		return candidate;
	}
}
refactor_Refactor.__name__ = true;
var refactor_RefactorResult = $hxEnums["refactor.RefactorResult"] = { __ename__:true,__constructs__:null
	,NoChange: {_hx_name:"NoChange",_hx_index:0,__enum__:"refactor.RefactorResult",toString:$estr}
	,NotFound: {_hx_name:"NotFound",_hx_index:1,__enum__:"refactor.RefactorResult",toString:$estr}
	,Unsupported: ($_=function(name) { return {_hx_index:2,name:name,__enum__:"refactor.RefactorResult",toString:$estr}; },$_._hx_name="Unsupported",$_.__params__ = ["name"],$_)
	,DryRun: {_hx_name:"DryRun",_hx_index:3,__enum__:"refactor.RefactorResult",toString:$estr}
	,Done: {_hx_name:"Done",_hx_index:4,__enum__:"refactor.RefactorResult",toString:$estr}
};
refactor_RefactorResult.__constructs__ = [refactor_RefactorResult.NoChange,refactor_RefactorResult.NotFound,refactor_RefactorResult.Unsupported,refactor_RefactorResult.DryRun,refactor_RefactorResult.Done];
class refactor_discover_File {
	constructor(name) {
		this.name = name;
		let stat = js_node_Fs.statSync(name);
		this.fileDate = stat.mtime.getTime();
		this.fileSize = stat.size;
	}
	init(packageIdent,imports,types,posForImport) {
		this.packageIdentifier = packageIdent;
		this.importList = imports;
		this.typeList = types;
		this.importInsertPos = posForImport;
	}
	getPackage() {
		if(this.packageIdentifier != null) {
			return this.packageIdentifier.name;
		}
		return "";
	}
	importsModule(packName,moduleName,typeName) {
		if(packName.length <= 0) {
			return refactor_discover_ImportStatus.Global;
		}
		let fullModule = "" + packName + "." + moduleName;
		let fullSubModule = null;
		let isMainModule = true;
		if(moduleName != typeName) {
			fullSubModule = "" + fullModule + "." + typeName;
			isMainModule = false;
		}
		let _g = 0;
		let _g1 = this.importList;
		while(_g < _g1.length) {
			let importEntry = _g1[_g];
			++_g;
			if(importEntry.moduleName.name == fullModule) {
				if(importEntry.alias != null) {
					return refactor_discover_ImportStatus.ImportedWithAlias(importEntry.alias.name);
				}
				return refactor_discover_ImportStatus.Imported;
			}
			if(importEntry.moduleName.name == fullSubModule) {
				if(importEntry.alias != null) {
					return refactor_discover_ImportStatus.ImportedWithAlias(importEntry.alias.name);
				}
				return refactor_discover_ImportStatus.Imported;
			}
			if(isMainModule && importEntry.starImport) {
				if(importEntry.moduleName.name == packName) {
					return refactor_discover_ImportStatus.StarImported;
				}
			}
		}
		if(this.importHxFile == null) {
			if(packName == this.getPackage()) {
				return refactor_discover_ImportStatus.SamePackage;
			}
			if(packName == this.getPackage()) {
				return refactor_discover_ImportStatus.SamePackage;
			}
			return refactor_discover_ImportStatus.None;
		}
		let result = this.importHxFile.importsModule(packName,moduleName,typeName);
		if(result == refactor_discover_ImportStatus.None) {
			if(packName == this.getPackage()) {
				return refactor_discover_ImportStatus.SamePackage;
			}
		}
		return result;
	}
	getMainModulName() {
		let path = new haxe_io_Path(this.name);
		return path.file;
	}
	getType(typeName) {
		let _g = 0;
		let _g1 = this.typeList;
		while(_g < _g1.length) {
			let type = _g1[_g];
			++_g;
			if(type.name.name == typeName) {
				return type;
			}
		}
		return null;
	}
	getIdentifier(pos) {
		if(this.packageIdentifier != null && this.packageIdentifier.containsPos(pos)) {
			return this.packageIdentifier;
		}
		let _g = 0;
		let _g1 = this.importList;
		while(_g < _g1.length) {
			let imp = _g1[_g];
			++_g;
			if(imp.alias != null && imp.alias.containsPos(pos)) {
				return imp.alias;
			}
			if(imp.moduleName.containsPos(pos)) {
				return imp.moduleName;
			}
		}
		let _g2 = 0;
		let _g3 = this.typeList;
		while(_g2 < _g3.length) {
			let type = _g3[_g2];
			++_g2;
			let identifier = type.findIdentifier(pos);
			if(identifier != null) {
				return identifier;
			}
		}
		return null;
	}
	findAllIdentifiers(matcher) {
		let results = [];
		if(this.packageIdentifier != null && matcher(this.packageIdentifier)) {
			results.push(this.packageIdentifier);
		}
		let _g = 0;
		let _g1 = this.importList;
		while(_g < _g1.length) {
			let imp = _g1[_g];
			++_g;
			if(imp.alias != null && matcher(imp.alias)) {
				results.push(imp.alias);
			}
			if(matcher(imp.moduleName)) {
				results.push(imp.moduleName);
			}
		}
		let _g2 = 0;
		let _g3 = this.typeList;
		while(_g2 < _g3.length) {
			let type = _g3[_g2];
			++_g2;
			results = results.concat(type.findAllIdentifiers(matcher));
		}
		results.sort(refactor_discover_Identifier.sortIdentifier);
		return results;
	}
}
refactor_discover_File.__name__ = true;
var refactor_discover_ImportStatus = $hxEnums["refactor.discover.ImportStatus"] = { __ename__:true,__constructs__:null
	,None: {_hx_name:"None",_hx_index:0,__enum__:"refactor.discover.ImportStatus",toString:$estr}
	,Global: {_hx_name:"Global",_hx_index:1,__enum__:"refactor.discover.ImportStatus",toString:$estr}
	,SamePackage: {_hx_name:"SamePackage",_hx_index:2,__enum__:"refactor.discover.ImportStatus",toString:$estr}
	,Imported: {_hx_name:"Imported",_hx_index:3,__enum__:"refactor.discover.ImportStatus",toString:$estr}
	,ImportedWithAlias: ($_=function(alias) { return {_hx_index:4,alias:alias,__enum__:"refactor.discover.ImportStatus",toString:$estr}; },$_._hx_name="ImportedWithAlias",$_.__params__ = ["alias"],$_)
	,StarImported: {_hx_name:"StarImported",_hx_index:5,__enum__:"refactor.discover.ImportStatus",toString:$estr}
};
refactor_discover_ImportStatus.__constructs__ = [refactor_discover_ImportStatus.None,refactor_discover_ImportStatus.Global,refactor_discover_ImportStatus.SamePackage,refactor_discover_ImportStatus.Imported,refactor_discover_ImportStatus.ImportedWithAlias,refactor_discover_ImportStatus.StarImported];
class refactor_discover_FileList {
	constructor() {
		this.files = [];
	}
	addFile(file) {
		this.files.push(file);
	}
	getFile(fileName) {
		let _g = 0;
		let _g1 = this.files;
		while(_g < _g1.length) {
			let file = _g1[_g];
			++_g;
			if(file.name == fileName) {
				return file;
			}
		}
		return null;
	}
}
refactor_discover_FileList.__name__ = true;
class refactor_discover_Identifier {
	constructor(type,name,pos,nameMap,file,defineType) {
		this.type = type;
		this.name = name;
		this.pos = pos;
		this.file = file;
		this.defineType = defineType;
		this.parent = null;
		this.edited = false;
		if(defineType != null) {
			defineType.addIdentifier(this);
		}
		nameMap.addIdentifier(this);
	}
	reset() {
		this.edited = false;
	}
	addUse(identifier) {
		if(identifier == null) {
			return;
		}
		if(this.uses == null) {
			this.uses = [];
		}
		this.uses.push(identifier);
		identifier.parent = this;
	}
	containsPos(offset) {
		if(this.pos.start <= offset) {
			return this.pos.end >= offset;
		} else {
			return false;
		}
	}
	findIdentifier(offset) {
		if(this.containsPos(offset)) {
			return this;
		}
		if(this.uses == null) {
			return null;
		}
		let _g = 0;
		let _g1 = this.uses;
		while(_g < _g1.length) {
			let use = _g1[_g];
			++_g;
			let identifier = use.findIdentifier(offset);
			if(identifier != null) {
				return identifier;
			}
		}
		return null;
	}
	findAllIdentifiers(matcher) {
		let results = [];
		if(matcher(this)) {
			results.push(this);
		}
		if(this.uses == null) {
			return results;
		}
		let _g = 0;
		let _g1 = this.uses;
		while(_g < _g1.length) {
			let use = _g1[_g];
			++_g;
			results = results.concat(use.findAllIdentifiers(matcher));
		}
		results.sort(refactor_discover_Identifier.sortIdentifier);
		return results;
	}
	getTypeHint() {
		if(this.uses == null) {
			return null;
		}
		let _g = 0;
		let _g1 = this.uses;
		while(_g < _g1.length) {
			let use = _g1[_g];
			++_g;
			if(use.type._hx_index == 26) {
				return use;
			}
		}
		return null;
	}
	toString() {
		return "" + this.name + " " + this.pos.fileName + "@" + this.pos.start + "-" + this.pos.end + " (" + refactor_PrintHelper.typeToString(this.type) + ")";
	}
	static sortIdentifier(a,b) {
		if(a.pos.fileName < b.pos.fileName) {
			return -1;
		}
		if(a.pos.fileName > b.pos.fileName) {
			return 1;
		}
		if(a.pos.start < b.pos.start) {
			return -1;
		}
		if(a.pos.start > b.pos.start) {
			return 1;
		}
		return 0;
	}
}
refactor_discover_Identifier.__name__ = true;
var refactor_discover_IdentifierType = $hxEnums["refactor.discover.IdentifierType"] = { __ename__:true,__constructs__:null
	,PackageName: {_hx_name:"PackageName",_hx_index:0,__enum__:"refactor.discover.IdentifierType",toString:$estr}
	,ImportModul: {_hx_name:"ImportModul",_hx_index:1,__enum__:"refactor.discover.IdentifierType",toString:$estr}
	,ImportAlias: {_hx_name:"ImportAlias",_hx_index:2,__enum__:"refactor.discover.IdentifierType",toString:$estr}
	,UsingModul: {_hx_name:"UsingModul",_hx_index:3,__enum__:"refactor.discover.IdentifierType",toString:$estr}
	,Abstract: {_hx_name:"Abstract",_hx_index:4,__enum__:"refactor.discover.IdentifierType",toString:$estr}
	,Class: {_hx_name:"Class",_hx_index:5,__enum__:"refactor.discover.IdentifierType",toString:$estr}
	,Enum: {_hx_name:"Enum",_hx_index:6,__enum__:"refactor.discover.IdentifierType",toString:$estr}
	,Interface: {_hx_name:"Interface",_hx_index:7,__enum__:"refactor.discover.IdentifierType",toString:$estr}
	,Typedef: {_hx_name:"Typedef",_hx_index:8,__enum__:"refactor.discover.IdentifierType",toString:$estr}
	,ModuleLevelStaticVar: {_hx_name:"ModuleLevelStaticVar",_hx_index:9,__enum__:"refactor.discover.IdentifierType",toString:$estr}
	,ModuleLevelStaticMethod: {_hx_name:"ModuleLevelStaticMethod",_hx_index:10,__enum__:"refactor.discover.IdentifierType",toString:$estr}
	,Extends: {_hx_name:"Extends",_hx_index:11,__enum__:"refactor.discover.IdentifierType",toString:$estr}
	,Implements: {_hx_name:"Implements",_hx_index:12,__enum__:"refactor.discover.IdentifierType",toString:$estr}
	,AbstractOver: {_hx_name:"AbstractOver",_hx_index:13,__enum__:"refactor.discover.IdentifierType",toString:$estr}
	,AbstractFrom: {_hx_name:"AbstractFrom",_hx_index:14,__enum__:"refactor.discover.IdentifierType",toString:$estr}
	,AbstractTo: {_hx_name:"AbstractTo",_hx_index:15,__enum__:"refactor.discover.IdentifierType",toString:$estr}
	,Property: {_hx_name:"Property",_hx_index:16,__enum__:"refactor.discover.IdentifierType",toString:$estr}
	,FieldVar: ($_=function(isStatic) { return {_hx_index:17,isStatic:isStatic,__enum__:"refactor.discover.IdentifierType",toString:$estr}; },$_._hx_name="FieldVar",$_.__params__ = ["isStatic"],$_)
	,Method: ($_=function(isStatic) { return {_hx_index:18,isStatic:isStatic,__enum__:"refactor.discover.IdentifierType",toString:$estr}; },$_._hx_name="Method",$_.__params__ = ["isStatic"],$_)
	,TypedParameter: {_hx_name:"TypedParameter",_hx_index:19,__enum__:"refactor.discover.IdentifierType",toString:$estr}
	,TypedefBase: {_hx_name:"TypedefBase",_hx_index:20,__enum__:"refactor.discover.IdentifierType",toString:$estr}
	,TypedefField: ($_=function(fields) { return {_hx_index:21,fields:fields,__enum__:"refactor.discover.IdentifierType",toString:$estr}; },$_._hx_name="TypedefField",$_.__params__ = ["fields"],$_)
	,StructureField: ($_=function(fieldNames) { return {_hx_index:22,fieldNames:fieldNames,__enum__:"refactor.discover.IdentifierType",toString:$estr}; },$_._hx_name="StructureField",$_.__params__ = ["fieldNames"],$_)
	,InterfaceProperty: {_hx_name:"InterfaceProperty",_hx_index:23,__enum__:"refactor.discover.IdentifierType",toString:$estr}
	,InterfaceVar: {_hx_name:"InterfaceVar",_hx_index:24,__enum__:"refactor.discover.IdentifierType",toString:$estr}
	,InterfaceMethod: {_hx_name:"InterfaceMethod",_hx_index:25,__enum__:"refactor.discover.IdentifierType",toString:$estr}
	,TypeHint: {_hx_name:"TypeHint",_hx_index:26,__enum__:"refactor.discover.IdentifierType",toString:$estr}
	,EnumField: ($_=function(params) { return {_hx_index:27,params:params,__enum__:"refactor.discover.IdentifierType",toString:$estr}; },$_._hx_name="EnumField",$_.__params__ = ["params"],$_)
	,CaseLabel: ($_=function(switchIdentifier) { return {_hx_index:28,switchIdentifier:switchIdentifier,__enum__:"refactor.discover.IdentifierType",toString:$estr}; },$_._hx_name="CaseLabel",$_.__params__ = ["switchIdentifier"],$_)
	,Call: ($_=function(isNew) { return {_hx_index:29,isNew:isNew,__enum__:"refactor.discover.IdentifierType",toString:$estr}; },$_._hx_name="Call",$_.__params__ = ["isNew"],$_)
	,ArrayAccess: ($_=function(posClosing) { return {_hx_index:30,posClosing:posClosing,__enum__:"refactor.discover.IdentifierType",toString:$estr}; },$_._hx_name="ArrayAccess",$_.__params__ = ["posClosing"],$_)
	,Access: {_hx_name:"Access",_hx_index:31,__enum__:"refactor.discover.IdentifierType",toString:$estr}
	,ForIterator: {_hx_name:"ForIterator",_hx_index:32,__enum__:"refactor.discover.IdentifierType",toString:$estr}
	,ScopedLocal: ($_=function(scopeStart,scopeEnd,scopeType) { return {_hx_index:33,scopeStart:scopeStart,scopeEnd:scopeEnd,scopeType:scopeType,__enum__:"refactor.discover.IdentifierType",toString:$estr}; },$_._hx_name="ScopedLocal",$_.__params__ = ["scopeStart","scopeEnd","scopeType"],$_)
	,StringConst: {_hx_name:"StringConst",_hx_index:34,__enum__:"refactor.discover.IdentifierType",toString:$estr}
};
refactor_discover_IdentifierType.__constructs__ = [refactor_discover_IdentifierType.PackageName,refactor_discover_IdentifierType.ImportModul,refactor_discover_IdentifierType.ImportAlias,refactor_discover_IdentifierType.UsingModul,refactor_discover_IdentifierType.Abstract,refactor_discover_IdentifierType.Class,refactor_discover_IdentifierType.Enum,refactor_discover_IdentifierType.Interface,refactor_discover_IdentifierType.Typedef,refactor_discover_IdentifierType.ModuleLevelStaticVar,refactor_discover_IdentifierType.ModuleLevelStaticMethod,refactor_discover_IdentifierType.Extends,refactor_discover_IdentifierType.Implements,refactor_discover_IdentifierType.AbstractOver,refactor_discover_IdentifierType.AbstractFrom,refactor_discover_IdentifierType.AbstractTo,refactor_discover_IdentifierType.Property,refactor_discover_IdentifierType.FieldVar,refactor_discover_IdentifierType.Method,refactor_discover_IdentifierType.TypedParameter,refactor_discover_IdentifierType.TypedefBase,refactor_discover_IdentifierType.TypedefField,refactor_discover_IdentifierType.StructureField,refactor_discover_IdentifierType.InterfaceProperty,refactor_discover_IdentifierType.InterfaceVar,refactor_discover_IdentifierType.InterfaceMethod,refactor_discover_IdentifierType.TypeHint,refactor_discover_IdentifierType.EnumField,refactor_discover_IdentifierType.CaseLabel,refactor_discover_IdentifierType.Call,refactor_discover_IdentifierType.ArrayAccess,refactor_discover_IdentifierType.Access,refactor_discover_IdentifierType.ForIterator,refactor_discover_IdentifierType.ScopedLocal,refactor_discover_IdentifierType.StringConst];
var refactor_discover_ScopedLocalType = $hxEnums["refactor.discover.ScopedLocalType"] = { __ename__:true,__constructs__:null
	,Parameter: ($_=function(params) { return {_hx_index:0,params:params,__enum__:"refactor.discover.ScopedLocalType",toString:$estr}; },$_._hx_name="Parameter",$_.__params__ = ["params"],$_)
	,Var: {_hx_name:"Var",_hx_index:1,__enum__:"refactor.discover.ScopedLocalType",toString:$estr}
	,CaseCapture: {_hx_name:"CaseCapture",_hx_index:2,__enum__:"refactor.discover.ScopedLocalType",toString:$estr}
	,ForLoop: ($_=function(loopIdentifiers) { return {_hx_index:3,loopIdentifiers:loopIdentifiers,__enum__:"refactor.discover.ScopedLocalType",toString:$estr}; },$_._hx_name="ForLoop",$_.__params__ = ["loopIdentifiers"],$_)
};
refactor_discover_ScopedLocalType.__constructs__ = [refactor_discover_ScopedLocalType.Parameter,refactor_discover_ScopedLocalType.Var,refactor_discover_ScopedLocalType.CaseCapture,refactor_discover_ScopedLocalType.ForLoop];
var refactor_discover_TypedefFieldType = $hxEnums["refactor.discover.TypedefFieldType"] = { __ename__:true,__constructs__:null
	,Required: ($_=function(identifier) { return {_hx_index:0,identifier:identifier,__enum__:"refactor.discover.TypedefFieldType",toString:$estr}; },$_._hx_name="Required",$_.__params__ = ["identifier"],$_)
	,Optional: ($_=function(identifier) { return {_hx_index:1,identifier:identifier,__enum__:"refactor.discover.TypedefFieldType",toString:$estr}; },$_._hx_name="Optional",$_.__params__ = ["identifier"],$_)
};
refactor_discover_TypedefFieldType.__constructs__ = [refactor_discover_TypedefFieldType.Required,refactor_discover_TypedefFieldType.Optional];
class refactor_discover_NameMap {
	constructor() {
		this.names = new haxe_ds_StringMap();
		this.parts = new haxe_ds_StringMap();
	}
	getIdentifiers(name) {
		let results = this.names.h[name];
		if(results == null) {
			return [];
		}
		results.sort(refactor_discover_Identifier.sortIdentifier);
		return results;
	}
	addIdentifier(identifier) {
		let addToMap = function(map,key) {
			let list = map.h[key];
			if(list == null) {
				map.h[key] = [identifier];
			} else {
				list.push(identifier);
			}
		};
		identifier.reset();
		addToMap(this.names,identifier.name);
		let nameParts = identifier.name.split(".");
		let _g = 0;
		while(_g < nameParts.length) {
			let part = nameParts[_g];
			++_g;
			addToMap(this.parts,part);
		}
	}
	getStartsWith(prefix) {
		let results = [];
		let h = this.names.h;
		let _g_h = h;
		let _g_keys = Object.keys(h);
		let _g_length = _g_keys.length;
		let _g_current = 0;
		while(_g_current < _g_length) {
			let key = _g_keys[_g_current++];
			let _g_key = key;
			let _g_value = _g_h[key];
			let name = _g_key;
			let list = _g_value;
			if(name.startsWith(prefix)) {
				results = results.concat(list);
			}
		}
		results.sort(refactor_discover_Identifier.sortIdentifier);
		return results;
	}
	matchIdentifierPart(name,unused) {
		let results = this.parts.h[name];
		if(results == null) {
			return [];
		}
		if(unused) {
			let _g = [];
			let _g1 = 0;
			let _g2 = results;
			while(_g1 < _g2.length) {
				let v = _g2[_g1];
				++_g1;
				if(!v.edited) {
					_g.push(v);
				}
			}
			results = _g;
			results.sort(refactor_discover_Identifier.sortIdentifier);
		}
		return results;
	}
}
refactor_discover_NameMap.__name__ = true;
class refactor_discover_TraverseSources {
	static traverseSources(paths,usageContext) {
		let _g = 0;
		while(_g < paths.length) {
			let path = paths[_g];
			++_g;
			let path1 = StringTools.trim(path);
			if(!sys_FileSystem.exists(path1)) {
				continue;
			}
			if(sys_FileSystem.isDirectory(path1)) {
				let _g = [];
				let _g1 = 0;
				let _g2 = js_node_Fs.readdirSync(path1);
				while(_g1 < _g2.length) {
					let file = _g2[_g1];
					++_g1;
					_g.push(haxe_io_Path.join([path1,file]));
				}
				refactor_discover_TraverseSources.traverseSources(_g,usageContext);
			} else if(path1.endsWith(".hx")) {
				usageContext.fileName = path1;
				refactor_discover_TraverseSources.collectIdentifierData(usageContext);
			}
		}
	}
	static collectIdentifierData(usageContext) {
		let content = js_node_Fs.readFileSync(usageContext.fileName,{ encoding : "utf8"});
		usageContext.usageCollector.parseFile(haxe_io_Bytes.ofString(content),usageContext);
	}
}
refactor_discover_TraverseSources.__name__ = true;
class refactor_discover_Type {
	constructor(file) {
		this.file = file;
		this.nameMap = new refactor_discover_NameMap();
		this.uses = [];
	}
	getFullModulName() {
		let modulName = "" + this.file.getMainModulName() + ".";
		if(this.file.getMainModulName() == this.name.name) {
			modulName = "";
		}
		let packageName = this.file.getPackage();
		if(packageName.length <= 0) {
			return modulName + this.name.name;
		}
		return "" + packageName + "." + modulName + this.name.name;
	}
	addIdentifier(identifier) {
		this.nameMap.addIdentifier(identifier);
		this.uses.push(identifier);
	}
	getIdentifiers(search) {
		return this.nameMap.getIdentifiers(search);
	}
	findIdentifier(offset) {
		let identifier = this.name.findIdentifier(offset);
		if(identifier != null) {
			return identifier;
		}
		let _g = 0;
		let _g1 = this.uses;
		while(_g < _g1.length) {
			let use = _g1[_g];
			++_g;
			identifier = use.findIdentifier(offset);
			if(identifier != null) {
				return identifier;
			}
		}
		return null;
	}
	findAllIdentifiers(matcher) {
		let results = [];
		if(matcher(this.name)) {
			results = [this.name];
		}
		let _g = 0;
		let _g1 = this.uses;
		while(_g < _g1.length) {
			let use = _g1[_g];
			++_g;
			if(matcher(use)) {
				results.push(use);
			}
		}
		results.sort(refactor_discover_Identifier.sortIdentifier);
		return results;
	}
	getStartsWith(prefix) {
		return this.nameMap.getStartsWith(prefix);
	}
}
refactor_discover_Type.__name__ = true;
class refactor_discover_TypeList {
	constructor() {
		this.types = [];
	}
	addType(type) {
		this.types.push(type);
	}
	findTypeName(name) {
		let _g = [];
		let _g1 = 0;
		let _g2 = this.types;
		while(_g1 < _g2.length) {
			let v = _g2[_g1];
			++_g1;
			if(v.name.name == name) {
				_g.push(v);
			}
		}
		return _g;
	}
	makeTypeHintType(name) {
		let _g = 0;
		let _g1 = this.types;
		while(_g < _g1.length) {
			let type = _g1[_g];
			++_g;
			if(type.getFullModulName() == name) {
				return refactor_rename_TypeHintType.KnownType(type,[]);
			}
		}
		return null;
	}
}
refactor_discover_TypeList.__name__ = true;
class refactor_discover_UsageCollector {
	constructor() {
	}
	parseFile(content,context) {
		if(this.isCached(context)) {
			return;
		}
		let root = null;
		try {
			let lexer = new haxeparser_HaxeLexer(content,context.fileName);
			let t = lexer.token(haxeparser_HaxeLexer.tok);
			let tokens = [];
			while(t.tok != haxeparser_TokenDef.Eof) {
				tokens.push(t);
				t = lexer.token(haxeparser_HaxeLexer.tok);
			}
			root = tokentree_TokenTreeBuilder.buildTokenTree(tokens,content,tokentree_TokenTreeEntryPoint.TypeLevel);
			this.parseFileWithTokens(root,context);
		} catch( _g ) {
			let _g1 = haxe_Exception.caught(_g);
			let _g2 = _g1.unwrap();
			if(((_g2) instanceof hxparse_ParserError)) {
				let e = _g2;
				throw haxe_Exception.thrown("failed to parse " + context.fileName + " - ParserError: " + Std.string(e) + " (" + Std.string(e.pos) + ")");
			} else if(((_g2) instanceof haxeparser_LexerError)) {
				let e = _g2;
				throw haxe_Exception.thrown("failed to parse " + context.fileName + " - LexerError: " + Std.string(e.msg) + " (" + Std.string(e.pos) + ")");
			} else {
				let e = _g1;
				throw haxe_Exception.thrown("failed to parse " + context.fileName + " - " + e.details());
			}
		}
	}
	parseFileWithTokens(root,context) {
		if(this.isCached(context)) {
			return;
		}
		try {
			let file = new refactor_discover_File(context.fileName);
			context.file = file;
			context.type = null;
			let packageName = this.readPackageName(root,context);
			let imports = this.readImports(root,context);
			file.init(packageName,imports,this.readTypes(root,context),this.findImportInsertPos(root));
			context.fileList.addFile(file);
			if(context.cache != null) {
				context.cache.storeFile(file);
			}
		} catch( _g ) {
			let e = haxe_Exception.caught(_g);
			throw haxe_Exception.thrown("failed to parse " + context.fileName + " - " + e.details());
		}
	}
	isCached(context) {
		if(context.cache != null) {
			let file = context.cache.getFile(context.fileName,context.nameMap);
			if(file == null) {
				return false;
			}
			context.fileList.addFile(file);
			let _g = 0;
			let _g1 = file.typeList;
			while(_g < _g1.length) {
				let type = _g1[_g];
				++_g;
				context.typeList.addType(type);
			}
			return true;
		}
		return false;
	}
	updateImportHx(context) {
		let _g = 0;
		let _g1 = context.fileList.files;
		while(_g < _g1.length) {
			let importHxFile = _g1[_g];
			++_g;
			let importHxPath = new haxe_io_Path(importHxFile.name);
			if(importHxPath.file != "import") {
				continue;
			}
			let importHxFolder = importHxPath.dir;
			let _g2 = 0;
			let _g3 = context.fileList.files;
			while(_g2 < _g3.length) {
				let file = _g3[_g2];
				++_g2;
				if(file.name == importHxFile.name) {
					continue;
				}
				let path = new haxe_io_Path(file.name);
				if(!path.dir.startsWith(importHxFolder)) {
					continue;
				}
				file.importHxFile = importHxFile;
			}
		}
	}
	findImportInsertPos(root) {
		if(!root.hasChildren()) {
			return 0;
		}
		let pos = 0;
		let _g = 0;
		let _g1 = root.children;
		while(_g < _g1.length) {
			let child = _g1[_g];
			++_g;
			let _g2 = child.tok;
			if(_g2._hx_index == 1) {
				switch(_g2.k._hx_index) {
				case 34:
					pos = child.getPos().max + 1;
					break;
				case 13:case 36:
					return child.pos.min;
				default:
					return child.pos.min;
				}
			} else {
				return child.pos.min;
			}
		}
		return pos;
	}
	readPackageName(root,context) {
		let packages = root.filterCallback(function(token,index) {
			let _g = token.tok;
			if(_g._hx_index == 1) {
				if(_g.k._hx_index == 34) {
					return tokentree_FilterResult.FoundSkipSubtree;
				} else {
					return tokentree_FilterResult.SkipSubtree;
				}
			} else {
				return tokentree_FilterResult.SkipSubtree;
			}
		});
		if(packages.length != 1) {
			return null;
		}
		let token = packages[0].getFirstChild();
		return this.makeIdentifier(context,token,refactor_discover_IdentifierType.PackageName,null);
	}
	readImports(root,context) {
		let imports = [];
		let importTokens = root.filterCallback(function(token,index) {
			let _g = token.tok;
			switch(_g._hx_index) {
			case 1:
				switch(_g.k._hx_index) {
				case 13:case 36:
					return tokentree_FilterResult.FoundSkipSubtree;
				default:
					return tokentree_FilterResult.SkipSubtree;
				}
				break;
			case 3:
				let _g1 = _g.s;
				return tokentree_FilterResult.GoDeeper;
			default:
				return tokentree_FilterResult.SkipSubtree;
			}
		});
		let _g = 0;
		while(_g < importTokens.length) {
			let importToken = importTokens[_g];
			++_g;
			imports.push(this.readImport(importToken,context));
		}
		return imports;
	}
	readImport(token,context) {
		let pack = [];
		let alias = null;
		let type;
		let _g = token.tok;
		if(_g._hx_index == 1) {
			switch(_g.k._hx_index) {
			case 13:
				type = refactor_discover_IdentifierType.ImportModul;
				break;
			case 36:
				type = refactor_discover_IdentifierType.UsingModul;
				break;
			default:
				type = null;
			}
		} else {
			type = null;
		}
		if(type == null) {
			return null;
		}
		let starImport = false;
		token = token.getFirstChild();
		let pos = this.makePosition(context.fileName,token);
		_hx_loop1: while(true) {
			let _g = token.tok;
			switch(_g._hx_index) {
			case 1:
				let _g1 = _g.k;
				pack.push(token.toString());
				pos.end = token.pos.max;
				break;
			case 2:
				let _g2 = _g.c;
				if(_g2._hx_index == 3) {
					if(_g2.s == "as") {
						alias = this.makeIdentifier(context,token.getFirstChild(),refactor_discover_IdentifierType.ImportAlias,null);
						break _hx_loop1;
					} else {
						pack.push(token.toString());
						pos.end = token.pos.max;
					}
				} else {
					return null;
				}
				break;
			case 6:
				switch(_g.op._hx_index) {
				case 1:
					starImport = true;
					break;
				case 23:
					alias = this.makeIdentifier(context,token.getFirstChild(),refactor_discover_IdentifierType.ImportAlias,null);
					break _hx_loop1;
				default:
					return null;
				}
				break;
			case 10:
				break _hx_loop1;
			case 11:
				break;
			default:
				return null;
			}
			token = token.getFirstChild();
		}
		let importIdentifier = new refactor_discover_Identifier(type,pack.join("."),pos,context.nameMap,context.file,null);
		if(alias != null) {
			importIdentifier.addUse(alias.parent);
		}
		return { moduleName : importIdentifier, alias : alias, starImport : starImport};
	}
	readTypes(root,context) {
		let typeTokens = root.filterCallback(function(token,index) {
			let _g = token.tok;
			switch(_g._hx_index) {
			case 1:
				switch(_g.k._hx_index) {
				case 0:case 1:case 2:case 26:case 28:case 32:case 40:case 42:
					return tokentree_FilterResult.FoundSkipSubtree;
				default:
					return tokentree_FilterResult.SkipSubtree;
				}
				break;
			case 3:
				let _g1 = _g.s;
				return tokentree_FilterResult.GoDeeper;
			default:
				return tokentree_FilterResult.SkipSubtree;
			}
		});
		let types = [];
		let _g = 0;
		while(_g < typeTokens.length) {
			let typeToken = typeTokens[_g];
			++_g;
			types.push(this.readType(typeToken,context));
		}
		return types;
	}
	readType(token,context) {
		let type;
		let _g = token.tok;
		if(_g._hx_index == 1) {
			switch(_g.k._hx_index) {
			case 0:
				type = refactor_discover_IdentifierType.ModuleLevelStaticMethod;
				break;
			case 1:
				type = refactor_discover_IdentifierType.Class;
				break;
			case 26:
				type = refactor_discover_IdentifierType.Enum;
				break;
			case 28:
				type = refactor_discover_IdentifierType.Interface;
				break;
			case 32:
				type = refactor_discover_IdentifierType.Typedef;
				break;
			case 40:
				type = refactor_discover_IdentifierType.Abstract;
				break;
			case 2:case 42:
				type = refactor_discover_IdentifierType.ModuleLevelStaticVar;
				break;
			default:
				type = null;
			}
		} else {
			type = null;
		}
		if(type == null) {
			return null;
		}
		let nameToken = token.getFirstChild();
		let newType = new refactor_discover_Type(context.file);
		context.type = newType;
		let identifier = this.makeIdentifier(context,nameToken,type,null);
		newType.name = identifier;
		context.typeList.addType(newType);
		switch(type._hx_index) {
		case 4:
			this.addAbstractFields(context,identifier,nameToken);
			break;
		case 5:
			this.addFields(context,identifier,nameToken);
			break;
		case 6:
			this.readEnum(context,identifier,nameToken.getFirstChild());
			break;
		case 7:
			this.addFields(context,identifier,nameToken);
			if(identifier.uses != null) {
				let _g = 0;
				let _g1 = identifier.uses;
				while(_g < _g1.length) {
					let use = _g1[_g];
					++_g;
					let _g2 = use.type;
					switch(_g2._hx_index) {
					case 16:
						use.type = refactor_discover_IdentifierType.InterfaceProperty;
						break;
					case 17:
						let _g3 = _g2.isStatic;
						use.type = refactor_discover_IdentifierType.InterfaceVar;
						break;
					case 18:
						let _g4 = _g2.isStatic;
						use.type = refactor_discover_IdentifierType.InterfaceMethod;
						break;
					default:
					}
				}
			}
			break;
		case 8:
			this.readTypedef(context,identifier,nameToken);
			break;
		case 9:
			this.readVarInit(context,identifier,nameToken);
			break;
		case 10:
			this.readMethod(context,identifier,nameToken);
			break;
		default:
		}
		this.readStrings(context,identifier,nameToken);
		return newType;
	}
	readStrings(context,identifier,token) {
		let _gthis = this;
		token.filterCallback(function(token,index) {
			let _g = token.tok;
			if(_g._hx_index == 2) {
				let _g1 = _g.c;
				if(_g1._hx_index == 2) {
					let _g = _g1.s;
					let _g2 = _g1.kind;
					if(_g2 == null) {
						return tokentree_FilterResult.GoDeeper;
					} else {
						switch(_g2._hx_index) {
						case 0:
							let s = _g;
							let regEx = new EReg("^[a-z][a-zA-Z0-9]+(\\.[a-z][a-zA-Z0-9]+)*(|\\.[A-Z][a-zA-Z0-9]+)$","");
							if(regEx.match(s)) {
								let pos = { fileName : context.fileName, start : token.pos.min + 1, end : token.pos.max - 1};
								identifier.addUse(new refactor_discover_Identifier(refactor_discover_IdentifierType.StringConst,s,pos,context.nameMap,context.file,context.type));
							}
							return tokentree_FilterResult.SkipSubtree;
						case 1:
							let s1 = _g;
							_gthis.readStringInterpolation(context,identifier,token,s1);
							return tokentree_FilterResult.SkipSubtree;
						}
					}
				} else {
					return tokentree_FilterResult.GoDeeper;
				}
			} else {
				return tokentree_FilterResult.GoDeeper;
			}
		});
	}
	readStringInterpolation(context,identifier,token,text) {
		let start = 0;
		let index;
		while(true) {
			index = text.indexOf("${",start);
			if(!(index >= 0)) {
				break;
			}
			if(this.isDollarEscaped(text,index)) {
				start = index + 1;
				continue;
			}
			start = index + 1;
			let indexEnd = text.indexOf("}",index + 2);
			let fragment = text.substring(index + 2,indexEnd);
			if(fragment.indexOf("{") >= 0) {
				continue;
			}
			this.readInterpolatedFragment(context,identifier,fragment,token.pos.min + 1 + start + 1);
			start = indexEnd;
		}
		start = 0;
		let nameRegEx = new EReg("^[a-z][a-zA-Z0-9]*","");
		while(true) {
			index = text.indexOf("$",start);
			if(!(index >= 0)) {
				break;
			}
			if(index + 1 >= text.length) {
				break;
			}
			start = index + 1;
			if(nameRegEx.match(HxOverrides.substr(text,start,null))) {
				let matchedText = nameRegEx.matched(0);
				let pos = { fileName : token.pos.file, start : token.pos.min + start + 1, end : token.pos.min + start + matchedText.length + 1};
				identifier.addUse(new refactor_discover_Identifier(refactor_discover_IdentifierType.Access,matchedText,pos,context.nameMap,context.file,context.type));
			}
		}
	}
	isDollarEscaped(text,index) {
		let escaped = false;
		while(--index >= 0) {
			if(text.charCodeAt(index) != 36) {
				return escaped;
			}
			escaped = !escaped;
		}
		return escaped;
	}
	readInterpolatedFragment(context,identifier,text,offset) {
		let root = null;
		try {
			let content = haxe_io_Bytes.ofString(text);
			let lexer = new haxeparser_HaxeLexer(content,context.fileName);
			let t = lexer.token(haxeparser_HaxeLexer.tok);
			let tokens = [];
			while(t.tok != haxeparser_TokenDef.Eof) {
				t.pos.min += offset;
				t.pos.max += offset;
				tokens.push(t);
				t = lexer.token(haxeparser_HaxeLexer.tok);
			}
			root = tokentree_TokenTreeBuilder.buildTokenTree(tokens,content,tokentree_TokenTreeEntryPoint.ExpressionLevel);
			this.readExpression(context,identifier,root);
		} catch( _g ) {
			let _g1 = haxe_Exception.caught(_g);
			let _g2 = _g1.unwrap();
			if(((_g2) instanceof hxparse_ParserError)) {
				let e = _g2;
				throw haxe_Exception.thrown("failed to parse " + context.fileName + " - ParserError: " + Std.string(e) + " (" + Std.string(e.pos) + ")");
			} else if(((_g2) instanceof haxeparser_LexerError)) {
				let e = _g2;
				throw haxe_Exception.thrown("failed to parse " + context.fileName + " - LexerError: " + Std.string(e.msg) + " (" + Std.string(e.pos) + ")");
			} else {
				let e = _g1;
				throw haxe_Exception.thrown("failed to parse " + context.fileName + " - " + e.details());
			}
		}
	}
	readEnum(context,identifier,token) {
		if(!token.hasChildren()) {
			return;
		}
		let _g = 0;
		let _g1 = token.children;
		while(_g < _g1.length) {
			let child = _g1[_g];
			++_g;
			let _g2 = child.tok;
			switch(_g2._hx_index) {
			case 2:
				let _g3 = _g2.c;
				if(_g3._hx_index == 3) {
					let _g = _g3.s;
					let enumField = this.makeIdentifier(context,child,refactor_discover_IdentifierType.EnumField([]),identifier);
					if(enumField == null) {
						continue;
					}
					if(!child.hasChildren()) {
						continue;
					}
					let pOpen = child.getFirstChild();
					if(!pOpen.matches(tokentree_TokenTreeDef.POpen)) {
						continue;
					}
					let params = this.readParameter(context,enumField,pOpen,pOpen.pos.max);
					enumField.type = refactor_discover_IdentifierType.EnumField(params);
				} else {
					continue;
				}
				break;
			case 3:
				switch(_g2.s) {
				case "else":
					this.readEnum(context,identifier,child);
					break;
				case "elseif":case "if":
					this.readExpression(context,identifier,child.getFirstChild());
					let _g4 = 1;
					let _g5 = child.children.length - 1;
					while(_g4 < _g5) {
						let index = _g4++;
						let _g = child.children[index].tok;
						if(_g._hx_index == 3) {
							let _g1 = _g.s;
						} else {
							this.readEnum(context,identifier,child.children[index]);
						}
					}
					break;
				default:
					continue;
				}
				break;
			default:
				continue;
			}
		}
	}
	readTypedef(context,identifier,token) {
		if(!token.hasChildren()) {
			return;
		}
		let assignToken = token.getFirstChild();
		let tmp;
		if(assignToken != null) {
			let _g = assignToken.tok;
			tmp = !(_g._hx_index == 6 && _g.op._hx_index == 4);
		} else {
			tmp = true;
		}
		if(tmp || !assignToken.hasChildren()) {
			return;
		}
		let _g = 0;
		let _g1 = assignToken.children;
		while(_g < _g1.length) {
			let child = _g1[_g];
			++_g;
			let _g2 = child.tok;
			switch(_g2._hx_index) {
			case 2:
				let _g3 = _g2.c;
				if(_g3._hx_index == 3) {
					let _g = _g3.s;
					this.makeIdentifier(context,child,refactor_discover_IdentifierType.TypedefBase,identifier);
				}
				break;
			case 18:
				this.readAnonStructure(context,identifier,child);
				break;
			default:
			}
		}
	}
	addFields(context,identifier,token) {
		if(token == null || !token.hasChildren()) {
			return;
		}
		let _g = 0;
		let _g1 = token.children;
		while(_g < _g1.length) {
			let child = _g1[_g];
			++_g;
			let _g2 = child.tok;
			switch(_g2._hx_index) {
			case 1:
				switch(_g2.k._hx_index) {
				case 0:
					let nameToken = child.getFirstChild();
					let method = this.makeIdentifier(context,nameToken,refactor_discover_IdentifierType.Method(tokentree_TokenTreeAccessHelper.firstOf(nameToken,tokentree_TokenTreeDef.Kwd(haxeparser_Keyword.KwdStatic)) != null),identifier);
					this.readMethod(context,method,nameToken);
					break;
				case 11:
					this.makeIdentifier(context,child.getFirstChild(),refactor_discover_IdentifierType.Extends,identifier);
					break;
				case 12:
					this.makeIdentifier(context,child.getFirstChild(),refactor_discover_IdentifierType.Implements,identifier);
					break;
				case 2:case 42:
					let nameToken1 = child.getFirstChild();
					this.makeIdentifier(context,nameToken1,refactor_discover_IdentifierType.FieldVar(tokentree_TokenTreeAccessHelper.firstOf(nameToken1,tokentree_TokenTreeDef.Kwd(haxeparser_Keyword.KwdStatic)) != null),identifier);
					break;
				default:
				}
				break;
			case 3:
				let _g3 = _g2.s;
				this.addFields(context,identifier,child);
				break;
			case 18:
				this.addFields(context,identifier,child);
				break;
			default:
			}
		}
	}
	addAbstractFields(context,identifier,token) {
		if(token == null || !token.hasChildren()) {
			return;
		}
		let staticVars = false;
		let block = null;
		let _g = 0;
		let _g1 = token.children;
		_hx_loop1: while(_g < _g1.length) {
			let child = _g1[_g];
			++_g;
			let _g2 = child.tok;
			switch(_g2._hx_index) {
			case 1:
				if(_g2.k._hx_index == 26) {
					staticVars = true;
				}
				break;
			case 2:
				let _g3 = _g2.c;
				if(_g3._hx_index == 3) {
					switch(_g3.s) {
					case "from":
						this.makeIdentifier(context,child.getFirstChild(),refactor_discover_IdentifierType.AbstractFrom,identifier);
						break;
					case "to":
						this.makeIdentifier(context,child.getFirstChild(),refactor_discover_IdentifierType.AbstractTo,identifier);
						break;
					default:
					}
				}
				break;
			case 18:
				block = child;
				break _hx_loop1;
			case 20:
				this.readTypeHint(context,identifier,child,refactor_discover_IdentifierType.AbstractOver);
				break;
			default:
			}
		}
		if(block == null) {
			return;
		}
		let _g2 = 0;
		let _g3 = block.children;
		while(_g2 < _g3.length) {
			let child = _g3[_g2];
			++_g2;
			let _g = child.tok;
			if(_g._hx_index == 1) {
				switch(_g.k._hx_index) {
				case 0:
					let nameToken = child.getFirstChild();
					let method = this.makeIdentifier(context,nameToken,refactor_discover_IdentifierType.Method(tokentree_TokenTreeAccessHelper.firstOf(nameToken,tokentree_TokenTreeDef.Kwd(haxeparser_Keyword.KwdStatic)) != null),identifier);
					this.readMethod(context,method,nameToken);
					break;
				case 2:case 42:
					let nameToken1 = child.getFirstChild();
					let variable = this.makeIdentifier(context,nameToken1,refactor_discover_IdentifierType.FieldVar(staticVars),identifier);
					if(tokentree_TokenTreeAccessHelper.matches(tokentree_TokenTreeAccessHelper.firstChild(nameToken1),tokentree_TokenTreeDef.POpen) != null) {
						variable.type = refactor_discover_IdentifierType.Property;
					}
					break;
				default:
				}
			}
		}
	}
	readVarInit(context,identifier,token) {
		if(!token.hasChildren()) {
			return;
		}
		let _g = 0;
		let _g1 = token.children;
		while(_g < _g1.length) {
			let child = _g1[_g];
			++_g;
			let _g2 = child.tok;
			if(_g2._hx_index == 6) {
				if(_g2.op._hx_index == 4) {
					this.readExpression(context,identifier,child.getFirstChild());
				}
			}
		}
	}
	readMethod(context,identifier,token) {
		let ignore = true;
		let fullPos = token.getPos();
		let _g = 0;
		let _g1 = token.children;
		while(_g < _g1.length) {
			let child = _g1[_g];
			++_g;
			switch(child.tok._hx_index) {
			case 12:
				break;
			case 18:
				if(ignore) {
					continue;
				}
				this.readBlock(context,identifier,child);
				break;
			case 20:
				this.readParameter(context,identifier,child,fullPos.max);
				ignore = false;
				break;
			default:
				if(ignore) {
					continue;
				}
				this.readExpression(context,identifier,child);
			}
		}
	}
	readObjectLiteral(context,identifier,token) {
		if(!token.hasChildren()) {
			return;
		}
		let names = [];
		let _g = 0;
		let _g1 = token.children;
		_hx_loop1: while(_g < _g1.length) {
			let child = _g1[_g];
			++_g;
			let _g2 = child.tok;
			switch(_g2._hx_index) {
			case 2:
				let _g3 = _g2.c;
				if(_g3._hx_index == 3) {
					let s = _g3.s;
					names.push(s);
					let field = this.makeIdentifier(context,child,refactor_discover_IdentifierType.StructureField(names),identifier);
					this.readExpression(context,field,child.getFirstChild());
				} else {
					break _hx_loop1;
				}
				break;
			case 19:
				break _hx_loop1;
			default:
				break _hx_loop1;
			}
		}
	}
	readBlock(context,identifier,token) {
		if(!token.hasChildren()) {
			return;
		}
		let fullPos = token.getPos();
		let scopeEnd = fullPos.max;
		let _g = 0;
		let _g1 = token.children;
		while(_g < _g1.length) {
			let child = _g1[_g];
			++_g;
			let _g2 = child.tok;
			switch(_g2._hx_index) {
			case 1:
				switch(_g2.k._hx_index) {
				case 0:
					child = child.getFirstChild();
					let method = this.makeIdentifier(context,child,refactor_discover_IdentifierType.ScopedLocal(child.pos.min,scopeEnd,refactor_discover_ScopedLocalType.Var),identifier);
					this.readMethod(context,method,child);
					break;
				case 2:
					child = child.getFirstChild();
					this.makeIdentifier(context,child,refactor_discover_IdentifierType.ScopedLocal(child.getPos().max,scopeEnd,refactor_discover_ScopedLocalType.Var),identifier);
					break;
				case 42:
					child = child.getFirstChild();
					this.makeIdentifier(context,child,refactor_discover_IdentifierType.ScopedLocal(child.getPos().max,scopeEnd,refactor_discover_ScopedLocalType.Var),identifier);
					break;
				default:
					this.readExpression(context,identifier,child);
				}
				break;
			case 10:
				break;
			case 11:
				break;
			default:
				this.readExpression(context,identifier,child);
			}
		}
	}
	readExpression(context,identifier,token) {
		if(token == null) {
			return;
		}
		let _g = token.tok;
		switch(_g._hx_index) {
		case 1:
			switch(_g.k._hx_index) {
			case 0:
				let fullPos = token.parent.getPos();
				let scopeEnd = fullPos.max;
				let child = token.getFirstChild();
				let method = this.makeIdentifier(context,child,refactor_discover_IdentifierType.ScopedLocal(child.pos.min,scopeEnd,refactor_discover_ScopedLocalType.Var),identifier);
				if(method == null) {
					this.readMethod(context,identifier,token);
				} else {
					this.readMethod(context,method,child);
				}
				return;
			case 2:
				let fullPos1 = token.parent.getPos();
				let scopeEnd1 = fullPos1.max;
				let token1 = token.getFirstChild();
				let variable = this.makeIdentifier(context,token1,refactor_discover_IdentifierType.ScopedLocal(token1.getPos().max,scopeEnd1,refactor_discover_ScopedLocalType.Var),identifier);
				this.readVarInit(context,variable,token1);
				return;
			case 7:
				this.readFor(context,identifier,token);
				return;
			case 14:
				this.readSwitch(context,identifier,token);
				return;
			case 23:
				this.makeIdentifier(context,token,refactor_discover_IdentifierType.Access,identifier);
				return;
			default:
			}
			break;
		case 2:
			let _g1 = _g.c;
			if(_g1._hx_index == 3) {
				let _g = _g1.s;
				let parent = token.parent;
				if(parent.tok._hx_index == 11) {
					let prev = parent.previousSibling;
					if(prev != null) {
						switch(prev.tok._hx_index) {
						case 17:case 21:
							this.makeIdentifier(context,token,refactor_discover_IdentifierType.ArrayAccess(prev.pos.min),identifier);
							return;
						default:
						}
					}
				} else {
					this.makeIdentifier(context,token,refactor_discover_IdentifierType.Access,identifier);
					return;
				}
			}
			break;
		case 10:
			return;
		case 18:
			switch(tokentree_utils_TokenTreeCheckUtils.getBrOpenType(token)._hx_index) {
			case 0:
				this.readBlock(context,identifier,token);
				break;
			case 1:
				this.readBlock(context,identifier,token);
				break;
			case 2:
				this.readObjectLiteral(context,identifier,token);
				break;
			case 3:
				this.readBlock(context,identifier,token);
				break;
			case 4:
				this.readBlock(context,identifier,token);
				break;
			}
			return;
		default:
		}
		if(token.hasChildren()) {
			let _g = 0;
			let _g1 = token.children;
			while(_g < _g1.length) {
				let child = _g1[_g];
				++_g;
				this.readExpression(context,identifier,child);
			}
		}
	}
	readSwitch(context,identifier,token) {
		if(!token.hasChildren()) {
			return;
		}
		let index = 0;
		if(identifier != null && identifier.uses != null) {
			index = identifier.uses.length;
		}
		this.readExpression(context,identifier,token.getFirstChild());
		let switchIdent = identifier;
		if(identifier != null && identifier.uses != null && identifier.uses.length > index) {
			switchIdent = identifier.uses[index];
		}
		let brOpen = tokentree_TokenTreeAccessHelper.firstOf(token,tokentree_TokenTreeDef.BrOpen);
		if(brOpen == null || !brOpen.hasChildren()) {
			return;
		}
		let _g = 0;
		let _g1 = brOpen.children;
		_hx_loop1: while(_g < _g1.length) {
			let child = _g1[_g];
			++_g;
			let _g2 = child.tok;
			if(_g2._hx_index == 1) {
				switch(_g2.k._hx_index) {
				case 15:
					this.readCase(context,switchIdent,child);
					break;
				case 16:
					if(child.hasChildren()) {
						this.readBlock(context,switchIdent,child.getFirstChild());
					}
					break;
				default:
					break _hx_loop1;
				}
			} else {
				break;
			}
		}
	}
	readFor(context,identifier,token) {
		if(!token.hasChildren()) {
			return;
		}
		let skip = true;
		let _g = 0;
		let _g1 = token.children;
		while(_g < _g1.length) {
			let child = _g1[_g];
			++_g;
			if(child.tok._hx_index == 20) {
				let fullPos = token.getPos();
				let scopeEnd = fullPos.max;
				this.readForIteration(context,identifier,child.getFirstChild(),scopeEnd);
				skip = false;
			} else {
				if(skip) {
					continue;
				}
				this.readExpression(context,identifier,child);
			}
		}
	}
	readForIteration(context,identifier,token,scopeEnd) {
		let loopIdentifiers = [];
		let pClose = tokentree_TokenTreeAccessHelper.firstOf(tokentree_TokenTreeAccessHelper.parent(token),tokentree_TokenTreeDef.PClose);
		let scopeStart = token.pos.min;
		if(pClose != null) {
			scopeStart = pClose.pos.max;
		}
		let ident = this.makeIdentifier(context,token,refactor_discover_IdentifierType.ScopedLocal(scopeStart,scopeEnd,refactor_discover_ScopedLocalType.ForLoop(loopIdentifiers)),identifier);
		loopIdentifiers.push(ident);
		if(!token.hasChildren()) {
			return;
		}
		let _g = 0;
		let _g1 = token.children;
		while(_g < _g1.length) {
			let child = _g1[_g];
			++_g;
			let _g2 = child.tok;
			if(_g2._hx_index == 6) {
				if(_g2.op._hx_index == 22) {
					ident = this.makeIdentifier(context,child.getFirstChild(),refactor_discover_IdentifierType.ScopedLocal(scopeStart,scopeEnd,refactor_discover_ScopedLocalType.ForLoop(loopIdentifiers)),identifier);
					loopIdentifiers.push(ident);
				} else {
					this.readExpression(context,ident,child);
					if(ident.uses != null) {
						let _g = 0;
						let _g1 = ident.uses;
						while(_g < _g1.length) {
							let use = _g1[_g];
							++_g;
							if(use.type._hx_index == 31) {
								use.type = refactor_discover_IdentifierType.ForIterator;
							}
							loopIdentifiers.push(use);
						}
					}
				}
			} else {
				this.readExpression(context,ident,child);
				if(ident.uses != null) {
					let _g = 0;
					let _g1 = ident.uses;
					while(_g < _g1.length) {
						let use = _g1[_g];
						++_g;
						if(use.type._hx_index == 31) {
							use.type = refactor_discover_IdentifierType.ForIterator;
						}
						loopIdentifiers.push(use);
					}
				}
			}
		}
	}
	readCase(context,identifier,token) {
		if(!token.hasChildren()) {
			return;
		}
		let fullPos = token.getPos();
		let scopeEnd = fullPos.max;
		let _g = 0;
		let _g1 = token.children;
		_hx_loop1: while(_g < _g1.length) {
			let child = _g1[_g];
			++_g;
			let _g2 = child.tok;
			switch(_g2._hx_index) {
			case 1:
				if(_g2.k._hx_index == 2) {
					child = child.getFirstChild();
					this.makeIdentifier(context,child,refactor_discover_IdentifierType.ScopedLocal(child.pos.min,scopeEnd,refactor_discover_ScopedLocalType.CaseCapture),identifier);
				}
				break;
			case 2:
				let _g3 = _g2.c;
				if(_g3._hx_index == 3) {
					let _g = _g3.s;
					this.readCaseConst(context,identifier,child,scopeEnd);
				}
				break;
			case 12:
				this.readBlock(context,identifier,child);
				break _hx_loop1;
			case 16:
				this.readCaseArray(context,identifier,child,scopeEnd);
				break;
			case 18:
				this.readCaseStructure(context,identifier,child,scopeEnd);
				break;
			default:
			}
		}
	}
	readCaseConst(context,identifier,token,scopeEnd) {
		if(!token.hasChildren()) {
			return;
		}
		let caseIdent = this.makeIdentifier(context,token,refactor_discover_IdentifierType.CaseLabel(identifier),identifier);
		let pOpen = token.filterCallback(function(token,index) {
			if(token.tok._hx_index == 20) {
				return tokentree_FilterResult.FoundSkipSubtree;
			} else {
				return tokentree_FilterResult.GoDeeper;
			}
		});
		let _g = 0;
		while(_g < pOpen.length) {
			let child = pOpen[_g];
			++_g;
			this.readParameter(context,caseIdent,child,scopeEnd);
		}
	}
	readCaseArray(context,identifier,token,scopeEnd) {
		if(!token.hasChildren()) {
			return;
		}
		let _g = 0;
		let _g1 = token.children;
		while(_g < _g1.length) {
			let child = _g1[_g];
			++_g;
			this.makeIdentifier(context,child,refactor_discover_IdentifierType.ScopedLocal(child.pos.max,scopeEnd,refactor_discover_ScopedLocalType.CaseCapture),identifier);
		}
	}
	readCaseStructure(context,identifier,token,scopeEnd) {
		if(!token.hasChildren()) {
			return;
		}
		let _g = 0;
		let _g1 = token.children;
		while(_g < _g1.length) {
			let child = _g1[_g];
			++_g;
			let _g2 = child.tok;
			if(_g2._hx_index == 2) {
				let _g = _g2.c;
				let field = this.makeIdentifier(context,child,refactor_discover_IdentifierType.StructureField([]),identifier);
				if(field == null) {
					continue;
				}
				if(!child.hasChildren()) {
					continue;
				}
				let valueChild = child.getFirstChild();
				let _g1 = valueChild.tok;
				switch(_g1._hx_index) {
				case 1:
					let _g3 = _g1.k;
					this.readExpression(context,field,valueChild);
					break;
				case 2:
					let _g4 = _g1.c;
					this.readExpression(context,field,valueChild);
					break;
				case 4:
					let _g5 = _g1.s;
					this.readExpression(context,field,valueChild);
					break;
				case 5:
					let _g6 = _g1.op;
					this.readExpression(context,field,valueChild);
					break;
				case 6:
					let _g7 = _g1.op;
					this.readExpression(context,field,valueChild);
					break;
				case 16:case 18:
					this.readCaseStructure(context,field,valueChild,scopeEnd);
					continue;
				default:
				}
				if(field.uses != null) {
					let _g = 0;
					let _g1 = field.uses;
					while(_g < _g1.length) {
						let use = _g1[_g];
						++_g;
						use.type = refactor_discover_IdentifierType.ScopedLocal(use.pos.start,scopeEnd,refactor_discover_ScopedLocalType.CaseCapture);
					}
				}
			} else {
				break;
			}
		}
	}
	readParameter(context,identifier,token,scopeEnd) {
		let params = [];
		let _g = 0;
		let _g1 = token.children;
		while(_g < _g1.length) {
			let child = _g1[_g];
			++_g;
			let _g2 = child.tok;
			switch(_g2._hx_index) {
			case 2:
				let _g3 = _g2.c;
				if(_g3._hx_index == 3) {
					let _g = _g3.s;
					let paramIdent = this.makeIdentifier(context,child,refactor_discover_IdentifierType.ScopedLocal(child.pos.min,scopeEnd,refactor_discover_ScopedLocalType.Parameter(params)),identifier);
					params.push(paramIdent);
				}
				break;
			case 22:
				child = child.getFirstChild();
				let paramIdent = this.makeIdentifier(context,child,refactor_discover_IdentifierType.ScopedLocal(child.pos.min,scopeEnd,refactor_discover_ScopedLocalType.Parameter(params)),identifier);
				params.push(paramIdent);
				break;
			default:
			}
		}
		return params;
	}
	makePosition(fileName,token) {
		return { fileName : fileName, start : token.pos.min, end : token.pos.max};
	}
	makeIdentifier(context,nameToken,type,parentIdentifier) {
		if(nameToken == null) {
			return null;
		}
		let _g = nameToken.tok;
		switch(_g._hx_index) {
		case 1:
			switch(_g.k._hx_index) {
			case 23:case 37:
				break;
			default:
				return null;
			}
			break;
		case 2:
			let _g1 = _g.c;
			if(_g1._hx_index == 3) {
				let _g = _g1.s;
			} else {
				return null;
			}
			break;
		default:
			return null;
		}
		let pos = this.makePosition(context.fileName,nameToken);
		let pack = [];
		let typeParamLt = null;
		let typeHintColon = null;
		let pOpenToken = null;
		let parent = nameToken.parent;
		let lastNamePart = nameToken;
		let findAllNames = null;
		findAllNames = function(parentPart) {
			if(!parentPart.hasChildren()) {
				return;
			}
			let _g = 0;
			let _g1 = parentPart.children;
			while(_g < _g1.length) {
				let child = _g1[_g];
				++_g;
				let _g2 = child.tok;
				switch(_g2._hx_index) {
				case 1:
					switch(_g2.k._hx_index) {
					case 23:case 37:
						pack.push(child.toString());
						break;
					default:
						continue;
					}
					break;
				case 2:
					let _g3 = _g2.c;
					pack.push(child.toString());
					break;
				case 5:
					let _g4 = _g2.op;
					return;
				case 6:
					let _g5 = _g2.op;
					return;
				case 11:
					break;
				case 20:
					let _g6 = parent.tok;
					if(_g6._hx_index == 1) {
						switch(_g6.k._hx_index) {
						case 0:
							break;
						case 2:case 42:
							type = refactor_discover_IdentifierType.Property;
							break;
						default:
						}
					}
					return;
				default:
					continue;
				}
				lastNamePart = child;
				findAllNames(child);
			}
		};
		pack.push(nameToken.toString());
		findAllNames(nameToken);
		pos.end = lastNamePart.pos.max;
		if(lastNamePart.hasChildren()) {
			let _g = 0;
			let _g1 = lastNamePart.children;
			while(_g < _g1.length) {
				let child = _g1[_g];
				++_g;
				let _g2 = child.tok;
				switch(_g2._hx_index) {
				case 6:
					switch(_g2.op._hx_index) {
					case 4:
						if(!parent.matches(tokentree_TokenTreeDef.Kwd(haxeparser_Keyword.KwdTypedef))) {
							pOpenToken = child;
						}
						break;
					case 9:
						if(tokentree_utils_TokenTreeCheckUtils.isTypeParameter(child)) {
							typeParamLt = child;
						}
						break;
					case 22:
						if(type._hx_index == 33) {
							let _g = type.scopeStart;
							let _g1 = type.scopeEnd;
							let _g2 = type.scopeType;
							if(_g2._hx_index == 3) {
								let _g = _g2.loopIdentifiers;
							} else {
								pOpenToken = child;
							}
						} else {
							pOpenToken = child;
						}
						break;
					case 23:
						break;
					default:
						pOpenToken = child;
					}
					break;
				case 12:
					switch(tokentree_utils_TokenTreeCheckUtils.getColonType(child)._hx_index) {
					case 0:
						break;
					case 1:
						typeHintColon = child;
						break;
					case 2:
						typeHintColon = child;
						break;
					case 3:
						break;
					case 4:
						break;
					case 5:
						break;
					case 6:
						break;
					}
					break;
				case 16:
					pOpenToken = child;
					break;
				case 20:
					if(type._hx_index == 31) {
						if(parent.matches(tokentree_TokenTreeDef.Kwd(haxeparser_Keyword.KwdNew))) {
							type = refactor_discover_IdentifierType.Call(true);
						} else {
							type = refactor_discover_IdentifierType.Call(false);
						}
						pOpenToken = child;
					}
					break;
				default:
				}
			}
		}
		if(pack.length <= 0) {
			return null;
		}
		let identifier = new refactor_discover_Identifier(type,pack.join("."),pos,context.nameMap,context.file,context.type);
		if(parentIdentifier != null) {
			parentIdentifier.addUse(identifier);
		}
		if(typeParamLt != null) {
			this.addTypeParameter(context,identifier,typeParamLt);
		}
		if(typeHintColon != null) {
			this.readTypeHint(context,identifier,typeHintColon,refactor_discover_IdentifierType.TypeHint);
		}
		if(pOpenToken != null) {
			this.readExpression(context,identifier,pOpenToken);
			if(pOpenToken.nextSibling != null) {
				this.readExpression(context,identifier,pOpenToken.nextSibling);
			}
		}
		return identifier;
	}
	addTypeParameter(context,identifier,token) {
		if(!token.hasChildren()) {
			return;
		}
		let _g = 0;
		let _g1 = token.children;
		_hx_loop1: while(_g < _g1.length) {
			let child = _g1[_g];
			++_g;
			let _g2 = child.tok;
			switch(_g2._hx_index) {
			case 2:
				let _g3 = _g2.c;
				if(_g3._hx_index == 3) {
					let _g = _g3.s;
					this.makeIdentifier(context,child,refactor_discover_IdentifierType.TypedParameter,identifier);
				}
				break;
			case 6:
				if(_g2.op._hx_index == 7) {
					break _hx_loop1;
				}
				break;
			case 20:
				this.readParameter(context,identifier,child,token.getPos().max);
				break;
			default:
			}
		}
	}
	readTypeHint(context,identifier,token,type) {
		if(!token.hasChildren()) {
			return;
		}
		let _g = 0;
		let _g1 = token.children;
		_hx_loop1: while(_g < _g1.length) {
			let child = _g1[_g];
			++_g;
			let _g2 = child.tok;
			switch(_g2._hx_index) {
			case 2:
				let _g3 = _g2.c;
				if(_g3._hx_index == 3) {
					let _g = _g3.s;
					this.makeIdentifier(context,child,type,identifier);
				}
				break;
			case 18:
				this.readAnonStructure(context,identifier,child);
				break _hx_loop1;
			default:
			}
		}
	}
	readAnonStructure(context,identifier,token) {
		if(!token.hasChildren()) {
			return;
		}
		let fields = [];
		let _g = 0;
		let _g1 = token.children;
		while(_g < _g1.length) {
			let child = _g1[_g];
			++_g;
			let _g2 = child.tok;
			switch(_g2._hx_index) {
			case 1:
				switch(_g2.k._hx_index) {
				case 2:case 42:
					let nameToken = child.getFirstChild();
					let identifier1 = this.makeIdentifier(context,nameToken,refactor_discover_IdentifierType.TypedefField(fields),identifier);
					if(tokentree_TokenTreeAccessHelper.firstOf(tokentree_TokenTreeAccessHelper.firstOf(tokentree_TokenTreeAccessHelper.firstOf(nameToken,tokentree_TokenTreeDef.At),tokentree_TokenTreeDef.DblDot),tokentree_TokenTreeDef.Const(haxeparser_Constant.CIdent("optional"))) != null) {
						fields.push(refactor_discover_TypedefFieldType.Optional(identifier1));
					} else {
						fields.push(refactor_discover_TypedefFieldType.Required(identifier1));
					}
					break;
				default:
				}
				break;
			case 2:
				let _g3 = _g2.c;
				if(_g3._hx_index == 3) {
					let _g = _g3.s;
					let identifier1 = this.makeIdentifier(context,child,refactor_discover_IdentifierType.TypedefField(fields),identifier);
					if(tokentree_TokenTreeAccessHelper.firstOf(tokentree_TokenTreeAccessHelper.firstOf(tokentree_TokenTreeAccessHelper.firstOf(child,tokentree_TokenTreeDef.At),tokentree_TokenTreeDef.DblDot),tokentree_TokenTreeDef.Const(haxeparser_Constant.CIdent("optional"))) != null) {
						fields.push(refactor_discover_TypedefFieldType.Optional(identifier1));
					} else {
						fields.push(refactor_discover_TypedefFieldType.Required(identifier1));
					}
				}
				break;
			case 22:
				let identifier2 = this.makeIdentifier(context,child.getFirstChild(),refactor_discover_IdentifierType.TypedefField(fields),identifier);
				fields.push(refactor_discover_TypedefFieldType.Optional(identifier2));
				break;
			default:
			}
		}
	}
}
refactor_discover_UsageCollector.__name__ = true;
class refactor_edits_Changelist {
	constructor(context) {
		this.changes = new haxe_ds_StringMap();
		this.context = context;
	}
	addChange(fileName,change,identifier) {
		if(identifier != null) {
			if(identifier.edited) {
				return;
			}
			identifier.edited = true;
		}
		let fileChanges = this.changes.h[fileName];
		if(fileChanges == null) {
			this.changes.h[fileName] = [change];
		} else {
			fileChanges.push(change);
		}
	}
	execute() {
		if(!this.context.forRealExecute) {
			return this.dryRun();
		}
		let hasChanges = false;
		let h = this.changes.h;
		let _g_h = h;
		let _g_keys = Object.keys(h);
		let _g_length = _g_keys.length;
		let _g_current = 0;
		while(_g_current < _g_length) {
			let key = _g_keys[_g_current++];
			let _g_key = key;
			let _g_value = _g_h[key];
			let file = _g_key;
			let edits = _g_value;
			edits.sort($bind(this,this.sortFileEdits));
			hasChanges = true;
			let doc = this.context.docFactory(file);
			let _g = 0;
			while(_g < edits.length) {
				let edit = edits[_g];
				++_g;
				doc.addChange(edit);
			}
			doc.endEdits();
		}
		if(hasChanges) {
			return refactor_RefactorResult.Done;
		} else {
			return refactor_RefactorResult.NoChange;
		}
	}
	dryRun() {
		let hasChanges = false;
		let h = this.changes.h;
		let _g_h = h;
		let _g_keys = Object.keys(h);
		let _g_length = _g_keys.length;
		let _g_current = 0;
		while(_g_current < _g_length) {
			let key = _g_keys[_g_current++];
			let _g_key = key;
			let _g_value = _g_h[key];
			let file = _g_key;
			let edits = _g_value;
			edits.sort($bind(this,this.sortFileEdits));
			hasChanges = true;
			process.stdout.write(Std.string("" + file));
			process.stdout.write("\n");
			let _g = 0;
			while(_g < edits.length) {
				let edit = edits[_g];
				++_g;
				switch(edit._hx_index) {
				case 0:
					let newFileName = edit.newFileName;
					process.stdout.write(Std.string("* rename to \"" + newFileName + "\""));
					process.stdout.write("\n");
					break;
				case 1:
					let text = edit.text;
					let pos = edit.pos;
					let v = "* replace text with \"" + text + "\" @" + pos.start + "-" + pos.end;
					process.stdout.write(Std.string(v));
					process.stdout.write("\n");
					this.printDiffLines(pos,text);
					break;
				case 2:
					let text1 = edit.text;
					let pos1 = edit.pos;
					let v1 = "* insert text \"" + text1 + "\" @" + pos1.start + "-" + pos1.end;
					process.stdout.write(Std.string(v1));
					process.stdout.write("\n");
					process.stdout.write(Std.string("+++ " + text1));
					process.stdout.write("\n");
					break;
				case 3:
					let pos2 = edit.pos;
					let v2 = "* remove text @" + pos2.start + "-" + pos2.end;
					process.stdout.write(Std.string(v2));
					process.stdout.write("\n");
					this.printDiffLines(pos2,null);
					break;
				}
			}
		}
		if(hasChanges) {
			return refactor_RefactorResult.DryRun;
		} else {
			return refactor_RefactorResult.NoChange;
		}
	}
	sortFileEdits(a,b) {
		let offsetA;
		switch(a._hx_index) {
		case 0:
			let _g = a.newFileName;
			offsetA = 0;
			break;
		case 1:
			let _g1 = a.text;
			let pos = a.pos;
			offsetA = pos.start;
			break;
		case 2:
			let _g2 = a.text;
			let pos1 = a.pos;
			offsetA = pos1.start;
			break;
		case 3:
			let pos2 = a.pos;
			offsetA = pos2.start;
			break;
		}
		let offsetB;
		switch(b._hx_index) {
		case 0:
			let _g3 = b.newFileName;
			offsetB = 0;
			break;
		case 1:
			let _g4 = b.text;
			let pos3 = b.pos;
			offsetB = pos3.start;
			break;
		case 2:
			let _g5 = b.text;
			let pos4 = b.pos;
			offsetB = pos4.start;
			break;
		case 3:
			let pos5 = b.pos;
			offsetB = pos5.start;
			break;
		}
		if(offsetA < offsetB) {
			return -1;
		}
		if(offsetA > offsetB) {
			return 1;
		}
		return 0;
	}
	printDiffLines(pos,toName) {
		let content = js_node_buffer__$Buffer_Helper.bytesOfBuffer(js_node_Fs.readFileSync(pos.fileName));
		let lineStart = pos.start;
		let lineEnd = pos.end;
		while(lineStart > 0) {
			let char = content.b[lineStart];
			if(char == 10 || char == 13) {
				++lineStart;
				break;
			}
			--lineStart;
		}
		while(lineEnd < content.length) {
			let char = content.b[lineEnd];
			if(char == 10 || char == 13) {
				break;
			}
			++lineEnd;
		}
		let origLine = content.getString(lineStart,lineEnd - lineStart);
		process.stdout.write(Std.string("--- " + origLine));
		process.stdout.write("\n");
		if(toName != null) {
			let newContent = content.getString(0,pos.start) + toName + content.getString(pos.end,content.length - pos.end);
			let newLine = haxe_io_Bytes.ofString(newContent).getString(lineStart,lineEnd + (toName.length - (pos.end - pos.start) - lineStart));
			process.stdout.write(Std.string("+++ " + newLine));
			process.stdout.write("\n");
		}
	}
}
refactor_edits_Changelist.__name__ = true;
class refactor_edits_EditableDocument {
	constructor(fileName) {
		this.fileName = fileName;
		this.originalFileName = fileName;
		this.originalContent = js_node_buffer__$Buffer_Helper.bytesOfBuffer(js_node_Fs.readFileSync(fileName));
		this.refactoredContent = new StringBuf();
		this.lastPos = 0;
	}
	addChange(edit) {
		switch(edit._hx_index) {
		case 0:
			let newFileName = edit.newFileName;
			this.fileName = newFileName;
			break;
		case 1:
			let text = edit.text;
			let pos = edit.pos;
			let _this = this.refactoredContent;
			let x = this.originalContent.getString(this.lastPos,pos.start - this.lastPos);
			_this.b += Std.string(x);
			this.refactoredContent.b += text == null ? "null" : "" + text;
			this.lastPos = pos.end;
			break;
		case 2:
			let text1 = edit.text;
			let pos1 = edit.pos;
			let _this1 = this.refactoredContent;
			let x1 = this.originalContent.getString(this.lastPos,pos1.start - this.lastPos);
			_this1.b += Std.string(x1);
			this.refactoredContent.b += text1 == null ? "null" : "" + text1;
			this.lastPos = pos1.start;
			break;
		case 3:
			let pos2 = edit.pos;
			let _this2 = this.refactoredContent;
			let x2 = this.originalContent.getString(this.lastPos,pos2.start - this.lastPos);
			_this2.b += Std.string(x2);
			this.lastPos = pos2.end;
			break;
		}
	}
	endEdits() {
		if(this.lastPos < this.originalContent.length) {
			let _this = this.refactoredContent;
			let x = this.originalContent.getString(this.lastPos,this.originalContent.length - this.lastPos);
			_this.b += Std.string(x);
		}
		let folder = haxe_io_Path.directory(this.fileName);
		if(!sys_FileSystem.isDirectory(folder)) {
			sys_FileSystem.createDirectory(folder);
		}
		js_node_Fs.writeFileSync(this.fileName,this.refactoredContent.b);
		if(this.fileName != this.originalFileName) {
			js_node_Fs.unlinkSync(this.originalFileName);
		}
	}
}
refactor_edits_EditableDocument.__name__ = true;
var refactor_edits_FileEdit = $hxEnums["refactor.edits.FileEdit"] = { __ename__:true,__constructs__:null
	,Move: ($_=function(newFileName) { return {_hx_index:0,newFileName:newFileName,__enum__:"refactor.edits.FileEdit",toString:$estr}; },$_._hx_name="Move",$_.__params__ = ["newFileName"],$_)
	,ReplaceText: ($_=function(text,pos) { return {_hx_index:1,text:text,pos:pos,__enum__:"refactor.edits.FileEdit",toString:$estr}; },$_._hx_name="ReplaceText",$_.__params__ = ["text","pos"],$_)
	,InsertText: ($_=function(text,pos) { return {_hx_index:2,text:text,pos:pos,__enum__:"refactor.edits.FileEdit",toString:$estr}; },$_._hx_name="InsertText",$_.__params__ = ["text","pos"],$_)
	,RemoveText: ($_=function(pos) { return {_hx_index:3,pos:pos,__enum__:"refactor.edits.FileEdit",toString:$estr}; },$_._hx_name="RemoveText",$_.__params__ = ["pos"],$_)
};
refactor_edits_FileEdit.__constructs__ = [refactor_edits_FileEdit.Move,refactor_edits_FileEdit.ReplaceText,refactor_edits_FileEdit.InsertText,refactor_edits_FileEdit.RemoveText];
class refactor_rename_RenameAnonStructField {
	static refactorAnonStructField(context,file,identifier,fields) {
		let changelist = new refactor_edits_Changelist(context);
		changelist.addChange(identifier.pos.fileName,refactor_edits_FileEdit.ReplaceText(context.what.toName,identifier.pos),identifier);
		return refactor_rename_RenameAnonStructField.renameFieldsOfType(context,changelist,identifier.defineType,fields,identifier.name).then(function(result) {
			return changelist.execute();
		});
	}
	static refactorStructureField(context,file,identifier,fieldNames) {
		let allUses = context.nameMap.getIdentifiers(identifier.name);
		let _g = 0;
		while(_g < allUses.length) {
			let use = allUses[_g];
			++_g;
			let _g1 = use.type;
			if(_g1._hx_index == 21) {
				let fields = _g1.fields;
				fields = fields.concat(refactor_rename_RenameAnonStructField.findBaseTypes(context,use.defineType));
				if(refactor_rename_RenameAnonStructField.matchesFields(fields,fieldNames)) {
					return refactor_rename_RenameAnonStructField.refactorAnonStructField(context,use.file,use,fields);
				}
			} else {
				continue;
			}
		}
		return Promise.resolve(refactor_RefactorResult.Unsupported(identifier.toString()));
	}
	static renameFieldsOfType(context,changelist,type,fields,fromName) {
		let packName = type.file.getPackage();
		let mainModuleName = type.file.getMainModulName();
		fields = fields.concat(refactor_rename_RenameAnonStructField.findBaseTypes(context,type));
		let allUses = context.nameMap.matchIdentifierPart(fromName,true);
		let promises = [];
		let _g = 0;
		while(_g < allUses.length) {
			let use = allUses[_g];
			++_g;
			let _g1 = use.type;
			switch(_g1._hx_index) {
			case 22:
				let fieldNames = _g1.fieldNames;
				if(!refactor_rename_RenameAnonStructField.matchesFields(fields,fieldNames)) {
					continue;
				}
				break;
			case 29:
				if(_g1.isNew == false) {
					promises.push(refactor_rename_RenameHelper.replaceSingleAccessOrCall(context,changelist,use,fromName,[type]));
					continue;
				} else {
					continue;
				}
				break;
			case 31:
				promises.push(refactor_rename_RenameHelper.replaceSingleAccessOrCall(context,changelist,use,fromName,[type]));
				continue;
			default:
				continue;
			}
			let _g2 = use.file.importsModule(packName,mainModuleName,type.name.name);
			switch(_g2._hx_index) {
			case 0:
				continue;
			case 4:
				let _g3 = _g2.alias;
				break;
			case 1:case 2:case 3:case 5:
				break;
			}
			changelist.addChange(use.pos.fileName,refactor_edits_FileEdit.ReplaceText(context.what.toName,use.pos),use);
		}
		promises.push(refactor_rename_RenameAnonStructField.findAllExtending(context,changelist,type,fields,fromName));
		return Promise.all(promises).then(null);
	}
	static findAllExtending(context,changelist,type,fields,fromName) {
		let allUses = context.nameMap.getIdentifiers(type.name.name);
		let promises = [];
		let _g = 0;
		while(_g < allUses.length) {
			let use = allUses[_g];
			++_g;
			if(use.type._hx_index == 20) {
				promises.push(refactor_rename_RenameAnonStructField.renameFieldsOfType(context,changelist,use.defineType,refactor_rename_RenameAnonStructField.getFieldsOfTypedef(use.defineType),fromName));
			}
		}
		return Promise.all(promises).then(null);
	}
	static matchesFields(fields,fieldNames) {
		let allowedFieldNames = [];
		let _g = 0;
		while(_g < fields.length) {
			let field = fields[_g];
			++_g;
			switch(field._hx_index) {
			case 0:
				let identifier = field.identifier;
				allowedFieldNames.push(identifier.name);
				if(!fieldNames.includes(identifier.name)) {
					return false;
				}
				break;
			case 1:
				let identifier1 = field.identifier;
				allowedFieldNames.push(identifier1.name);
				break;
			}
		}
		let _g1 = 0;
		while(_g1 < fieldNames.length) {
			let fieldName = fieldNames[_g1];
			++_g1;
			if(!allowedFieldNames.includes(fieldName)) {
				return false;
			}
		}
		return true;
	}
	static findBaseTypes(context,type) {
		let fieldTypes = [];
		let baseTypes = type.findAllIdentifiers(function(i) {
			if(i.type._hx_index == 20) {
				return true;
			} else {
				return false;
			}
		});
		let _g = 0;
		while(_g < baseTypes.length) {
			let baseTypeName = baseTypes[_g];
			++_g;
			let base = refactor_rename_RenameAnonStructField.findBase(context,baseTypeName);
			if(base == null) {
				continue;
			}
			fieldTypes = fieldTypes.concat(refactor_rename_RenameAnonStructField.getFieldsOfTypedef(base));
		}
		return fieldTypes;
	}
	static getFieldsOfTypedef(type) {
		let allChilds = type.findAllIdentifiers(function(i) {
			return true;
		});
		let _g = 0;
		while(_g < allChilds.length) {
			let child = allChilds[_g];
			++_g;
			let _g1 = child.type;
			if(_g1._hx_index == 21) {
				let fields = _g1.fields;
				return fields;
			}
		}
		return [];
	}
	static findBase(context,baseTypeName) {
		let allUses = context.nameMap.getIdentifiers(baseTypeName.name);
		let _g = 0;
		while(_g < allUses.length) {
			let use = allUses[_g];
			++_g;
			if(use.type._hx_index != 8) {
				continue;
			}
			let _g1 = baseTypeName.file.importsModule(use.file.getPackage(),use.file.getMainModulName(),baseTypeName.name);
			switch(_g1._hx_index) {
			case 0:
				continue;
			case 4:
				let _g2 = _g1.alias;
				break;
			case 1:case 2:case 3:case 5:
				break;
			}
			return use.defineType;
		}
		return null;
	}
}
refactor_rename_RenameAnonStructField.__name__ = true;
class refactor_rename_RenameEnumField {
	static refactorEnumField(context,file,identifier) {
		let changelist = new refactor_edits_Changelist(context);
		changelist.addChange(identifier.pos.fileName,refactor_edits_FileEdit.ReplaceText(context.what.toName,identifier.pos),identifier);
		let packName = file.getPackage();
		let mainModuleName = file.getMainModulName();
		let typeName = identifier.defineType.name.name;
		let fullModuleTypeName = identifier.defineType.getFullModulName();
		let allUses = context.nameMap.getIdentifiers("" + typeName + "." + identifier.name);
		let _g = 0;
		while(_g < allUses.length) {
			let use = allUses[_g];
			++_g;
			let _g1 = use.file.importsModule(packName,mainModuleName,typeName);
			switch(_g1._hx_index) {
			case 0:
				continue;
			case 4:
				let alias = _g1.alias;
				if(alias != typeName) {
					continue;
				}
				break;
			case 1:case 2:case 3:case 5:
				break;
			}
			refactor_rename_RenameHelper.replaceTextWithPrefix(use,typeName,context.what.toName,changelist);
		}
		allUses = context.nameMap.getIdentifiers("" + fullModuleTypeName + "." + identifier.name);
		let _g1 = 0;
		while(_g1 < allUses.length) {
			let use = allUses[_g1];
			++_g1;
			refactor_rename_RenameHelper.replaceTextWithPrefix(use,fullModuleTypeName,context.what.toName,changelist);
		}
		allUses = context.nameMap.matchIdentifierPart(identifier.name,true);
		let changes = [];
		let _g2 = 0;
		while(_g2 < allUses.length) {
			let use = allUses[_g2];
			++_g2;
			let _g = use.type;
			switch(_g._hx_index) {
			case 28:
				let switchIdentifier = _g.switchIdentifier;
				changes.push(refactor_rename_RenameHelper.matchesType(context,{ name : switchIdentifier.name, pos : switchIdentifier.pos.start, defineType : switchIdentifier.defineType},refactor_rename_TypeHintType.KnownType(identifier.defineType,[])).then(function(matched) {
					if(matched) {
						refactor_rename_RenameHelper.replaceTextWithPrefix(use,"",context.what.toName,changelist);
					}
				}));
				continue;
			case 29:
				if(_g.isNew == false) {
					let _g = use.parent.type;
					if(_g._hx_index == 29) {
						let _g1 = _g.isNew;
					} else {
						continue;
					}
					let _g1 = use.file.importsModule(packName,mainModuleName,typeName);
					switch(_g1._hx_index) {
					case 0:
						continue;
					case 4:
						let alias = _g1.alias;
						if(alias != typeName) {
							continue;
						}
						break;
					case 1:case 2:case 3:case 5:
						break;
					}
				} else {
					continue;
				}
				break;
			case 31:
				let _g1 = use.parent.type;
				if(_g1._hx_index == 29) {
					let _g = _g1.isNew;
				} else {
					continue;
				}
				let _g3 = use.file.importsModule(packName,mainModuleName,typeName);
				switch(_g3._hx_index) {
				case 0:
					continue;
				case 4:
					let alias = _g3.alias;
					if(alias != typeName) {
						continue;
					}
					break;
				case 1:case 2:case 3:case 5:
					break;
				}
				break;
			default:
				continue;
			}
			refactor_rename_RenameHelper.replaceTextWithPrefix(use,"",context.what.toName,changelist);
		}
		return Promise.all(changes).then(function(_) {
			return changelist.execute();
		});
	}
}
refactor_rename_RenameEnumField.__name__ = true;
class refactor_rename_RenameField {
	static refactorField(context,file,identifier,isStatic) {
		let changelist = new refactor_edits_Changelist(context);
		let packName = file.getPackage();
		let types = refactor_rename_RenameHelper.findDescendantTypes(context,packName,identifier.defineType);
		types.push(identifier.defineType);
		let changes = [];
		let _g = 0;
		while(_g < types.length) {
			let type = types[_g];
			++_g;
			refactor_rename_RenameField.replaceInType(changelist,type,"",identifier.name,context.what.toName);
			refactor_rename_RenameField.replaceInTypeWithFieldAccess(changelist,type,"",identifier.name,context.what.toName);
			refactor_rename_RenameField.replaceInType(changelist,type,"super.",identifier.name,context.what.toName);
			refactor_rename_RenameField.replaceInType(changelist,type,"this.",identifier.name,context.what.toName);
			refactor_rename_RenameField.replaceInTypeWithFieldAccess(changelist,type,"this.",identifier.name,context.what.toName);
			if(identifier.type._hx_index == 23) {
				refactor_rename_RenameField.replaceInType(changelist,type,"set_",identifier.name,context.what.toName);
				refactor_rename_RenameField.replaceInType(changelist,type,"get_",identifier.name,context.what.toName);
			}
			if(isStatic) {
				refactor_rename_RenameField.replaceStaticUse(context,changelist,type,identifier.name);
				let _g = identifier.type;
				if(_g._hx_index == 18) {
					if(_g.isStatic == true) {
						changes.push(refactor_rename_RenameHelper.replaceStaticExtension(context,changelist,identifier));
					}
				}
			}
		}
		changes.push(refactor_rename_RenameField.replaceAccessOrCalls(context,changelist,identifier,types));
		return Promise.all(changes).then(function(_) {
			return changelist.execute();
		});
	}
	static replaceAccessOrCalls(context,changelist,identifier,types) {
		let allUses = context.nameMap.matchIdentifierPart(identifier.name,true);
		let changes = [];
		let _g = 0;
		while(_g < allUses.length) {
			let use = allUses[_g];
			++_g;
			changes.push(refactor_rename_RenameHelper.replaceSingleAccessOrCall(context,changelist,use,identifier.name,types));
		}
		return Promise.all(changes).then(null);
	}
	static replaceInType(changelist,type,prefix,from,to) {
		let allUses = type.getIdentifiers(prefix + from);
		let innerScopeStart = 0;
		let innerScopeEnd = -1;
		let _g = 0;
		while(_g < allUses.length) {
			let use = allUses[_g];
			++_g;
			if(innerScopeStart < use.pos.start && use.pos.start < innerScopeEnd) {
				continue;
			}
			let _g1 = use.type;
			switch(_g1._hx_index) {
			case 22:
				let _g2 = _g1.fieldNames;
				continue;
			case 33:
				let _g3 = _g1.scopeType;
				let start = _g1.scopeStart;
				let end = _g1.scopeEnd;
				innerScopeStart = start;
				innerScopeEnd = end;
				continue;
			default:
			}
			refactor_rename_RenameHelper.replaceTextWithPrefix(use,prefix,to,changelist);
		}
	}
	static replaceInTypeWithFieldAccess(changelist,type,prefix,from,to) {
		let allUses = type.getIdentifiers(prefix + from);
		let allAccess = type.getStartsWith("" + prefix + from + ".");
		let shadowed = false;
		let _g = 0;
		while(_g < allAccess.length) {
			let access = allAccess[_g];
			++_g;
			let _g1 = 0;
			_hx_loop2: while(_g1 < allUses.length) {
				let use = allUses[_g1];
				++_g1;
				if(use.pos.start > access.pos.start) {
					break;
				}
				let _g = use.type;
				switch(_g._hx_index) {
				case 22:
					let _g2 = _g.fieldNames;
					break;
				case 33:
					let _g3 = _g.scopeStart;
					let _g4 = _g.scopeType;
					let end = _g.scopeEnd;
					if(end > access.pos.start) {
						shadowed = true;
						break _hx_loop2;
					}
					break;
				default:
				}
			}
			if(shadowed) {
				continue;
			}
			let pos = { fileName : access.pos.fileName, start : access.pos.start + prefix.length, end : access.pos.start + prefix.length + from.length};
			changelist.addChange(access.pos.fileName,refactor_edits_FileEdit.ReplaceText(to,pos),access);
		}
	}
	static replaceStaticUse(context,changelist,type,fromName) {
		let packName = type.file.getPackage();
		let allUses = context.nameMap.getIdentifiers("" + type.name.name + "." + fromName);
		let _g = 0;
		while(_g < allUses.length) {
			let use = allUses[_g];
			++_g;
			let _g1 = use.file.importsModule(packName,type.file.getMainModulName(),type.name.name);
			switch(_g1._hx_index) {
			case 0:
				continue;
			case 4:
				let _g2 = _g1.alias;
				continue;
			case 1:case 2:case 3:case 5:
				break;
			}
			refactor_rename_RenameHelper.replaceTextWithPrefix(use,"" + type.name.name + ".",context.what.toName,changelist);
		}
		let fullModuleName = type.getFullModulName();
		let allUses1 = context.nameMap.getIdentifiers("" + fullModuleName + "." + fromName);
		let _g1 = 0;
		while(_g1 < allUses1.length) {
			let use = allUses1[_g1];
			++_g1;
			refactor_rename_RenameHelper.replaceTextWithPrefix(use,"" + fullModuleName + ".",context.what.toName,changelist);
		}
	}
}
refactor_rename_RenameField.__name__ = true;
class refactor_rename_RenameHelper {
	static replaceTextWithPrefix(use,prefix,to,changelist) {
		if(prefix.length <= 0) {
			changelist.addChange(use.pos.fileName,refactor_edits_FileEdit.ReplaceText(to,use.pos),use);
		} else {
			let pos = { fileName : use.pos.fileName, start : use.pos.start + prefix.length, end : use.pos.end};
			changelist.addChange(use.pos.fileName,refactor_edits_FileEdit.ReplaceText(to,pos),use);
		}
	}
	static findDescendantTypes(context,packName,baseType) {
		let types = [];
		let fullModulName = "" + packName + "." + baseType.name.name;
		let pushType = function(newType) {
			let _g = 0;
			while(_g < types.length) {
				let type = types[_g];
				++_g;
				if(type.file.name == newType.file.name && type.name.name == newType.name.name) {
					return;
				}
			}
			types.push(newType);
		};
		let searchImplementingTypes = function(types,search) {
			let _g = 0;
			while(_g < types.length) {
				let type = types[_g];
				++_g;
				let _g1 = 0;
				let _g2 = type.getIdentifiers(search);
				while(_g1 < _g2.length) {
					let use = _g2[_g1];
					++_g1;
					switch(use.type._hx_index) {
					case 11:case 12:
						pushType(use.defineType);
						break;
					case 13:
						pushType(use.defineType);
						break;
					default:
					}
				}
			}
		};
		let allUses = context.nameMap.getIdentifiers(fullModulName);
		let _g = 0;
		while(_g < allUses.length) {
			let use = allUses[_g];
			++_g;
			switch(use.type._hx_index) {
			case 1:
				let search;
				let _g1 = use.file.importsModule(baseType.file.getPackage(),baseType.file.getMainModulName(),baseType.name.name);
				switch(_g1._hx_index) {
				case 0:
					continue;
				case 4:
					let alias = _g1.alias;
					search = alias;
					break;
				case 1:case 2:case 3:case 5:
					search = baseType.name.name;
					break;
				}
				searchImplementingTypes(use.file.typeList,search);
				break;
			case 11:case 12:
				pushType(use.defineType);
				break;
			case 13:
				pushType(use.defineType);
				break;
			default:
			}
		}
		allUses = context.nameMap.getIdentifiers(baseType.name.name);
		let _g1 = 0;
		while(_g1 < allUses.length) {
			let use = allUses[_g1];
			++_g1;
			switch(use.type._hx_index) {
			case 11:case 12:
				pushType(use.defineType);
				break;
			case 13:
				pushType(use.defineType);
				break;
			default:
			}
		}
		let _g2 = 0;
		while(_g2 < types.length) {
			let type = types[_g2];
			++_g2;
			let _g = 0;
			let _g1 = refactor_rename_RenameHelper.findDescendantTypes(context,type.file.getPackage(),type);
			while(_g < _g1.length) {
				let t = _g1[_g];
				++_g;
				pushType(t);
			}
		}
		return types;
	}
	static matchesType(context,searchTypeOf,searchType) {
		return refactor_rename_RenameHelper.findTypeOfIdentifier(context,searchTypeOf).then(function(identifierType) {
			if(identifierType == null) {
				return false;
			}
			if(identifierType == null) {
				let context1 = context;
				let tmp = "types do not match for static extension " + searchTypeOf.name + ":" + refactor_PrintHelper.printTypeHint(identifierType) + " != " + refactor_PrintHelper.printTypeHint(searchType);
				context1.verboseLog(tmp,{ fileName : "src/refactor/rename/RenameHelper.hx", lineNumber : 121, className : "refactor.rename.RenameHelper", methodName : "matchesType"});
				return false;
			} else {
				switch(identifierType._hx_index) {
				case 0:
					if(searchType._hx_index == 0) {
						let type2 = searchType.type;
						let params2 = searchType.typeParams;
						let params1 = identifierType.typeParams;
						let type1 = identifierType.type;
						if(type1.getFullModulName() != type2.getFullModulName()) {
							return false;
						}
						if(params1.length != params2.length) {
							return false;
						}
						let _g = 0;
						let _g1 = params1.length;
						while(_g < _g1) {
							let index = _g++;
							if(params1[index].name != params2[index].name) {
								return false;
							}
						}
						return true;
					} else {
						let context1 = context;
						let tmp = "types do not match for static extension " + searchTypeOf.name + ":" + refactor_PrintHelper.printTypeHint(identifierType) + " != " + refactor_PrintHelper.printTypeHint(searchType);
						context1.verboseLog(tmp,{ fileName : "src/refactor/rename/RenameHelper.hx", lineNumber : 121, className : "refactor.rename.RenameHelper", methodName : "matchesType"});
						return false;
					}
					break;
				case 1:
					if(searchType._hx_index == 1) {
						let name2 = searchType.name;
						let params2 = searchType.typeParams;
						let params1 = identifierType.typeParams;
						let name1 = identifierType.name;
						if(name1 != name2) {
							return false;
						}
						if(params1.length != params2.length) {
							return false;
						}
						let _g = 0;
						let _g1 = params1.length;
						while(_g < _g1) {
							let index = _g++;
							if(params1[index].name != params2[index].name) {
								return false;
							}
						}
						return true;
					} else {
						let context1 = context;
						let tmp = "types do not match for static extension " + searchTypeOf.name + ":" + refactor_PrintHelper.printTypeHint(identifierType) + " != " + refactor_PrintHelper.printTypeHint(searchType);
						context1.verboseLog(tmp,{ fileName : "src/refactor/rename/RenameHelper.hx", lineNumber : 121, className : "refactor.rename.RenameHelper", methodName : "matchesType"});
						return false;
					}
					break;
				}
			}
		});
	}
	static findTypeWithTyper(context,fileName,pos) {
		if(context.typer == null) {
			return Promise.reject("no typer");
		}
		return context.typer.resolveType(fileName,pos);
	}
	static findTypeOfIdentifier(context,searchTypeOf) {
		let parts = searchTypeOf.name.split(".");
		let part = parts.shift();
		return refactor_rename_RenameHelper.findFieldOrScopedLocal(context,searchTypeOf.defineType,part,searchTypeOf.pos).then(function(type) {
			let index = 0;
			let findFieldForPart = null;
			findFieldForPart = function(partType) {
				if(index >= parts.length) {
					return Promise.resolve(partType);
				}
				index += 1;
				let part = parts[index - 1];
				if(partType == null) {
					context.verboseLog("unable to determine type of \"" + part + "\" in " + searchTypeOf.defineType.file.name + "@" + searchTypeOf.pos,{ fileName : "src/refactor/rename/RenameHelper.hx", lineNumber : 147, className : "refactor.rename.RenameHelper", methodName : "findTypeOfIdentifier"});
					return Promise.reject("unable to determine type of \"" + part + "\" in " + searchTypeOf.defineType.file.name + "@" + searchTypeOf.pos);
				} else {
					switch(partType._hx_index) {
					case 0:
						let t = partType.type;
						let params = partType.typeParams;
						return refactor_rename_RenameHelper.findField(context,t,part).then(findFieldForPart);
					case 1:
						let _g = partType.typeParams;
						let name = partType.name;
						return Promise.reject("unable to determine type of \"" + part + "\" in " + searchTypeOf.defineType.name.name + "@" + searchTypeOf.pos);
					}
				}
			};
			return findFieldForPart(type);
		});
	}
	static findFieldOrScopedLocal(context,containerType,name,pos) {
		return refactor_rename_RenameHelper.findTypeWithTyper(context,containerType.file.name,pos).catch(function(msg) {
			let allUses = containerType.getIdentifiers(name);
			let candidate = null;
			let fieldCandidate = null;
			let _g = 0;
			while(_g < allUses.length) {
				let use = allUses[_g];
				++_g;
				let _g1 = use.type;
				switch(_g1._hx_index) {
				case 16:
					fieldCandidate = use;
					break;
				case 17:
					let _g2 = _g1.isStatic;
					fieldCandidate = use;
					break;
				case 18:
					let _g3 = _g1.isStatic;
					fieldCandidate = use;
					break;
				case 21:
					let _g4 = _g1.fields;
					fieldCandidate = use;
					break;
				case 27:
					let _g5 = _g1.params;
					return Promise.resolve(refactor_rename_TypeHintType.KnownType(use.defineType,[]));
				case 28:
					let switchIdentifier = _g1.switchIdentifier;
					if(use.pos.start == pos) {
						return refactor_rename_RenameHelper.findFieldOrScopedLocal(context,containerType,switchIdentifier.name,switchIdentifier.pos.start);
					}
					break;
				case 33:
					let _g6 = _g1.scopeType;
					let scopeStart = _g1.scopeStart;
					let scopeEnd = _g1.scopeEnd;
					if(pos >= scopeStart && pos <= scopeEnd) {
						candidate = use;
					}
					if(pos == use.pos.start) {
						candidate = use;
					}
					break;
				default:
				}
			}
			if(candidate == null) {
				candidate = fieldCandidate;
			}
			if(candidate == null) {
				return Promise.resolve(null);
			}
			let typeHint = candidate.getTypeHint();
			let _g1 = candidate.type;
			if(_g1._hx_index == 33) {
				let _g = _g1.scopeStart;
				let _g2 = _g1.scopeEnd;
				let _g3 = _g1.scopeType;
				switch(_g3._hx_index) {
				case 0:
					let params = _g3.params;
					if(typeHint != null) {
						return refactor_rename_RenameHelper.typeFromTypeHint(context,typeHint);
					}
					let index = params.indexOf(candidate);
					let _g4 = candidate.parent.type;
					if(_g4._hx_index == 28) {
						let switchIdentifier = _g4.switchIdentifier;
						return refactor_rename_RenameHelper.findFieldOrScopedLocal(context,containerType,switchIdentifier.name,switchIdentifier.pos.start).then(function(enumType) {
							if(enumType == null) {
								return Promise.resolve(null);
							} else {
								switch(enumType._hx_index) {
								case 0:
									let type = enumType.type;
									let typeParams = enumType.typeParams;
									if(type.name.type._hx_index == 6) {
										let enumFields = type.findAllIdentifiers(function(i) {
											return i.name == candidate.parent.name;
										});
										let _g = 0;
										while(_g < enumFields.length) {
											let field = enumFields[_g];
											++_g;
											let _g1 = field.type;
											if(_g1._hx_index == 27) {
												let params = _g1.params;
												if(params.length <= index) {
													return Promise.resolve(null);
												}
												typeHint = params[index].getTypeHint();
												if(typeHint == null) {
													return Promise.resolve(null);
												}
												return refactor_rename_RenameHelper.typeFromTypeHint(context,typeHint);
											} else {
												return Promise.reject("not an enum field");
											}
										}
									}
									break;
								case 1:
									let _g = enumType.name;
									let _g1 = enumType.typeParams;
									return Promise.resolve(null);
								}
							}
							return Promise.resolve(enumType);
						});
					}
					break;
				case 3:
					let loopIdent = _g3.loopIdentifiers;
					let index1 = loopIdent.indexOf(candidate);
					let changes = [];
					let _g5 = 0;
					while(_g5 < loopIdent.length) {
						let child = loopIdent[_g5];
						++_g5;
						let _g = child.type;
						if(_g._hx_index == 33) {
							let _g1 = _g.scopeStart;
							let _g2 = _g.scopeEnd;
							let _g3 = _g.scopeType;
							if(_g3._hx_index == 3) {
								let _g = _g3.loopIdentifiers;
								continue;
							} else {
								changes.push(refactor_rename_RenameHelper.findTypeOfIdentifier(context,{ name : child.name, pos : child.pos.start, defineType : containerType}).then(function(data) {
									if(data != null) {
										switch(data._hx_index) {
										case 0:
											let _g = data.type;
											let typeParams = data.typeParams;
											if(typeParams.length <= index1) {
												return Promise.reject("not enough type parameters");
											}
											return refactor_rename_RenameHelper.typeFromTypeHint(context,typeParams[index1]);
										case 1:
											let _g1 = data.name;
											let typeParams1 = data.typeParams;
											if(typeParams1.length <= index1) {
												return Promise.reject("not enough type parameters");
											}
											return refactor_rename_RenameHelper.typeFromTypeHint(context,typeParams1[index1]);
										}
									}
									return Promise.reject("not found");
								}));
							}
						} else {
							changes.push(refactor_rename_RenameHelper.findTypeOfIdentifier(context,{ name : child.name, pos : child.pos.start, defineType : containerType}).then(function(data) {
								if(data != null) {
									switch(data._hx_index) {
									case 0:
										let _g = data.type;
										let typeParams = data.typeParams;
										if(typeParams.length <= index1) {
											return Promise.reject("not enough type parameters");
										}
										return refactor_rename_RenameHelper.typeFromTypeHint(context,typeParams[index1]);
									case 1:
										let _g1 = data.name;
										let typeParams1 = data.typeParams;
										if(typeParams1.length <= index1) {
											return Promise.reject("not enough type parameters");
										}
										return refactor_rename_RenameHelper.typeFromTypeHint(context,typeParams1[index1]);
									}
								}
								return Promise.reject("not found");
							}));
						}
					}
					let winner = Promise.race(changes);
					return winner.catch(function(data) {
						if(typeHint != null) {
							return refactor_rename_RenameHelper.typeFromTypeHint(context,typeHint);
						}
						return Promise.reject("type not found");
					});
				default:
				}
			}
			if(typeHint != null) {
				return refactor_rename_RenameHelper.typeFromTypeHint(context,typeHint);
			}
			return Promise.resolve(null);
		});
	}
	static findField(context,containerType,name) {
		let allUses = containerType.getIdentifiers(name);
		let candidate = null;
		let _g = 0;
		_hx_loop1: while(_g < allUses.length) {
			let use = allUses[_g];
			++_g;
			let _g1 = use.type;
			switch(_g1._hx_index) {
			case 16:
				candidate = use;
				break _hx_loop1;
			case 17:
				let _g2 = _g1.isStatic;
				candidate = use;
				break _hx_loop1;
			case 18:
				let _g3 = _g1.isStatic;
				candidate = use;
				break _hx_loop1;
			case 21:
				let _g4 = _g1.fields;
				candidate = use;
				break _hx_loop1;
			case 27:
				let _g5 = _g1.params;
				candidate = use;
				break _hx_loop1;
			default:
			}
		}
		if(candidate == null || candidate.uses == null) {
			switch(containerType.name.type._hx_index) {
			case 5:
				let baseType = refactor_rename_RenameHelper.findBaseClass(context.typeList,containerType);
				if(baseType == null) {
					return Promise.resolve(null);
				}
				return refactor_rename_RenameHelper.findField(context,baseType,name);
			case 8:
				break;
			default:
			}
			return Promise.resolve(null);
		}
		let _g1 = 0;
		let _g2 = candidate.uses;
		while(_g1 < _g2.length) {
			let use = _g2[_g1];
			++_g1;
			if(use.type._hx_index == 26) {
				return refactor_rename_RenameHelper.typeFromTypeHint(context,use);
			}
		}
		return Promise.resolve(null);
	}
	static findBaseClass(typeList,type) {
		let baseClasses = type.findAllIdentifiers(function(i) {
			if(i.type._hx_index == 11) {
				return true;
			} else {
				return false;
			}
		});
		let _g = 0;
		while(_g < baseClasses.length) {
			let base = baseClasses[_g];
			++_g;
			let candidateTypes = typeList.findTypeName(base.name);
			let _g1 = 0;
			while(_g1 < candidateTypes.length) {
				let candidate = candidateTypes[_g1];
				++_g1;
				let _g = type.file.importsModule(candidate.file.getPackage(),candidate.file.getMainModulName(),candidate.name.name);
				switch(_g._hx_index) {
				case 0:
					break;
				case 4:
					let _g2 = _g.alias;
					break;
				case 1:case 2:case 3:case 5:
					return candidate;
				}
			}
		}
		return null;
	}
	static typeFromTypeHint(context,hint) {
		if(hint.name == "Null") {
			if(hint.uses == null || hint.uses.length <= 0) {
				return Promise.reject();
			}
			return refactor_rename_RenameHelper.typeFromTypeHint(context,hint.uses[0]);
		}
		let parts = hint.name.split(".");
		let typeName = parts.pop();
		let typeParams = [];
		if(hint.uses != null) {
			let _g = 0;
			let _g1 = hint.uses;
			while(_g < _g1.length) {
				let use = _g1[_g];
				++_g;
				if(use.type._hx_index == 19) {
					typeParams.push(use);
				}
			}
		}
		let allTypes = context.typeList.findTypeName(typeName);
		if(parts.length > 0) {
			let _g = 0;
			while(_g < allTypes.length) {
				let type = allTypes[_g];
				++_g;
				if(type.getFullModulName() == hint.name) {
					return Promise.resolve(refactor_rename_TypeHintType.KnownType(type,typeParams));
				}
			}
			return Promise.resolve(refactor_rename_TypeHintType.UnknownType(hint.name,typeParams));
		}
		let _g = 0;
		while(_g < allTypes.length) {
			let type = allTypes[_g];
			++_g;
			let _g1 = hint.file.importsModule(type.file.getPackage(),type.file.getMainModulName(),type.name.name);
			switch(_g1._hx_index) {
			case 0:
				break;
			case 4:
				let _g2 = _g1.alias;
				break;
			case 1:case 2:case 3:case 5:
				return Promise.resolve(refactor_rename_TypeHintType.KnownType(type,typeParams));
			}
		}
		return Promise.resolve(refactor_rename_TypeHintType.UnknownType(hint.name,typeParams));
	}
	static replaceStaticExtension(context,changelist,identifier) {
		let allUses = context.nameMap.matchIdentifierPart(identifier.name,true);
		if(identifier.uses == null) {
			return Promise.resolve(null);
		}
		let firstParam = null;
		let _g = 0;
		let _g1 = identifier.uses;
		while(_g < _g1.length) {
			let use = _g1[_g];
			++_g;
			let _g2 = use.type;
			if(_g2._hx_index == 33) {
				let _g = _g2.scopeStart;
				let _g1 = _g2.scopeEnd;
				let _g3 = _g2.scopeType;
				if(_g3._hx_index == 0) {
					let _g = _g3.params;
					firstParam = use;
					break;
				}
			}
		}
		if(firstParam == null) {
			return Promise.resolve(null);
		}
		let changes = [];
		let _g2 = 0;
		let _g3 = firstParam.uses;
		while(_g2 < _g3.length) {
			let use = _g3[_g2];
			++_g2;
			if(use.type._hx_index == 26) {
				changes.push(refactor_rename_RenameHelper.typeFromTypeHint(context,use).then(function(firstParamType) {
					if(firstParamType == null) {
						context.verboseLog("could not find type of first parameter for static extension",{ fileName : "src/refactor/rename/RenameHelper.hx", lineNumber : 397, className : "refactor.rename.RenameHelper", methodName : "replaceStaticExtension"});
						return Promise.resolve(null);
					}
					let innerChanges = [];
					let _g = 0;
					while(_g < allUses.length) {
						let use = allUses[_g];
						++_g;
						let object = "";
						if(use.name == identifier.name) {
							if(use.parent != null) {
								if(firstParamType != null) {
									switch(firstParamType._hx_index) {
									case 0:
										let _g = firstParamType.typeParams;
										let type = firstParamType.type;
										if(use.parent.name == type.name.name) {
											changelist.addChange(use.pos.fileName,refactor_edits_FileEdit.ReplaceText(context.what.toName,use.pos),use);
											continue;
										}
										break;
									case 1:
										let _g1 = firstParamType.typeParams;
										let name = firstParamType.name;
										if(use.parent.name == name) {
											changelist.addChange(use.pos.fileName,refactor_edits_FileEdit.ReplaceText(context.what.toName,use.pos),use);
											continue;
										}
										break;
									}
								}
							}
							object = use.name;
						} else {
							object = HxOverrides.substr(use.name,0,use.name.length - identifier.name.length - 1);
						}
						innerChanges.push(refactor_rename_RenameHelper.matchesType(context,{ name : object, pos : use.pos.start, defineType : use.defineType},firstParamType).then(function(matches) {
							if(matches) {
								refactor_rename_RenameHelper.replaceTextWithPrefix(use,"" + object + ".",context.what.toName,changelist);
							}
						}));
					}
					return Promise.all(innerChanges).then(null);
				}));
			}
		}
		return Promise.all(changes).then(null);
	}
	static replaceSingleAccessOrCall(context,changelist,use,fromName,types) {
		let name = use.name;
		let index = name.lastIndexOf("." + fromName);
		if(index < 0) {
			let _g = use.type;
			if(_g._hx_index == 30) {
				let posClosing = _g.posClosing;
				return refactor_rename_RenameHelper.replaceArrayAccess(context,changelist,use,fromName,types,posClosing);
			}
			return Promise.resolve(null);
		}
		name = HxOverrides.substr(name,0,index);
		let search = { name : name, pos : use.pos.start, defineType : use.defineType};
		return refactor_rename_RenameHelper.findTypeOfIdentifier(context,search).then(function(typeHint) {
			if(typeHint != null) {
				switch(typeHint._hx_index) {
				case 0:
					let _g = typeHint.typeParams;
					let type = typeHint.type;
					let _g1 = 0;
					while(_g1 < types.length) {
						let t = types[_g1];
						++_g1;
						if(t != type) {
							continue;
						}
						let pos = { fileName : use.pos.fileName, start : use.pos.start + name.length + 1, end : use.pos.end};
						pos.end = pos.start + fromName.length;
						changelist.addChange(use.pos.fileName,refactor_edits_FileEdit.ReplaceText(context.what.toName,pos),use);
					}
					break;
				case 1:
					let _g2 = typeHint.name;
					let _g3 = typeHint.typeParams;
					break;
				}
			}
		});
	}
	static replaceArrayAccess(context,changelist,use,fromName,types,posClosing) {
		let name = use.name;
		let search = { name : name, pos : posClosing, defineType : use.defineType};
		return refactor_rename_RenameHelper.findTypeOfIdentifier(context,search).then(function(typeHint) {
			if(typeHint != null) {
				switch(typeHint._hx_index) {
				case 0:
					let _g = typeHint.typeParams;
					let type = typeHint.type;
					let _g1 = 0;
					while(_g1 < types.length) {
						let t = types[_g1];
						++_g1;
						if(t != type) {
							continue;
						}
						let pos = { fileName : use.pos.fileName, start : use.pos.start, end : use.pos.end};
						pos.end = pos.start + fromName.length;
						changelist.addChange(use.pos.fileName,refactor_edits_FileEdit.ReplaceText(context.what.toName,pos),use);
					}
					break;
				case 1:
					let _g2 = typeHint.name;
					let _g3 = typeHint.typeParams;
					break;
				}
			}
		});
	}
}
refactor_rename_RenameHelper.__name__ = true;
var refactor_rename_TypeHintType = $hxEnums["refactor.rename.TypeHintType"] = { __ename__:true,__constructs__:null
	,KnownType: ($_=function(type,typeParams) { return {_hx_index:0,type:type,typeParams:typeParams,__enum__:"refactor.rename.TypeHintType",toString:$estr}; },$_._hx_name="KnownType",$_.__params__ = ["type","typeParams"],$_)
	,UnknownType: ($_=function(name,typeParams) { return {_hx_index:1,name:name,typeParams:typeParams,__enum__:"refactor.rename.TypeHintType",toString:$estr}; },$_._hx_name="UnknownType",$_.__params__ = ["name","typeParams"],$_)
};
refactor_rename_TypeHintType.__constructs__ = [refactor_rename_TypeHintType.KnownType,refactor_rename_TypeHintType.UnknownType];
class refactor_rename_RenameImportAlias {
	static refactorImportAlias(context,file,identifier) {
		let allUses = context.nameMap.getIdentifiers(identifier.name);
		let isImportHx = file.getMainModulName() == "import";
		let changelist = new refactor_edits_Changelist(context);
		let _g = 0;
		while(_g < allUses.length) {
			let use = allUses[_g];
			++_g;
			if(use.file.name == file.name) {
				changelist.addChange(use.pos.fileName,refactor_edits_FileEdit.ReplaceText(context.what.toName,use.pos),use);
				continue;
			}
			if(isImportHx) {
				if(use.file.importHxFile.name == file.name) {
					changelist.addChange(use.pos.fileName,refactor_edits_FileEdit.ReplaceText(context.what.toName,use.pos),use);
				}
			}
		}
		return Promise.resolve(changelist.execute());
	}
}
refactor_rename_RenameImportAlias.__name__ = true;
class refactor_rename_RenameModuleLevelStatic {
	static refactorModuleLevelStatic(context,file,identifier) {
		let changelist = new refactor_edits_Changelist(context);
		let packageName = file.getPackage();
		let mainModulName = file.getMainModulName();
		let filesWithStaticImport = [];
		let withModul = "" + mainModulName + "." + identifier.name;
		let newWithModul = "" + mainModulName + "." + context.what.toName;
		refactor_rename_RenameModuleLevelStatic.refactorIdentifier(context,changelist,withModul,newWithModul,filesWithStaticImport);
		if(packageName.length > 0) {
			let fullQualified = "" + packageName + "." + mainModulName + "." + identifier.name;
			let newFullQualified = "" + packageName + "." + mainModulName + "." + context.what.toName;
			refactor_rename_RenameModuleLevelStatic.refactorIdentifier(context,changelist,fullQualified,newFullQualified,filesWithStaticImport);
		}
		let allUses = context.nameMap.getIdentifiers(identifier.name);
		let _g = 0;
		while(_g < allUses.length) {
			let use = allUses[_g];
			++_g;
			if(use.pos.fileName != file.name && !filesWithStaticImport.includes(use.pos.fileName)) {
				continue;
			}
			changelist.addChange(use.pos.fileName,refactor_edits_FileEdit.ReplaceText(context.what.toName,use.pos),use);
		}
		let importModul = "" + packageName + "." + mainModulName;
		allUses = context.nameMap.getIdentifiers(importModul);
		let _g1 = 0;
		while(_g1 < allUses.length) {
			let use = allUses[_g1];
			++_g1;
			if(use.type._hx_index == 1) {
				let uses = use.file.findAllIdentifiers(function(i) {
					return i.name == identifier.name;
				});
				let _g = 0;
				while(_g < uses.length) {
					let u = uses[_g];
					++_g;
					let _g1 = u.type;
					switch(_g1._hx_index) {
					case 29:
						if(_g1.isNew == false) {
							changelist.addChange(u.pos.fileName,refactor_edits_FileEdit.ReplaceText(context.what.toName,u.pos),u);
						}
						break;
					case 31:
						changelist.addChange(u.pos.fileName,refactor_edits_FileEdit.ReplaceText(context.what.toName,u.pos),u);
						break;
					case 33:
						let _g2 = _g1.scopeStart;
						let _g3 = _g1.scopeEnd;
						let _g4 = _g1.scopeType;
						break;
					default:
					}
				}
			}
		}
		return refactor_rename_RenameHelper.replaceStaticExtension(context,changelist,identifier).then(function(_) {
			return changelist.execute();
		});
	}
	static refactorIdentifier(context,changelist,searchName,replaceName,filesWithStaticImport) {
		let allUses = context.nameMap.getIdentifiers(searchName);
		let _g = 0;
		while(_g < allUses.length) {
			let use = allUses[_g];
			++_g;
			if(use.type._hx_index == 1) {
				filesWithStaticImport.push(use.pos.fileName);
			}
			changelist.addChange(use.pos.fileName,refactor_edits_FileEdit.ReplaceText(replaceName,use.pos),use);
		}
		let searchNameDot = "" + searchName + ".";
		let replaceNameDot = "" + replaceName + ".";
		allUses = context.nameMap.getStartsWith(searchNameDot);
		let _g1 = 0;
		while(_g1 < allUses.length) {
			let use = allUses[_g1];
			++_g1;
			let pos = { fileName : use.pos.fileName, start : use.pos.start, end : use.pos.start + searchNameDot.length};
			changelist.addChange(use.pos.fileName,refactor_edits_FileEdit.ReplaceText(replaceNameDot,pos),use);
		}
	}
}
refactor_rename_RenameModuleLevelStatic.__name__ = true;
class refactor_rename_RenamePackage {
	static refactorPackageName(context,file,identifier) {
		let changelist = new refactor_edits_Changelist(context);
		let mainTypeName = file.getMainModulName();
		let packageNamePrefix = "";
		let packageName = file.getPackage();
		if(packageName.length > 0) {
			packageNamePrefix = file.packageIdentifier.name + ".";
			changelist.addChange(file.name,refactor_edits_FileEdit.ReplaceText(context.what.toName,file.packageIdentifier.pos),identifier);
		} else {
			changelist.addChange(file.name,refactor_edits_FileEdit.InsertText("package " + context.what.toName + ";\n",{ fileName : file.name, start : 0, end : 0}),identifier);
		}
		let newMainModulName = context.what.toName + "." + mainTypeName;
		let mainModule = packageNamePrefix + mainTypeName;
		let allUses = context.nameMap.getIdentifiers(mainModule);
		let _g = 0;
		while(_g < allUses.length) {
			let use = allUses[_g];
			++_g;
			changelist.addChange(use.pos.fileName,refactor_edits_FileEdit.ReplaceText(newMainModulName,use.pos),use);
		}
		let _g1 = 0;
		let _g2 = file.typeList;
		while(_g1 < _g2.length) {
			let type = _g2[_g1];
			++_g1;
			if(mainTypeName == type.name.name) {
				continue;
			}
			let typeName = type.name.name;
			let fullModulName = packageNamePrefix + typeName;
			let newFullModulName = context.what.toName + "." + typeName;
			allUses = context.nameMap.getIdentifiers(fullModulName);
			let _g = 0;
			while(_g < allUses.length) {
				let use = allUses[_g];
				++_g;
				changelist.addChange(use.pos.fileName,refactor_edits_FileEdit.ReplaceText(newFullModulName,use.pos),use);
			}
			fullModulName = packageNamePrefix + mainTypeName + "." + typeName;
			newFullModulName = context.what.toName + "." + mainTypeName + "." + typeName;
			allUses = context.nameMap.getIdentifiers(fullModulName);
			let _g3 = 0;
			while(_g3 < allUses.length) {
				let use = allUses[_g3];
				++_g3;
				changelist.addChange(use.pos.fileName,refactor_edits_FileEdit.ReplaceText(newFullModulName,use.pos),use);
			}
		}
		let uniqueFiles = [];
		allUses = context.nameMap.getIdentifiers(mainTypeName);
		let _g3 = 0;
		while(_g3 < allUses.length) {
			let use = allUses[_g3];
			++_g3;
			if(use.file.name == file.name) {
				continue;
			}
			if(use.file.getPackage() != packageName) {
				continue;
			}
			if(uniqueFiles.includes(use.pos.fileName)) {
				continue;
			}
			let _g = use.file.importsModule(packageName,mainTypeName,mainTypeName);
			switch(_g._hx_index) {
			case 0:
				break;
			case 3:
				break;
			case 4:
				let _g1 = _g.alias;
				break;
			case 1:case 2:case 5:
				let importPos = { fileName : use.pos.fileName, start : use.file.importInsertPos, end : use.file.importInsertPos};
				changelist.addChange(use.pos.fileName,refactor_edits_FileEdit.InsertText("import " + newMainModulName + ";\n",importPos),use);
				uniqueFiles.push(use.pos.fileName);
				break;
			}
		}
		refactor_rename_RenamePackage.moveFileToPackage(context,file,changelist,packageName);
		return Promise.resolve(changelist.execute());
	}
	static moveFileToPackage(context,file,changelist,packageName) {
		let path = new haxe_io_Path(file.name);
		let mainTypeName = file.getMainModulName();
		let dotPath = StringTools.replace(StringTools.replace(path.dir,"/","."),"\\",".");
		let index = dotPath.indexOf(packageName);
		let pathParts = context.what.toName.split(".");
		let rootPath = haxe_io_Path.join(HxOverrides.substr(dotPath,0,index).split("."));
		pathParts.unshift(haxe_io_Path.removeTrailingSlashes(rootPath));
		pathParts.push("" + mainTypeName + ".hx");
		changelist.addChange(file.name,refactor_edits_FileEdit.Move(haxe_io_Path.join(pathParts)),null);
	}
}
refactor_rename_RenamePackage.__name__ = true;
class refactor_rename_RenameScopedLocal {
	static refactorScopedLocal(context,file,identifier,scopeStart,scopeEnd) {
		let changelist = new refactor_edits_Changelist(context);
		let identifierDot = identifier.name + ".";
		let toNameDot = context.what.toName + ".";
		changelist.addChange(identifier.pos.fileName,refactor_edits_FileEdit.ReplaceText(context.what.toName,identifier.pos),identifier);
		let allUses = identifier.defineType.findAllIdentifiers(function(ident) {
			if(ident.pos.start < scopeStart) {
				return false;
			}
			if(ident.pos.start > scopeEnd) {
				return false;
			}
			if(ident.name == identifier.name) {
				return true;
			}
			if(ident.name.startsWith(identifierDot)) {
				return true;
			}
			return false;
		});
		let allShadows = identifier.defineType.findAllIdentifiers(function(ident) {
			if(ident.pos.start < scopeStart) {
				return false;
			}
			if(ident.pos.start > scopeEnd) {
				return false;
			}
			if(ident.name == context.what.toName) {
				return true;
			}
			if(ident.name.startsWith(toNameDot)) {
				return true;
			}
			return false;
		});
		let _g = 0;
		while(_g < allShadows.length) {
			let use = allShadows[_g];
			++_g;
			let _g1 = use.type;
			switch(_g1._hx_index) {
			case 29:
				let _g2 = _g1.isNew;
				let pos = { fileName : use.pos.fileName, start : use.pos.start, end : use.pos.start};
				changelist.addChange(use.pos.fileName,refactor_edits_FileEdit.InsertText("this.",pos),use);
				break;
			case 31:
				let pos1 = { fileName : use.pos.fileName, start : use.pos.start, end : use.pos.start};
				changelist.addChange(use.pos.fileName,refactor_edits_FileEdit.InsertText("this.",pos1),use);
				break;
			case 33:
				let _g3 = _g1.scopeStart;
				let _g4 = _g1.scopeEnd;
				let _g5 = _g1.scopeType;
				return Promise.reject("local var \"" + context.what.toName + "\" exists");
			default:
			}
		}
		let skipForIterator = false;
		let innerScopeStart = 0;
		let innerScopeEnd = -1;
		let _g1 = 0;
		while(_g1 < allUses.length) {
			let use = allUses[_g1];
			++_g1;
			if(innerScopeStart < use.pos.start && use.pos.start < innerScopeEnd) {
				continue;
			}
			let _g = use.type;
			switch(_g._hx_index) {
			case 22:
				let _g2 = _g.fieldNames;
				continue;
			case 32:
				if(skipForIterator) {
					skipForIterator = false;
					continue;
				}
				break;
			case 33:
				let _g3 = _g.scopeType;
				let start = _g.scopeStart;
				let scopeEnd = _g.scopeEnd;
				if(use.pos.start == identifier.pos.start) {
					scopeStart = start;
					skipForIterator = true;
				} else {
					innerScopeStart = start;
					innerScopeEnd = scopeEnd;
					continue;
				}
				break;
			default:
				if(use.pos.start < scopeStart) {
					continue;
				}
			}
			if(use.name == identifier.name) {
				changelist.addChange(use.pos.fileName,refactor_edits_FileEdit.ReplaceText(context.what.toName,use.pos),use);
			} else {
				let pos = { fileName : use.pos.fileName, start : use.pos.start, end : use.pos.start + identifier.pos.end - identifier.pos.start};
				changelist.addChange(use.pos.fileName,refactor_edits_FileEdit.ReplaceText(context.what.toName,pos),use);
			}
		}
		return Promise.resolve(changelist.execute());
	}
}
refactor_rename_RenameScopedLocal.__name__ = true;
class refactor_rename_RenameTypeName {
	static refactorTypeName(context,file,identifier) {
		let changelist = new refactor_edits_Changelist(context);
		let packName = file.getPackage();
		let mainModuleName = file.getMainModulName();
		let path = new haxe_io_Path(file.name);
		if(mainModuleName == identifier.name) {
			let newFileName = haxe_io_Path.join([path.dir,context.what.toName]) + "." + path.ext;
			changelist.addChange(file.name,refactor_edits_FileEdit.Move(newFileName),null);
		}
		changelist.addChange(identifier.pos.fileName,refactor_edits_FileEdit.ReplaceText(context.what.toName,identifier.pos),identifier);
		let allUses;
		if(file.packageIdentifier != null) {
			let fullName = identifier.defineType.getFullModulName();
			let parts = fullName.split(".");
			parts.pop();
			let prefix = parts.join(".") + ".";
			allUses = context.nameMap.getIdentifiers(fullName);
			if(allUses != null) {
				let _g = 0;
				while(_g < allUses.length) {
					let use = allUses[_g];
					++_g;
					refactor_rename_RenameHelper.replaceTextWithPrefix(use,prefix,context.what.toName,changelist);
				}
			}
		}
		allUses = context.nameMap.matchIdentifierPart(identifier.name,true);
		let changes = [];
		let _g = 0;
		while(_g < allUses.length) {
			let use = allUses[_g];
			++_g;
			if(use.defineType == null) {
				continue;
			}
			let _g1 = use.file.importsModule(packName,mainModuleName,identifier.name);
			switch(_g1._hx_index) {
			case 0:
				continue;
			case 4:
				let alias = _g1.alias;
				if(alias != identifier.name) {
					continue;
				}
				break;
			case 1:case 2:case 3:case 5:
				break;
			}
			changes.push(refactor_rename_RenameHelper.findTypeOfIdentifier(context,{ name : use.name, pos : use.pos.start, defineType : use.defineType}).then(function(typeHint) {
				if(typeHint != null) {
					switch(typeHint._hx_index) {
					case 0:
						let _g = typeHint.typeParams;
						let type = typeHint.type;
						if(type != identifier.defineType) {
							return;
						}
						break;
					case 1:
						let _g1 = typeHint.name;
						let _g2 = typeHint.typeParams;
						return;
					}
				}
				if(use.name == identifier.name) {
					changelist.addChange(use.pos.fileName,refactor_edits_FileEdit.ReplaceText(context.what.toName,use.pos),use);
					return;
				}
				if(use.name.startsWith("" + identifier.name + ".")) {
					let newPos = { fileName : use.pos.fileName, start : use.pos.start, end : use.pos.start + identifier.name.length};
					changelist.addChange(use.pos.fileName,refactor_edits_FileEdit.ReplaceText(context.what.toName,newPos),use);
				}
			}));
		}
		return Promise.all(changes).then(function(_) {
			return Promise.resolve(changelist.execute());
		});
	}
}
refactor_rename_RenameTypeName.__name__ = true;
class sys_FileSystem {
	static exists(path) {
		try {
			js_node_Fs.accessSync(path);
			return true;
		} catch( _g ) {
			return false;
		}
	}
	static isDirectory(path) {
		try {
			return js_node_Fs.statSync(path).isDirectory();
		} catch( _g ) {
			return false;
		}
	}
	static createDirectory(path) {
		try {
			js_node_Fs.mkdirSync(path);
		} catch( _g ) {
			let e = haxe_Exception.caught(_g).unwrap();
			if(e.code == "ENOENT") {
				sys_FileSystem.createDirectory(js_node_Path.dirname(path));
				js_node_Fs.mkdirSync(path);
			} else {
				let stat;
				try {
					stat = js_node_Fs.statSync(path);
				} catch( _g ) {
					throw e;
				}
				if(!stat.isDirectory()) {
					throw e;
				}
			}
		}
	}
}
sys_FileSystem.__name__ = true;
class sys_io_FileInput extends haxe_io_Input {
	constructor(fd) {
		super();
		this.fd = fd;
		this.pos = 0;
	}
	readByte() {
		let buf = js_node_buffer_Buffer.alloc(1);
		let bytesRead;
		try {
			bytesRead = js_node_Fs.readSync(this.fd,buf,0,1,this.pos);
		} catch( _g ) {
			let e = haxe_Exception.caught(_g).unwrap();
			if(e.code == "EOF") {
				throw haxe_Exception.thrown(new haxe_io_Eof());
			} else {
				throw haxe_Exception.thrown(haxe_io_Error.Custom(e));
			}
		}
		if(bytesRead == 0) {
			throw haxe_Exception.thrown(new haxe_io_Eof());
		}
		this.pos++;
		return buf[0];
	}
	readBytes(s,pos,len) {
		let data = s.b;
		let buf = js_node_buffer_Buffer.from(data.buffer,data.byteOffset,s.length);
		let bytesRead;
		try {
			bytesRead = js_node_Fs.readSync(this.fd,buf,pos,len,this.pos);
		} catch( _g ) {
			let e = haxe_Exception.caught(_g).unwrap();
			if(e.code == "EOF") {
				throw haxe_Exception.thrown(new haxe_io_Eof());
			} else {
				throw haxe_Exception.thrown(haxe_io_Error.Custom(e));
			}
		}
		if(bytesRead == 0) {
			throw haxe_Exception.thrown(new haxe_io_Eof());
		}
		this.pos += bytesRead;
		return bytesRead;
	}
	close() {
		js_node_Fs.closeSync(this.fd);
	}
	seek(p,pos) {
		switch(pos._hx_index) {
		case 0:
			this.pos = p;
			break;
		case 1:
			this.pos += p;
			break;
		case 2:
			this.pos = js_node_Fs.fstatSync(this.fd).size + p;
			break;
		}
	}
	tell() {
		return this.pos;
	}
	eof() {
		return this.pos >= js_node_Fs.fstatSync(this.fd).size;
	}
}
sys_io_FileInput.__name__ = true;
class sys_io_FileOutput extends haxe_io_Output {
	constructor(fd) {
		super();
		this.fd = fd;
		this.pos = 0;
	}
	writeByte(b) {
		let buf = js_node_buffer_Buffer.alloc(1);
		buf[0] = b;
		js_node_Fs.writeSync(this.fd,buf,0,1,this.pos);
		this.pos++;
	}
	writeBytes(s,pos,len) {
		let data = s.b;
		let buf = js_node_buffer_Buffer.from(data.buffer,data.byteOffset,s.length);
		let wrote = js_node_Fs.writeSync(this.fd,buf,pos,len,this.pos);
		this.pos += wrote;
		return wrote;
	}
	close() {
		js_node_Fs.closeSync(this.fd);
	}
	seek(p,pos) {
		switch(pos._hx_index) {
		case 0:
			this.pos = p;
			break;
		case 1:
			this.pos += p;
			break;
		case 2:
			this.pos = js_node_Fs.fstatSync(this.fd).size + p;
			break;
		}
	}
	tell() {
		return this.pos;
	}
}
sys_io_FileOutput.__name__ = true;
var sys_io_FileSeek = $hxEnums["sys.io.FileSeek"] = { __ename__:true,__constructs__:null
	,SeekBegin: {_hx_name:"SeekBegin",_hx_index:0,__enum__:"sys.io.FileSeek",toString:$estr}
	,SeekCur: {_hx_name:"SeekCur",_hx_index:1,__enum__:"sys.io.FileSeek",toString:$estr}
	,SeekEnd: {_hx_name:"SeekEnd",_hx_index:2,__enum__:"sys.io.FileSeek",toString:$estr}
};
sys_io_FileSeek.__constructs__ = [sys_io_FileSeek.SeekBegin,sys_io_FileSeek.SeekCur,sys_io_FileSeek.SeekEnd];
class tokentree_ToTokenTreeDef {
	static _new(tok) {
		return tok;
	}
	static toTokenTreeDef(this1) {
		return this1;
	}
	static fromTokenDef(tok) {
		let tmp;
		switch(tok._hx_index) {
		case 0:
			tmp = tokentree_TokenTreeDef.Eof;
			break;
		case 1:
			let c = tok.c;
			switch(c._hx_index) {
			case 0:
				let v = c.v;
				let s = c.s;
				tmp = tokentree_TokenTreeDef.Const(haxeparser_Constant.CInt(v,s));
				break;
			case 1:
				let f = c.f;
				let s1 = c.s;
				tmp = tokentree_TokenTreeDef.Const(haxeparser_Constant.CFloat(f,s1));
				break;
			case 2:
				let s2 = c.s;
				let kind = c.kind;
				tmp = tokentree_TokenTreeDef.Const(haxeparser_Constant.CString(s2,kind));
				break;
			case 3:
				let s3 = c.s;
				tmp = tokentree_TokenTreeDef.Const(haxeparser_Constant.CIdent(s3));
				break;
			case 4:
				let r = c.r;
				let opt = c.opt;
				tmp = tokentree_TokenTreeDef.Const(haxeparser_Constant.CRegexp(r,opt));
				break;
			case 5:
				let s4 = c.s;
				tmp = tokentree_TokenTreeDef.Const(haxeparser_Constant.CMarkup(s4));
				break;
			}
			break;
		case 2:
			let k = tok.k;
			tmp = tokentree_TokenTreeDef.Kwd(k);
			break;
		case 3:
			let s5 = tok.s;
			tmp = tokentree_TokenTreeDef.Comment(s5);
			break;
		case 4:
			let s6 = tok.s;
			tmp = tokentree_TokenTreeDef.CommentLine(s6);
			break;
		case 5:
			let op = tok.op;
			tmp = tokentree_TokenTreeDef.Binop(op);
			break;
		case 6:
			let op1 = tok.op;
			tmp = tokentree_TokenTreeDef.Unop(op1);
			break;
		case 7:
			tmp = tokentree_TokenTreeDef.Semicolon;
			break;
		case 8:
			tmp = tokentree_TokenTreeDef.Comma;
			break;
		case 9:
			tmp = tokentree_TokenTreeDef.BrOpen;
			break;
		case 10:
			tmp = tokentree_TokenTreeDef.BrClose;
			break;
		case 11:
			tmp = tokentree_TokenTreeDef.BkOpen;
			break;
		case 12:
			tmp = tokentree_TokenTreeDef.BkClose;
			break;
		case 13:
			tmp = tokentree_TokenTreeDef.POpen;
			break;
		case 14:
			tmp = tokentree_TokenTreeDef.PClose;
			break;
		case 15:
			tmp = tokentree_TokenTreeDef.Dot;
			break;
		case 16:
			tmp = tokentree_TokenTreeDef.DblDot;
			break;
		case 17:
			tmp = tokentree_TokenTreeDef.QuestionDot;
			break;
		case 18:
			tmp = tokentree_TokenTreeDef.Arrow;
			break;
		case 19:
			let s7 = tok.s;
			tmp = tokentree_TokenTreeDef.IntInterval(s7);
			break;
		case 20:
			let s8 = tok.s;
			tmp = tokentree_TokenTreeDef.Sharp(s8);
			break;
		case 21:
			tmp = tokentree_TokenTreeDef.Question;
			break;
		case 22:
			tmp = tokentree_TokenTreeDef.At;
			break;
		case 23:
			let s9 = tok.s;
			tmp = tokentree_TokenTreeDef.Dollar(s9);
			break;
		case 24:
			tmp = tokentree_TokenTreeDef.Spread;
			break;
		}
		return tokentree_ToTokenTreeDef._new(tmp);
	}
}
var tokentree_TokenStreamMode = $hxEnums["tokentree.TokenStreamMode"] = { __ename__:true,__constructs__:null
	,Strict: {_hx_name:"Strict",_hx_index:0,__enum__:"tokentree.TokenStreamMode",toString:$estr}
	,Relaxed: {_hx_name:"Relaxed",_hx_index:1,__enum__:"tokentree.TokenStreamMode",toString:$estr}
};
tokentree_TokenStreamMode.__constructs__ = [tokentree_TokenStreamMode.Strict,tokentree_TokenStreamMode.Relaxed];
class tokentree_TokenStream {
	constructor(tokens,bytes) {
		this.tokens = tokens;
		this.bytes = bytes;
		this.sharpIfStack = [];
		this.tempStore = [];
		this.current = 0;
	}
	hasMore() {
		return this.current < this.tokens.length;
	}
	consumeToken() {
		if(this.current < 0 || this.current >= this.tokens.length) {
			switch(tokentree_TokenStream.MODE._hx_index) {
			case 0:
				throw haxe_Exception.thrown("no more tokens");
			case 1:
				return this.createDummyToken(tokentree_TokenTreeDef.CommentLine("auto insert"));
			}
		}
		let token = this.tokens[this.current];
		this.current++;
		let space = "";
		return new tokentree_TokenTree(tokentree_ToTokenTreeDef.toTokenTreeDef(tokentree_ToTokenTreeDef.fromTokenDef(token.tok)),space,token.pos,this.current - 1);
	}
	consumeConstIdent() {
		let _g = this.token();
		switch(_g._hx_index) {
		case 2:
			let _g1 = _g.c;
			if(_g1._hx_index == 3) {
				let _g = _g1.s;
				return this.consumeToken();
			} else {
				switch(tokentree_TokenStream.MODE._hx_index) {
				case 0:
					let s = "bad token " + Std.string(this.token()) + " != Const(CIdent(_))";
					throw haxe_Exception.thrown(this.formatCurrentPos() + ": " + s);
				case 1:
					return this.createDummyToken(tokentree_TokenTreeDef.Const(haxeparser_Constant.CIdent("autoInsert")));
				}
			}
			break;
		case 4:
			let _g2 = _g.s;
			return this.consumeToken();
		default:
			switch(tokentree_TokenStream.MODE._hx_index) {
			case 0:
				let s1 = "bad token " + Std.string(this.token()) + " != Const(CIdent(_))";
				throw haxe_Exception.thrown(this.formatCurrentPos() + ": " + s1);
			case 1:
				return this.createDummyToken(tokentree_TokenTreeDef.Const(haxeparser_Constant.CIdent("autoInsert")));
			}
		}
	}
	consumeConst() {
		let _g = this.token();
		if(_g._hx_index == 2) {
			let _g1 = _g.c;
			return this.consumeToken();
		} else {
			switch(tokentree_TokenStream.MODE._hx_index) {
			case 0:
				let s = "bad token " + Std.string(this.token()) + " != Const(_)";
				throw haxe_Exception.thrown(this.formatCurrentPos() + ": " + s);
			case 1:
				return this.createDummyToken(tokentree_TokenTreeDef.Const(haxeparser_Constant.CString("autoInsert")));
			}
		}
	}
	consumeTokenDef(tokenDef) {
		if(this.matches(tokenDef)) {
			return this.consumeToken();
		}
		switch(tokentree_TokenStream.MODE._hx_index) {
		case 0:
			let s = "bad token " + Std.string(this.token()) + " != " + Std.string(tokenDef);
			throw haxe_Exception.thrown(this.formatCurrentPos() + ": " + s);
		case 1:
			return this.createDummyToken(tokenDef);
		}
	}
	consumeToTempStore() {
		this.tempStore.push(this.consumeToken());
	}
	addToTempStore(token) {
		this.tempStore.push(token);
	}
	applyTempStore(parent) {
		while(this.tempStore.length > 0) parent.addChild(this.tempStore.shift());
	}
	hasTempStore() {
		return this.tempStore.length > 0;
	}
	getTempStore() {
		return this.tempStore;
	}
	clearTempStore() {
		this.tempStore = [];
	}
	error(s) {
		throw haxe_Exception.thrown(this.formatCurrentPos() + ": " + s);
	}
	formatCurrentPos() {
		let pos = this.tokens[this.current].pos;
		return new hxparse_Position(pos.file,pos.min,pos.max).format(this.bytes);
	}
	matches(tokenDef) {
		if(this.current < 0 || this.current >= this.tokens.length) {
			return false;
		}
		let token = this.tokens[this.current];
		return Type.enumEq(tokenDef,tokentree_ToTokenTreeDef.toTokenTreeDef(tokentree_ToTokenTreeDef.fromTokenDef(token.tok)));
	}
	isSharp() {
		if(this.current < 0 || this.current >= this.tokens.length) {
			return false;
		}
		let token = this.tokens[this.current];
		let _g = token.tok;
		if(_g._hx_index == 20) {
			let _g1 = _g.s;
			return true;
		} else {
			return false;
		}
	}
	isTypedParam() {
		if(this.current < 0 || this.current >= this.tokens.length) {
			return false;
		}
		let index = this.current + 1;
		let token = this.tokens[this.current];
		let _g = token.tok;
		if(_g._hx_index == 5) {
			if(_g.op._hx_index != 9) {
				return false;
			}
		} else {
			return false;
		}
		let depth = 1;
		let brDepth = 0;
		let bkDepth = 0;
		let pDepth = 0;
		while(true) {
			token = this.tokens[index++];
			let _g = token.tok;
			switch(_g._hx_index) {
			case 1:
				let _g1 = _g.c;
				break;
			case 5:
				switch(_g.op._hx_index) {
				case 7:
					if(pDepth > 0 || bkDepth > 0 || brDepth > 0) {
						continue;
					}
					--depth;
					if(depth <= 0) {
						return true;
					}
					break;
				case 9:
					if(pDepth > 0 || bkDepth > 0 || brDepth > 0) {
						continue;
					}
					++depth;
					break;
				default:
					return false;
				}
				break;
			case 9:
				++brDepth;
				break;
			case 10:
				if(brDepth <= 0) {
					return false;
				}
				--brDepth;
				break;
			case 11:
				++bkDepth;
				break;
			case 12:
				if(bkDepth <= 0) {
					return false;
				}
				--bkDepth;
				break;
			case 13:
				++pDepth;
				break;
			case 14:
				if(pDepth <= 0) {
					return false;
				}
				--pDepth;
				break;
			case 8:case 15:case 16:case 18:
				break;
			case 23:
				let _g2 = _g.s;
				break;
			default:
				return false;
			}
			if(index >= this.tokens.length) {
				return false;
			}
		}
	}
	token() {
		if(this.current < 0 || this.current >= this.tokens.length) {
			switch(tokentree_TokenStream.MODE._hx_index) {
			case 0:
				throw haxe_Exception.thrown("no more tokens");
			case 1:
				return tokentree_TokenTreeDef.CommentLine("auto insert");
			}
		}
		return tokentree_ToTokenTreeDef.toTokenTreeDef(tokentree_ToTokenTreeDef.fromTokenDef(this.tokens[this.current].tok));
	}
	tokenForMatch() {
		if(this.current < 0 || this.current >= this.tokens.length) {
			return tokentree_TokenTreeDef.Root;
		}
		return tokentree_ToTokenTreeDef.toTokenTreeDef(tokentree_ToTokenTreeDef.fromTokenDef(this.tokens[this.current].tok));
	}
	peekNonCommentToken() {
		if(this.current < 0 || this.current >= this.tokens.length) {
			switch(tokentree_TokenStream.MODE._hx_index) {
			case 0:
				throw haxe_Exception.thrown("no more tokens");
			case 1:
				return tokentree_TokenTreeDef.Const(haxeparser_Constant.CString("auto insert"));
			}
		}
		let index = this.current;
		while(index < this.tokens.length) {
			let token = this.tokens[index++];
			if(haxeparser_Token == null) {
				continue;
			}
			let _g = token.tok;
			switch(_g._hx_index) {
			case 3:
				let _g1 = _g.s;
				break;
			case 4:
				let _g2 = _g.s;
				break;
			default:
				return tokentree_ToTokenTreeDef.toTokenTreeDef(tokentree_ToTokenTreeDef.fromTokenDef(token.tok));
			}
		}
		return tokentree_TokenTreeDef.Root;
	}
	getTokenPos() {
		if(this.current < 0 || this.current >= this.tokens.length) {
			return null;
		}
		return this.tokens[this.current].pos;
	}
	rewind() {
		if(this.current <= 0) {
			return;
		}
		this.current--;
	}
	getStreamIndex() {
		return this.current;
	}
	rewindTo(pos) {
		this.current = pos;
	}
	consumeOpGt() {
		let tok = this.consumeTokenDef(tokentree_TokenTreeDef.Binop(haxe_macro_Binop.OpGt));
		let _g = this.token();
		if(_g._hx_index == 6) {
			switch(_g.op._hx_index) {
			case 4:
				let assignTok = this.consumeToken();
				return new tokentree_TokenTree(tokentree_TokenTreeDef.Binop(haxe_macro_Binop.OpGte),tok.space + assignTok.space,{ file : tok.pos.file, min : tok.pos.min, max : assignTok.pos.max},tok.index);
			case 7:
				return this.consumeOpShr(tok);
			default:
				return tok;
			}
		} else {
			return tok;
		}
	}
	consumeOpShr(parent) {
		let tok = this.consumeTokenDef(tokentree_TokenTreeDef.Binop(haxe_macro_Binop.OpGt));
		let _g = this.token();
		if(_g._hx_index == 6) {
			switch(_g.op._hx_index) {
			case 4:
				let assignTok = this.consumeToken();
				return new tokentree_TokenTree(tokentree_TokenTreeDef.Binop(haxe_macro_Binop.OpAssignOp(haxe_macro_Binop.OpShr)),assignTok.space,{ file : parent.pos.file, min : parent.pos.min, max : assignTok.pos.max},parent.index);
			case 7:
				let innerGt = this.consumeToken();
				let _g1 = this.token();
				if(_g1._hx_index == 6) {
					if(_g1.op._hx_index == 4) {
						let assignTok = this.consumeToken();
						return new tokentree_TokenTree(tokentree_TokenTreeDef.Binop(haxe_macro_Binop.OpAssignOp(haxe_macro_Binop.OpUShr)),assignTok.space,{ file : parent.pos.file, min : parent.pos.min, max : assignTok.pos.max},parent.index);
					}
				}
				return new tokentree_TokenTree(tokentree_TokenTreeDef.Binop(haxe_macro_Binop.OpUShr),innerGt.space,{ file : parent.pos.file, min : parent.pos.min, max : innerGt.pos.max},parent.index);
			default:
				return new tokentree_TokenTree(tokentree_TokenTreeDef.Binop(haxe_macro_Binop.OpShr),tok.space,{ file : parent.pos.file, min : parent.pos.min, max : tok.pos.max},parent.index);
			}
		} else {
			return new tokentree_TokenTree(tokentree_TokenTreeDef.Binop(haxe_macro_Binop.OpShr),tok.space,{ file : parent.pos.file, min : parent.pos.min, max : tok.pos.max},parent.index);
		}
	}
	consumeOpSub(parent) {
		let tok = this.consumeTokenDef(tokentree_TokenTreeDef.Binop(haxe_macro_Binop.OpSub));
		let _g = this.token();
		if(_g._hx_index == 2) {
			let _g1 = _g.c;
			switch(_g1._hx_index) {
			case 0:
				let _g2 = _g1.v;
				let _g3 = _g1.s;
				break;
			case 1:
				let _g4 = _g1.f;
				let _g5 = _g1.s;
				break;
			default:
				return new tokentree_TokenTree(tok.tok,tok.space,tok.pos,tok.index);
			}
		} else {
			return new tokentree_TokenTree(tok.tok,tok.space,tok.pos,tok.index);
		}
		let previous = this.current - 2;
		if(previous < 0) {
			throw haxe_Exception.thrown("no more tokens");
		}
		let prevTok = this.tokens[previous];
		let _g1 = prevTok.tok;
		switch(_g1._hx_index) {
		case 2:
			switch(_g1.k._hx_index) {
			case 3:case 4:case 5:case 6:case 7:case 10:case 15:case 30:
				break;
			default:
				return new tokentree_TokenTree(tok.tok,tok.space,tok.pos,tok.index);
			}
			break;
		case 5:
			let _g2 = _g1.op;
			break;
		case 6:
			let _g3 = _g1.op;
			break;
		case 7:case 8:case 9:case 11:case 13:case 16:case 21:
			break;
		case 14:
			if(parent == null || parent.tok == tokentree_TokenTreeDef.Root) {
				return new tokentree_TokenTree(tok.tok,tok.space,tok.pos,tok.index);
			}
			let _g4 = parent.tok;
			if(_g4._hx_index == 1) {
				switch(_g4.k._hx_index) {
				case 3:case 4:case 5:case 6:case 7:case 21:
					break;
				default:
					return new tokentree_TokenTree(tok.tok,tok.space,tok.pos,tok.index);
				}
			} else {
				return new tokentree_TokenTree(tok.tok,tok.space,tok.pos,tok.index);
			}
			break;
		case 19:
			let _g5 = _g1.s;
			break;
		default:
			return new tokentree_TokenTree(tok.tok,tok.space,tok.pos,tok.index);
		}
		let _g6 = this.token();
		if(_g6._hx_index == 2) {
			let _g = _g6.c;
			switch(_g._hx_index) {
			case 0:
				let v = _g.v;
				let s = _g.s;
				let $const = this.consumeConst();
				return new tokentree_TokenTree(tokentree_TokenTreeDef.Const(haxeparser_Constant.CInt("-" + v,s)),$const.space,{ file : tok.pos.file, min : tok.pos.min, max : $const.pos.max},tok.index);
			case 1:
				let v1 = _g.f;
				let s1 = _g.s;
				let const1 = this.consumeConst();
				return new tokentree_TokenTree(tokentree_TokenTreeDef.Const(haxeparser_Constant.CFloat("-" + v1,s1)),const1.space,{ file : tok.pos.file, min : tok.pos.min, max : const1.pos.max},tok.index);
			default:
				throw haxe_Exception.thrown("no more tokens");
			}
		} else {
			throw haxe_Exception.thrown("no more tokens");
		}
	}
	pushSharpIf(token) {
		this.sharpIfStack.push(token);
	}
	popSharpIf() {
		let token = this.sharpIfStack.pop();
		if(token == null) {
			switch(tokentree_TokenStream.MODE._hx_index) {
			case 0:
				throw haxe_Exception.thrown("no more tokens");
			case 1:
				return this.createDummyToken(tokentree_TokenTreeDef.CommentLine("dummy token"));
			}
		}
		return token;
	}
	peekSharpIf() {
		if(this.sharpIfStack.length <= 0) {
			switch(tokentree_TokenStream.MODE._hx_index) {
			case 0:
				throw haxe_Exception.thrown("no more tokens");
			case 1:
				return this.createDummyToken(tokentree_TokenTreeDef.CommentLine("dummy token"));
			}
		}
		return this.sharpIfStack[this.sharpIfStack.length - 1];
	}
	createDummyToken(tokDef) {
		let pos;
		if(this.tokens.length <= 0) {
			return new tokentree_TokenTree(tokDef,"",{ file : "<unknown>", min : 0, max : 0},-1,true);
		}
		if(this.current < 0 || this.current >= this.tokens.length) {
			let prevPos = this.tokens[this.tokens.length - 1].pos;
			pos = { min : prevPos.max, max : prevPos.max, file : prevPos.file};
		} else {
			let prevPos = this.tokens[this.current].pos;
			pos = { min : prevPos.min, max : prevPos.min, file : prevPos.file};
		}
		return new tokentree_TokenTree(tokDef,"",pos,-1,true);
	}
}
tokentree_TokenStream.__name__ = true;
class tokentree_TokenStreamProgress {
	constructor(stream) {
		this.stream = stream;
		this.pos = -1;
	}
	streamHasChanged() {
		if(this.pos == -1) {
			this.pos = this.stream.getStreamIndex();
			return true;
		}
		let oldPos = this.pos;
		this.pos = this.stream.getStreamIndex();
		return this.pos != oldPos;
	}
}
tokentree_TokenStreamProgress.__name__ = true;
class tokentree_TokenTree {
	constructor(tok,space,pos,index,inserted) {
		if(inserted == null) {
			inserted = false;
		}
		this.tok = tok;
		this.pos = pos;
		this.index = index;
		this.inserted = inserted;
		this.space = space;
		this.tokenTypeCache = { };
	}
	matches(tokenDef) {
		return Type.enumEq(tokenDef,this.tok);
	}
	isComment() {
		let _g = this.tok;
		switch(_g._hx_index) {
		case 7:
			let _g1 = _g.s;
			return true;
		case 8:
			let _g2 = _g.s;
			return true;
		default:
			return false;
		}
	}
	isCIdent() {
		let _g = this.tok;
		if(_g._hx_index == 2) {
			let _g1 = _g.c;
			if(_g1._hx_index == 3) {
				let _g = _g1.s;
				return true;
			} else {
				return false;
			}
		} else {
			return false;
		}
	}
	isCIdentOrCString() {
		let _g = this.tok;
		if(_g._hx_index == 2) {
			let _g1 = _g.c;
			switch(_g1._hx_index) {
			case 2:
				let _g2 = _g1.s;
				let _g3 = _g1.kind;
				return true;
			case 3:
				let _g4 = _g1.s;
				return true;
			default:
				return false;
			}
		} else {
			return false;
		}
	}
	addChild(child) {
		if(child == null) {
			return;
		}
		if(this.children == null) {
			this.children = [];
		}
		if(this.children.length > 0) {
			child.previousSibling = this.children[this.children.length - 1];
			this.children[this.children.length - 1].nextSibling = child;
		}
		this.children.push(child);
		child.parent = this;
	}
	hasChildren() {
		if(this.children == null) {
			return false;
		}
		return this.children.length > 0;
	}
	getFirstChild() {
		if(!this.hasChildren()) {
			return null;
		}
		return this.children[0];
	}
	getLastChild() {
		if(!this.hasChildren()) {
			return null;
		}
		return this.children[this.children.length - 1];
	}
	getPos() {
		if(this.children == null || this.children.length <= 0) {
			return this.pos;
		}
		let fullPos = { file : this.pos.file, min : this.pos.min, max : this.pos.max};
		let childPos;
		let _g = 0;
		let _g1 = this.children;
		while(_g < _g1.length) {
			let child = _g1[_g];
			++_g;
			childPos = child.getPos();
			if(childPos.min < fullPos.min) {
				fullPos.min = childPos.min;
			}
			if(childPos.max > fullPos.max) {
				fullPos.max = childPos.max;
			}
		}
		return fullPos;
	}
	filter(searchFor,mode,maxLevel) {
		if(maxLevel == null) {
			maxLevel = 9999;
		}
		return this.filterCallback(function(token,depth) {
			if(depth > maxLevel) {
				return tokentree_FilterResult.SkipSubtree;
			}
			if(token.matchesAny(searchFor)) {
				if(mode == tokentree_TokenFilterMode.All) {
					return tokentree_FilterResult.FoundGoDeeper;
				}
				return tokentree_FilterResult.FoundSkipSubtree;
			} else {
				return tokentree_FilterResult.GoDeeper;
			}
		});
	}
	filterCallback(callback) {
		let results = [];
		this.internalFilterCallback(callback,results,0);
		return results;
	}
	internalFilterCallback(callback,results,depth) {
		if(depth == null) {
			depth = 0;
		}
		if(this.tok._hx_index != 0) {
			switch(callback(this,depth)._hx_index) {
			case 0:
				results.push(this);
				return;
			case 1:
				results.push(this);
				break;
			case 2:
				return;
			case 3:
				break;
			}
		}
		if(this.children == null) {
			return;
		}
		let _g = 0;
		let _g1 = this.children;
		while(_g < _g1.length) {
			let child = _g1[_g];
			++_g;
			let _g2 = child.tok;
			if(_g2._hx_index == 3) {
				let _g = _g2.s;
				child.internalFilterCallback(callback,results,depth);
			} else {
				child.internalFilterCallback(callback,results,depth + 1);
			}
		}
	}
	matchesAny(searchFor) {
		if(searchFor == null || this.tok == tokentree_TokenTreeDef.Root) {
			return false;
		}
		let _g = 0;
		while(_g < searchFor.length) {
			let search = searchFor[_g];
			++_g;
			if(Type.enumEq(this.tok,search)) {
				return true;
			}
		}
		return false;
	}
	printTokenTree(prefix) {
		if(prefix == null) {
			prefix = "";
		}
		let buf_b = "";
		let tokString = "" + Std.string(this.tok);
		if(this.inserted) {
			tokString = "*** " + tokString + " ***";
		}
		if(this.tok != tokentree_TokenTreeDef.Root) {
			buf_b += Std.string("" + prefix + tokString + "\t\t\t\t" + Std.string(this.getPos()));
		}
		if(this.children == null) {
			return buf_b;
		}
		let _g = 0;
		let _g1 = this.children;
		while(_g < _g1.length) {
			let child = _g1[_g];
			++_g;
			buf_b += Std.string("\n" + prefix + child.printTokenTree(prefix + "  "));
		}
		return buf_b;
	}
	toString() {
		return tokentree_TokenTreeDefPrinter.toString(this.tok);
	}
}
tokentree_TokenTree.__name__ = true;
var tokentree_TokenFilterMode = $hxEnums["tokentree.TokenFilterMode"] = { __ename__:true,__constructs__:null
	,All: {_hx_name:"All",_hx_index:0,__enum__:"tokentree.TokenFilterMode",toString:$estr}
	,First: {_hx_name:"First",_hx_index:1,__enum__:"tokentree.TokenFilterMode",toString:$estr}
};
tokentree_TokenFilterMode.__constructs__ = [tokentree_TokenFilterMode.All,tokentree_TokenFilterMode.First];
var tokentree_FilterResult = $hxEnums["tokentree.FilterResult"] = { __ename__:true,__constructs__:null
	,FoundSkipSubtree: {_hx_name:"FoundSkipSubtree",_hx_index:0,__enum__:"tokentree.FilterResult",toString:$estr}
	,FoundGoDeeper: {_hx_name:"FoundGoDeeper",_hx_index:1,__enum__:"tokentree.FilterResult",toString:$estr}
	,SkipSubtree: {_hx_name:"SkipSubtree",_hx_index:2,__enum__:"tokentree.FilterResult",toString:$estr}
	,GoDeeper: {_hx_name:"GoDeeper",_hx_index:3,__enum__:"tokentree.FilterResult",toString:$estr}
};
tokentree_FilterResult.__constructs__ = [tokentree_FilterResult.FoundSkipSubtree,tokentree_FilterResult.FoundGoDeeper,tokentree_FilterResult.SkipSubtree,tokentree_FilterResult.GoDeeper];
class tokentree_TokenTreeAccessHelper {
	static get_token(this1) {
		return this1;
	}
	static access(tok) {
		return tok;
	}
	static parent(this1) {
		if(this1 != null) {
			return this1.parent;
		} else {
			return null;
		}
	}
	static findParent(this1,predicate) {
		let parent = tokentree_TokenTreeAccessHelper.parent(this1);
		while(parent != null && parent.tok != tokentree_TokenTreeDef.Root) {
			if(predicate(parent)) {
				return parent;
			}
			parent = tokentree_TokenTreeAccessHelper.parent(parent);
		}
		return null;
	}
	static previousSibling(this1) {
		if(this1 != null) {
			return this1.previousSibling;
		} else {
			return null;
		}
	}
	static nextSibling(this1) {
		if(this1 != null) {
			return this1.nextSibling;
		} else {
			return null;
		}
	}
	static firstChild(this1) {
		if(this1 != null) {
			return this1.getFirstChild();
		} else {
			return null;
		}
	}
	static lastChild(this1) {
		if(this1 != null) {
			return this1.getLastChild();
		} else {
			return null;
		}
	}
	static firstOf(this1,token) {
		if(this1 == null || this1.children == null) {
			return null;
		}
		let _g = 0;
		let _g1 = this1.children;
		while(_g < _g1.length) {
			let tok = _g1[_g];
			++_g;
			if(Type.enumEq(tok.tok,token)) {
				return tok;
			}
		}
		return null;
	}
	static lastOf(this1,token) {
		if(this1 == null || this1.children == null) {
			return null;
		}
		let found = null;
		let _g = 0;
		let _g1 = this1.children;
		while(_g < _g1.length) {
			let tok = _g1[_g];
			++_g;
			if(Type.enumEq(tok.tok,token)) {
				found = tok;
			}
		}
		return found;
	}
	static child(this1,index) {
		if(this1 != null && this1.children != null) {
			return this1.children[index];
		} else {
			return null;
		}
	}
	static matches(this1,tok) {
		if(this1 != null && Type.enumEq(this1.tok,tok)) {
			return this1;
		} else {
			return null;
		}
	}
	static isComment(this1) {
		if(this1 != null && this1.isComment()) {
			return this1;
		} else {
			return null;
		}
	}
	static isCIdent(this1) {
		if(this1 != null && this1.isCIdent()) {
			return this1;
		} else {
			return null;
		}
	}
	static or(this1,other) {
		if(this1 != null) {
			return this1;
		} else {
			return other;
		}
	}
	static exists(this1) {
		return this1 != null;
	}
}
class tokentree_TokenTreeBuilder {
	static buildTokenTree(tokens,bytes,entryPoint) {
		if(entryPoint == null) {
			entryPoint = tokentree_TokenTreeEntryPoint.TypeLevel;
		}
		return tokentree_TokenTreeBuilder.buildTokenTreeFromStream(new tokentree_TokenStream(tokens,bytes),entryPoint);
	}
	static buildTokenTreeFromStream(stream,entryPoint) {
		let root = stream.createDummyToken(tokentree_TokenTreeDef.Root);
		switch(entryPoint._hx_index) {
		case 0:
			tokentree_walk_WalkFile.walkFile(stream,root);
			break;
		case 1:
			tokentree_walk_WalkClass.walkClassBody(stream,root);
			break;
		case 2:
			tokentree_walk_WalkStatement.walkStatement(stream,root);
			break;
		case 3:
			tokentree_walk_WalkTypeNameDef.walkTypeNameDef(stream,root);
			break;
		}
		if(stream.hasMore()) {
			switch(tokentree_TokenStream.MODE._hx_index) {
			case 0:
				throw haxe_Exception.thrown("invalid token tree structure - found:" + Std.string(stream.token()));
			case 1:
				let progress = new tokentree_TokenStreamProgress(stream);
				while(progress.streamHasChanged()) tokentree_walk_WalkStatement.walkStatement(stream,root);
				if(stream.hasMore()) {
					throw haxe_Exception.thrown("invalid token tree structure - found:" + Std.string(stream.token()));
				}
				break;
			}
		}
		let tempStore = stream.getTempStore();
		switch(tokentree_TokenStream.MODE._hx_index) {
		case 0:
			if(tempStore.length != 0) {
				throw haxe_Exception.thrown("invalid token tree structure - tokens in temp store:" + tempStore.join(", "));
			}
			break;
		case 1:
			let _g = 0;
			while(_g < tempStore.length) {
				let stored = tempStore[_g];
				++_g;
				root.addChild(stored);
			}
			break;
		}
		return root;
	}
}
tokentree_TokenTreeBuilder.__name__ = true;
var tokentree_TokenTreeEntryPoint = $hxEnums["tokentree.TokenTreeEntryPoint"] = { __ename__:true,__constructs__:null
	,TypeLevel: {_hx_name:"TypeLevel",_hx_index:0,__enum__:"tokentree.TokenTreeEntryPoint",toString:$estr}
	,FieldLevel: {_hx_name:"FieldLevel",_hx_index:1,__enum__:"tokentree.TokenTreeEntryPoint",toString:$estr}
	,ExpressionLevel: {_hx_name:"ExpressionLevel",_hx_index:2,__enum__:"tokentree.TokenTreeEntryPoint",toString:$estr}
	,TypeHintLevel: {_hx_name:"TypeHintLevel",_hx_index:3,__enum__:"tokentree.TokenTreeEntryPoint",toString:$estr}
};
tokentree_TokenTreeEntryPoint.__constructs__ = [tokentree_TokenTreeEntryPoint.TypeLevel,tokentree_TokenTreeEntryPoint.FieldLevel,tokentree_TokenTreeEntryPoint.ExpressionLevel,tokentree_TokenTreeEntryPoint.TypeHintLevel];
var tokentree_TokenTreeDef = $hxEnums["tokentree.TokenTreeDef"] = { __ename__:true,__constructs__:null
	,Root: {_hx_name:"Root",_hx_index:0,__enum__:"tokentree.TokenTreeDef",toString:$estr}
	,Kwd: ($_=function(k) { return {_hx_index:1,k:k,__enum__:"tokentree.TokenTreeDef",toString:$estr}; },$_._hx_name="Kwd",$_.__params__ = ["k"],$_)
	,Const: ($_=function(c) { return {_hx_index:2,c:c,__enum__:"tokentree.TokenTreeDef",toString:$estr}; },$_._hx_name="Const",$_.__params__ = ["c"],$_)
	,Sharp: ($_=function(s) { return {_hx_index:3,s:s,__enum__:"tokentree.TokenTreeDef",toString:$estr}; },$_._hx_name="Sharp",$_.__params__ = ["s"],$_)
	,Dollar: ($_=function(s) { return {_hx_index:4,s:s,__enum__:"tokentree.TokenTreeDef",toString:$estr}; },$_._hx_name="Dollar",$_.__params__ = ["s"],$_)
	,Unop: ($_=function(op) { return {_hx_index:5,op:op,__enum__:"tokentree.TokenTreeDef",toString:$estr}; },$_._hx_name="Unop",$_.__params__ = ["op"],$_)
	,Binop: ($_=function(op) { return {_hx_index:6,op:op,__enum__:"tokentree.TokenTreeDef",toString:$estr}; },$_._hx_name="Binop",$_.__params__ = ["op"],$_)
	,Comment: ($_=function(s) { return {_hx_index:7,s:s,__enum__:"tokentree.TokenTreeDef",toString:$estr}; },$_._hx_name="Comment",$_.__params__ = ["s"],$_)
	,CommentLine: ($_=function(s) { return {_hx_index:8,s:s,__enum__:"tokentree.TokenTreeDef",toString:$estr}; },$_._hx_name="CommentLine",$_.__params__ = ["s"],$_)
	,IntInterval: ($_=function(s) { return {_hx_index:9,s:s,__enum__:"tokentree.TokenTreeDef",toString:$estr}; },$_._hx_name="IntInterval",$_.__params__ = ["s"],$_)
	,Semicolon: {_hx_name:"Semicolon",_hx_index:10,__enum__:"tokentree.TokenTreeDef",toString:$estr}
	,Dot: {_hx_name:"Dot",_hx_index:11,__enum__:"tokentree.TokenTreeDef",toString:$estr}
	,DblDot: {_hx_name:"DblDot",_hx_index:12,__enum__:"tokentree.TokenTreeDef",toString:$estr}
	,QuestionDot: {_hx_name:"QuestionDot",_hx_index:13,__enum__:"tokentree.TokenTreeDef",toString:$estr}
	,Arrow: {_hx_name:"Arrow",_hx_index:14,__enum__:"tokentree.TokenTreeDef",toString:$estr}
	,Comma: {_hx_name:"Comma",_hx_index:15,__enum__:"tokentree.TokenTreeDef",toString:$estr}
	,BkOpen: {_hx_name:"BkOpen",_hx_index:16,__enum__:"tokentree.TokenTreeDef",toString:$estr}
	,BkClose: {_hx_name:"BkClose",_hx_index:17,__enum__:"tokentree.TokenTreeDef",toString:$estr}
	,BrOpen: {_hx_name:"BrOpen",_hx_index:18,__enum__:"tokentree.TokenTreeDef",toString:$estr}
	,BrClose: {_hx_name:"BrClose",_hx_index:19,__enum__:"tokentree.TokenTreeDef",toString:$estr}
	,POpen: {_hx_name:"POpen",_hx_index:20,__enum__:"tokentree.TokenTreeDef",toString:$estr}
	,PClose: {_hx_name:"PClose",_hx_index:21,__enum__:"tokentree.TokenTreeDef",toString:$estr}
	,Question: {_hx_name:"Question",_hx_index:22,__enum__:"tokentree.TokenTreeDef",toString:$estr}
	,At: {_hx_name:"At",_hx_index:23,__enum__:"tokentree.TokenTreeDef",toString:$estr}
	,Eof: {_hx_name:"Eof",_hx_index:24,__enum__:"tokentree.TokenTreeDef",toString:$estr}
	,Spread: {_hx_name:"Spread",_hx_index:25,__enum__:"tokentree.TokenTreeDef",toString:$estr}
};
tokentree_TokenTreeDef.__constructs__ = [tokentree_TokenTreeDef.Root,tokentree_TokenTreeDef.Kwd,tokentree_TokenTreeDef.Const,tokentree_TokenTreeDef.Sharp,tokentree_TokenTreeDef.Dollar,tokentree_TokenTreeDef.Unop,tokentree_TokenTreeDef.Binop,tokentree_TokenTreeDef.Comment,tokentree_TokenTreeDef.CommentLine,tokentree_TokenTreeDef.IntInterval,tokentree_TokenTreeDef.Semicolon,tokentree_TokenTreeDef.Dot,tokentree_TokenTreeDef.DblDot,tokentree_TokenTreeDef.QuestionDot,tokentree_TokenTreeDef.Arrow,tokentree_TokenTreeDef.Comma,tokentree_TokenTreeDef.BkOpen,tokentree_TokenTreeDef.BkClose,tokentree_TokenTreeDef.BrOpen,tokentree_TokenTreeDef.BrClose,tokentree_TokenTreeDef.POpen,tokentree_TokenTreeDef.PClose,tokentree_TokenTreeDef.Question,tokentree_TokenTreeDef.At,tokentree_TokenTreeDef.Eof,tokentree_TokenTreeDef.Spread];
class tokentree_TokenTreeDefPrinter {
	static toString(def) {
		switch(def._hx_index) {
		case 0:
			return "<root>";
		case 1:
			let k = def.k;
			return HxOverrides.substr($hxEnums[k.__enum__].__constructs__[k._hx_index]._hx_name,3,null).toLowerCase();
		case 2:
			let _g = def.c;
			switch(_g._hx_index) {
			case 0:
				let _g1 = _g.v;
				let _g2 = _g.s;
				if(_g2 == null) {
					let v = _g1;
					return v;
				} else {
					let s = _g2;
					let v = _g1;
					return "" + v + s;
				}
				break;
			case 1:
				let _g3 = _g.f;
				let _g4 = _g.s;
				if(_g4 == null) {
					let v = _g3;
					return v;
				} else {
					let s = _g4;
					let v = _g3;
					return "" + v + s;
				}
				break;
			case 2:
				let _g5 = _g.kind;
				let s = _g.s;
				return "\"" + s + "\"";
			case 3:
				let s1 = _g.s;
				return s1;
			case 4:
				let r = _g.r;
				let opt = _g.opt;
				return "~/" + r + "/" + opt;
			case 5:
				let s2 = _g.s;
				return "" + s2;
			}
			break;
		case 3:
			let s3 = def.s;
			return "#" + s3;
		case 4:
			let s4 = def.s;
			return "$" + s4;
		case 5:
			let op = def.op;
			return new haxe_macro_Printer("").printUnop(op);
		case 6:
			let op1 = def.op;
			return new haxe_macro_Printer("").printBinop(op1);
		case 7:
			let s5 = def.s;
			return "/*" + s5 + "*/";
		case 8:
			let s6 = def.s;
			return "//" + s6;
		case 9:
			let s7 = def.s;
			return "" + s7 + "...";
		case 10:
			return ";";
		case 11:
			return ".";
		case 12:
			return ":";
		case 13:
			return "?.";
		case 14:
			return "->";
		case 15:
			return ",";
		case 16:
			return "[";
		case 17:
			return "]";
		case 18:
			return "{";
		case 19:
			return "}";
		case 20:
			return "(";
		case 21:
			return ")";
		case 22:
			return "?";
		case 23:
			return "@";
		case 24:
			return "<eof>";
		case 25:
			return "...";
		}
	}
}
tokentree_TokenTreeDefPrinter.__name__ = true;
class tokentree_utils_TokenTreeCheckUtils {
	static isImportMult(token) {
		let _g = token.tok;
		switch(_g._hx_index) {
		case 6:
			if(_g.op._hx_index == 1) {
				return tokentree_utils_TokenTreeCheckUtils.isImport(token.parent);
			} else {
				return false;
			}
			break;
		case 11:
			return tokentree_utils_TokenTreeCheckUtils.isImport(token.parent);
		default:
			return false;
		}
	}
	static isImport(token) {
		let parent = token;
		while(parent != null) {
			if(parent.tok == tokentree_TokenTreeDef.Root) {
				return false;
			}
			let _g = parent.tok;
			switch(_g._hx_index) {
			case 1:
				switch(_g.k._hx_index) {
				case 13:
					return true;
				case 25:
					break;
				case 27:
					break;
				case 36:
					return true;
				case 41:
					break;
				default:
					return false;
				}
				break;
			case 2:
				let _g1 = _g.c;
				if(_g1._hx_index == 3) {
					let _g = _g1.s;
				} else {
					return false;
				}
				break;
			case 6:
				if(_g.op._hx_index != 23) {
					return false;
				}
				break;
			case 11:
				break;
			default:
				return false;
			}
			parent = parent.parent;
		}
		return false;
	}
	static isTypeParameter(token) {
		let _g = token.tok;
		if(_g._hx_index == 6) {
			switch(_g.op._hx_index) {
			case 7:
				return tokentree_TokenTreeAccessHelper.matches(tokentree_TokenTreeAccessHelper.parent(token),tokentree_TokenTreeDef.Binop(haxe_macro_Binop.OpLt)) != null;
			case 9:
				return tokentree_TokenTreeAccessHelper.firstOf(token,tokentree_TokenTreeDef.Binop(haxe_macro_Binop.OpGt)) != null;
			default:
				return false;
			}
		} else {
			return false;
		}
	}
	static isOpGtTypedefExtension(token) {
		let _g = token.tok;
		if(_g._hx_index == 6) {
			if(_g.op._hx_index == 7) {
				return tokentree_TokenTreeAccessHelper.matches(tokentree_TokenTreeAccessHelper.parent(tokentree_TokenTreeAccessHelper.isCIdent(tokentree_TokenTreeAccessHelper.parent(tokentree_TokenTreeAccessHelper.matches(tokentree_TokenTreeAccessHelper.parent(tokentree_TokenTreeAccessHelper.matches(tokentree_TokenTreeAccessHelper.parent(token),tokentree_TokenTreeDef.BrOpen)),tokentree_TokenTreeDef.Binop(haxe_macro_Binop.OpAssign))))),tokentree_TokenTreeDef.Kwd(haxeparser_Keyword.KwdTypedef)) != null;
			} else {
				return false;
			}
		} else {
			return false;
		}
	}
	static filterOpSub(token) {
		if(token == null) {
			return false;
		}
		let _g = token.tok;
		if(!(_g._hx_index == 6 && _g.op._hx_index == 3)) {
			return false;
		}
		let prev = token.previousSibling;
		if(token.previousSibling == null) {
			prev = token.parent;
		} else {
			prev = tokentree_utils_TokenTreeCheckUtils.getLastToken(token.previousSibling);
			if(prev == null) {
				return false;
			}
		}
		let _g1 = prev.tok;
		switch(_g1._hx_index) {
		case 1:
			switch(_g1.k._hx_index) {
			case 4:
				return true;
			case 5:
				return true;
			case 6:
				return true;
			case 10:
				return true;
			case 27:
				return true;
			default:
				return false;
			}
			break;
		case 6:
			if(_g1.op._hx_index == 23) {
				return true;
			} else {
				return true;
			}
			break;
		case 12:
			return true;
		case 14:
			return true;
		case 15:
			return true;
		case 16:
			return true;
		case 17:
			return false;
		case 18:
			return true;
		case 19:
			return true;
		case 20:
			return true;
		case 21:
			let pOpen = prev.parent;
			let type = tokentree_utils_TokenTreeCheckUtils.getPOpenType(pOpen);
			switch(type._hx_index) {
			case 0:
				return true;
			case 1:
				return true;
			case 2:
				return false;
			case 3:
				return true;
			case 4:
				return true;
			case 5:
				return true;
			case 6:
				return true;
			case 7:
				return false;
			case 8:
				return true;
			case 9:
				return false;
			}
			break;
		case 22:
			return true;
		case 25:
			return true;
		default:
			return false;
		}
	}
	static isUnaryLeftSided(tok) {
		let child = tok.getFirstChild();
		if(child == null) {
			return false;
		}
		let _g = child.tok;
		switch(_g._hx_index) {
		case 1:
			switch(_g.k._hx_index) {
			case 23:
				return true;
			case 41:
				return true;
			default:
				return false;
			}
			break;
		case 2:
			let _g1 = _g.c;
			return true;
		case 20:
			return true;
		default:
			return false;
		}
	}
	static isTernary(token) {
		if(token == null) {
			return false;
		}
		if(token.tok._hx_index == 12) {
			return tokentree_utils_TokenTreeCheckUtils.isTernary(token.parent);
		}
		if(token.tok._hx_index != 22) {
			return false;
		}
		if(tokentree_TokenTreeAccessHelper.firstOf(token,tokentree_TokenTreeDef.DblDot) == null) {
			return false;
		}
		if(token.parent == null) {
			return false;
		}
		let _g = token.parent.tok;
		switch(_g._hx_index) {
		case 1:
			switch(_g.k._hx_index) {
			case 0:case 2:
				return false;
			case 42:
				return false;
			default:
				return true;
			}
			break;
		case 3:
			let _g1 = _g.s;
			return false;
		case 6:
			let _g2 = _g.op;
			return true;
		case 15:
			return false;
		case 20:
			let prev = token.previousSibling;
			if(prev == null) {
				return false;
			}
			let lastToken = tokentree_utils_TokenTreeCheckUtils.getLastToken(prev);
			if(lastToken == null) {
				return false;
			}
			switch(lastToken.tok._hx_index) {
			case 10:
				return false;
			case 15:
				return false;
			default:
				return true;
			}
			break;
		default:
			return true;
		}
	}
	static isTypeEnumAbstract(type) {
		let _g = type.tok;
		if(_g._hx_index == 1) {
			if(_g.k._hx_index == 40) {
				let name = tokentree_TokenTreeAccessHelper.firstChild(type);
				if(name == null || name.children == null || name.children.length <= 0) {
					return false;
				}
				if(tokentree_TokenTreeAccessHelper.firstOf(name,tokentree_TokenTreeDef.Kwd(haxeparser_Keyword.KwdEnum)) != null) {
					return true;
				}
				let _g = 0;
				let _g1 = name.children;
				while(_g < _g1.length) {
					let child = _g1[_g];
					++_g;
					if(child.tok._hx_index != 23) {
						continue;
					}
					let enumTok = tokentree_TokenTreeAccessHelper.matches(tokentree_TokenTreeAccessHelper.firstChild(tokentree_TokenTreeAccessHelper.matches(tokentree_TokenTreeAccessHelper.firstChild(child),tokentree_TokenTreeDef.DblDot)),tokentree_TokenTreeDef.Kwd(haxeparser_Keyword.KwdEnum));
					if(enumTok == null) {
						continue;
					}
					return true;
				}
			}
		}
		return false;
	}
	static isTypeStructure(typedefToken) {
		let afterAssign = tokentree_TokenTreeAccessHelper.firstChild(tokentree_TokenTreeAccessHelper.firstOf(tokentree_TokenTreeAccessHelper.isCIdent(tokentree_TokenTreeAccessHelper.firstChild(typedefToken)),tokentree_TokenTreeDef.Binop(haxe_macro_Binop.OpAssign)));
		if(tokentree_TokenTreeAccessHelper.matches(afterAssign,tokentree_TokenTreeDef.BrOpen) == null) {
			return tokentree_TokenTreeAccessHelper.firstOf(tokentree_TokenTreeAccessHelper.isCIdent(afterAssign),tokentree_TokenTreeDef.Binop(haxe_macro_Binop.OpAnd)) != null;
		} else {
			return true;
		}
	}
	static isTypeEnum(enumToken) {
		let _g = enumToken.tok;
		if(!(_g._hx_index == 1 && _g.k._hx_index == 26)) {
			return false;
		}
		if(tokentree_utils_TokenTreeCheckUtils.isTypeEnumAbstract(enumToken)) {
			return false;
		}
		if(tokentree_TokenTreeAccessHelper.matches(tokentree_TokenTreeAccessHelper.parent(tokentree_TokenTreeAccessHelper.matches(tokentree_TokenTreeAccessHelper.parent(enumToken),tokentree_TokenTreeDef.DblDot)),tokentree_TokenTreeDef.At) != null) {
			return false;
		}
		return true;
	}
	static isTypeMacroClass(classToken) {
		let _g = classToken.tok;
		if(_g._hx_index == 1 && _g.k._hx_index == 1) {
			return tokentree_TokenTreeAccessHelper.matches(tokentree_TokenTreeAccessHelper.parent(classToken),tokentree_TokenTreeDef.Kwd(haxeparser_Keyword.KwdMacro)) != null;
		} else {
			return false;
		}
	}
	static isBrOpenAnonTypeOrTypedef(token) {
		switch(tokentree_utils_TokenTreeCheckUtils.getBrOpenType(token)._hx_index) {
		case 0:
			return false;
		case 1:
			return true;
		case 2:
			return false;
		case 3:
			return true;
		case 4:
			return false;
		}
	}
	static getName(token) {
		if(token == null) {
			return null;
		}
		let _g = token.tok;
		switch(_g._hx_index) {
		case 1:
			if(_g.k._hx_index == 22) {
				return "new";
			} else {
				return null;
			}
			break;
		case 2:
			let _g1 = _g.c;
			if(_g1._hx_index == 3) {
				let ident = _g1.s;
				return ident;
			} else {
				return null;
			}
			break;
		default:
			return null;
		}
	}
	static getNameToken(token) {
		if(tokentree_utils_TokenTreeCheckUtils.isNameToken(token)) {
			return token;
		}
		let nameToken = tokentree_TokenTreeAccessHelper.firstChild(token);
		if(tokentree_utils_TokenTreeCheckUtils.isNameToken(nameToken)) {
			return nameToken;
		}
		nameToken = tokentree_TokenTreeAccessHelper.firstChild(tokentree_TokenTreeAccessHelper.matches(nameToken,tokentree_TokenTreeDef.Question));
		if(tokentree_utils_TokenTreeCheckUtils.isNameToken(nameToken)) {
			return nameToken;
		}
		return null;
	}
	static isNameToken(token) {
		if(token == null) {
			return false;
		}
		let _g = token.tok;
		switch(_g._hx_index) {
		case 1:
			if(_g.k._hx_index == 22) {
				return true;
			} else {
				return false;
			}
			break;
		case 2:
			let _g1 = _g.c;
			if(_g1._hx_index == 3) {
				let _g = _g1.s;
				return true;
			} else {
				return false;
			}
			break;
		default:
			return false;
		}
	}
	static getMetadata(declToken) {
		let ident = tokentree_TokenTreeAccessHelper.isCIdent(tokentree_TokenTreeAccessHelper.firstChild(declToken));
		if(ident == null || !ident.hasChildren()) {
			return [];
		}
		let _this = ident.children;
		let result = new Array(_this.length);
		let _g = 0;
		let _g1 = _this.length;
		while(_g < _g1) {
			let i = _g++;
			result[i] = tokentree_TokenTreeAccessHelper.firstChild(tokentree_TokenTreeAccessHelper.matches(tokentree_TokenTreeAccessHelper.firstChild(tokentree_TokenTreeAccessHelper.matches(_this[i],tokentree_TokenTreeDef.At)),tokentree_TokenTreeDef.DblDot));
		}
		let _g2 = [];
		let _g3 = 0;
		let _g4 = result;
		while(_g3 < _g4.length) {
			let v = _g4[_g3];
			++_g3;
			if(v != null) {
				_g2.push(v);
			}
		}
		return _g2;
	}
	static getDocComment(declToken) {
		let access = declToken;
		while(true) {
			access = tokentree_TokenTreeAccessHelper.previousSibling(access);
			if(access == null) {
				return null;
			}
			let _g = access.tok;
			switch(_g._hx_index) {
			case 7:
				let _g1 = _g.s;
				return access;
			case 8:
				let _g2 = _g.s;
				continue;
			default:
				return null;
			}
		}
	}
	static isModifier(keyword) {
		if(keyword == null) {
			return false;
		}
		let _g = keyword.tok;
		if(_g._hx_index == 1) {
			switch(_g.k._hx_index) {
			case 17:
				return true;
			case 18:
				return true;
			case 19:
				return true;
			case 25:
				return true;
			case 31:
				return true;
			case 33:
				return true;
			case 35:
				return true;
			case 41:
				return true;
			default:
				return false;
			}
		} else {
			return false;
		}
	}
	static getBrOpenType(token) {
		if(token == null) {
			return tokentree_utils_BrOpenType.Unknown;
		}
		if(token.tokenTypeCache.brOpenType != null) {
			return token.tokenTypeCache.brOpenType;
		}
		let type = tokentree_utils_TokenTreeCheckUtils.determineBrOpenType(token);
		token.tokenTypeCache.brOpenType = type;
		return type;
	}
	static determineBrOpenType(token) {
		if(token == null) {
			return tokentree_utils_BrOpenType.Unknown;
		}
		if(token.parent == null || token.parent.tok == tokentree_TokenTreeDef.Root) {
			return tokentree_utils_TokenTreeCheckUtils.determinBrChildren(token);
		}
		let _g = token.parent.tok;
		switch(_g._hx_index) {
		case 1:
			if(_g.k._hx_index == 10) {
				return tokentree_utils_TokenTreeCheckUtils.determinBrChildren(token);
			}
			break;
		case 2:
			let _g1 = _g.c;
			if(_g1._hx_index == 3) {
				switch(_g1.s) {
				case "from":case "to":
					return tokentree_utils_BrOpenType.AnonType;
				default:
					return tokentree_utils_BrOpenType.Block;
				}
			} else {
				return tokentree_utils_BrOpenType.Block;
			}
			break;
		case 4:
			let _g2 = _g.s;
			return tokentree_utils_BrOpenType.Block;
		case 6:
			switch(_g.op._hx_index) {
			case 4:
				if(tokentree_utils_TokenTreeCheckUtils.isInsideTypedef(token.parent)) {
					return tokentree_utils_BrOpenType.TypedefDecl;
				}
				return tokentree_utils_TokenTreeCheckUtils.determinBrChildren(token);
			case 9:
				return tokentree_utils_BrOpenType.AnonType;
			default:
				return tokentree_utils_BrOpenType.ObjectDecl;
			}
			break;
		case 12:
			if(tokentree_utils_TokenTreeCheckUtils.isTernary(token.parent)) {
				return tokentree_utils_BrOpenType.ObjectDecl;
			}
			let parent = token.parent.parent;
			let _g3 = parent.tok;
			switch(_g3._hx_index) {
			case 1:
				switch(_g3.k._hx_index) {
				case 15:
					return tokentree_utils_BrOpenType.ObjectDecl;
				case 16:
					return tokentree_utils_BrOpenType.ObjectDecl;
				default:
					return tokentree_utils_BrOpenType.AnonType;
				}
				break;
			case 2:
				let _g4 = _g3.c;
				switch(_g4._hx_index) {
				case 2:
					let _g5 = _g4.s;
					let _g6 = _g4.kind;
					break;
				case 3:
					let _g7 = _g4.s;
					break;
				default:
					return tokentree_utils_BrOpenType.AnonType;
				}
				break;
			default:
				return tokentree_utils_BrOpenType.AnonType;
			}
			parent = parent.parent;
			let _g8 = parent.tok;
			switch(_g8._hx_index) {
			case 1:
				switch(_g8.k._hx_index) {
				case 0:
					return tokentree_utils_BrOpenType.AnonType;
				case 2:
					return tokentree_utils_BrOpenType.AnonType;
				case 42:
					return tokentree_utils_BrOpenType.AnonType;
				default:
					return tokentree_utils_BrOpenType.ObjectDecl;
				}
				break;
			case 6:
				if(_g8.op._hx_index == 9) {
					return tokentree_utils_BrOpenType.AnonType;
				} else {
					return tokentree_utils_BrOpenType.ObjectDecl;
				}
				break;
			case 18:
				return tokentree_utils_TokenTreeCheckUtils.getBrOpenType(parent);
			case 20:
				return tokentree_utils_BrOpenType.AnonType;
			case 22:
				return tokentree_utils_BrOpenType.AnonType;
			default:
				return tokentree_utils_BrOpenType.ObjectDecl;
			}
			break;
		case 16:
			return tokentree_utils_BrOpenType.ObjectDecl;
		case 20:
			let pOpenType = tokentree_utils_TokenTreeCheckUtils.getPOpenType(token.parent);
			switch(pOpenType._hx_index) {
			case 0:
				return tokentree_utils_BrOpenType.ObjectDecl;
			case 1:
				return tokentree_utils_BrOpenType.AnonType;
			case 2:
				return tokentree_utils_BrOpenType.ObjectDecl;
			case 3:
				return tokentree_utils_BrOpenType.Unknown;
			case 4:
				return tokentree_utils_BrOpenType.Unknown;
			case 5:
				return tokentree_utils_BrOpenType.Unknown;
			case 6:
				return tokentree_utils_BrOpenType.Unknown;
			case 7:
				return tokentree_utils_BrOpenType.Unknown;
			case 8:
				return tokentree_utils_BrOpenType.Unknown;
			case 9:
				return tokentree_utils_BrOpenType.ObjectDecl;
			}
			break;
		case 22:
			if(tokentree_utils_TokenTreeCheckUtils.isTernary(token.parent)) {
				return tokentree_utils_BrOpenType.ObjectDecl;
			}
			break;
		default:
		}
		return tokentree_utils_TokenTreeCheckUtils.determinBrChildren(token);
	}
	static determinBrChildren(token) {
		if(token.children == null || token.children.length <= 0) {
			let _g = token.parent.tok;
			if(_g._hx_index == 1) {
				let _g1 = _g.k;
				return tokentree_utils_BrOpenType.Block;
			} else {
				return tokentree_utils_BrOpenType.ObjectDecl;
			}
		}
		if(token.parent != null && token.parent.tok != tokentree_TokenTreeDef.Root) {
			if(token.children.length == 1) {
				let _g = token.parent.tok;
				if(_g._hx_index == 1) {
					let _g1 = _g.k;
					return tokentree_utils_BrOpenType.Block;
				} else {
					return tokentree_utils_BrOpenType.ObjectDecl;
				}
			}
			if(token.children.length == 2 && token.getLastChild().tok._hx_index == 10) {
				let _g = token.parent.tok;
				if(_g._hx_index == 1) {
					let _g1 = _g.k;
					return tokentree_utils_BrOpenType.Block;
				} else {
					return tokentree_utils_BrOpenType.ObjectDecl;
				}
			}
		}
		if(tokentree_TokenTreeAccessHelper.firstOf(token,tokentree_TokenTreeDef.Arrow) != null) {
			return tokentree_utils_BrOpenType.AnonType;
		}
		if(token.nextSibling != null && token.nextSibling.tok._hx_index == 14) {
			return tokentree_utils_BrOpenType.AnonType;
		}
		let onlyComment = true;
		let _g = 0;
		let _g1 = token.children;
		while(_g < _g1.length) {
			let child = _g1[_g];
			++_g;
			let _g2 = child.tok;
			switch(_g2._hx_index) {
			case 2:
				let _g3 = _g2.c;
				switch(_g3._hx_index) {
				case 2:
					let _g4 = _g3.s;
					let _g5 = _g3.kind;
					if(tokentree_TokenTreeAccessHelper.matches(tokentree_TokenTreeAccessHelper.firstChild(child),tokentree_TokenTreeDef.DblDot) == null) {
						return tokentree_utils_BrOpenType.Block;
					}
					onlyComment = false;
					break;
				case 3:
					let _g6 = _g3.s;
					if(tokentree_TokenTreeAccessHelper.matches(tokentree_TokenTreeAccessHelper.firstChild(child),tokentree_TokenTreeDef.DblDot) == null) {
						return tokentree_utils_BrOpenType.Block;
					}
					onlyComment = false;
					break;
				default:
					return tokentree_utils_BrOpenType.Block;
				}
				break;
			case 3:
				let _g7 = _g2.s;
				break;
			case 7:
				let _g8 = _g2.s;
				break;
			case 8:
				let _g9 = _g2.s;
				break;
			case 19:
				if(onlyComment) {
					if(token.parent != null && token.parent.tok != tokentree_TokenTreeDef.Root) {
						let _g = token.parent.tok;
						if(_g._hx_index == 1) {
							let _g1 = _g.k;
							return tokentree_utils_BrOpenType.Block;
						} else {
							return tokentree_utils_BrOpenType.ObjectDecl;
						}
					} else {
						return tokentree_utils_BrOpenType.ObjectDecl;
					}
				}
				return tokentree_utils_BrOpenType.ObjectDecl;
			case 23:
				break;
			default:
				return tokentree_utils_BrOpenType.Block;
			}
		}
		return tokentree_utils_BrOpenType.ObjectDecl;
	}
	static getBkOpenType(token) {
		if(token == null) {
			return tokentree_utils_BkOpenType.Unknown;
		}
		if(token.tokenTypeCache.bkOpenType != null) {
			return token.tokenTypeCache.bkOpenType;
		}
		let type = tokentree_utils_TokenTreeCheckUtils.determineBkOpenType(token);
		token.tokenTypeCache.bkOpenType = type;
		return type;
	}
	static determineBkOpenType(token) {
		if(token == null) {
			return tokentree_utils_BkOpenType.Unknown;
		}
		let parent = token.parent;
		if(parent == null || parent.tok == tokentree_TokenTreeDef.Root) {
			return tokentree_utils_TokenTreeCheckUtils.determinBkChildren(token);
		}
		let _g = parent.tok;
		switch(_g._hx_index) {
		case 1:
			if(_g.k._hx_index == 23) {
				return tokentree_utils_BkOpenType.ArrayAccess;
			} else {
				return tokentree_utils_TokenTreeCheckUtils.determinBkChildren(token);
			}
			break;
		case 3:
			let _g1 = _g.s;
			return tokentree_utils_TokenTreeCheckUtils.determinBkChildren(token);
		case 6:
			let _g2 = _g.op;
			return tokentree_utils_TokenTreeCheckUtils.determinBkChildren(token);
		case 12:
			return tokentree_utils_TokenTreeCheckUtils.determinBkChildren(token);
		case 16:case 18:case 20:
			return tokentree_utils_TokenTreeCheckUtils.determinBkChildren(token);
		default:
			return tokentree_utils_BkOpenType.ArrayAccess;
		}
	}
	static determinBkChildren(token) {
		if(!token.hasChildren()) {
			return tokentree_utils_BkOpenType.Unknown;
		}
		let _g = 0;
		let _g1 = token.children;
		_hx_loop1: while(_g < _g1.length) {
			let child = _g1[_g];
			++_g;
			let _g2 = child.tok;
			switch(_g2._hx_index) {
			case 1:
				switch(_g2.k._hx_index) {
				case 5:case 7:
					return tokentree_utils_BkOpenType.Comprehension;
				default:
					break _hx_loop1;
				}
				break;
			case 7:
				let _g3 = _g2.s;
				break;
			case 8:
				let _g4 = _g2.s;
				break;
			default:
				break _hx_loop1;
			}
		}
		let bkDepth = -1;
		let childArrows = token.filterCallback(function(token,index) {
			let _g = token.tok;
			switch(_g._hx_index) {
			case 6:
				if(_g.op._hx_index == 22) {
					if(bkDepth == 0) {
						return tokentree_FilterResult.FoundSkipSubtree;
					} else {
						return tokentree_FilterResult.SkipSubtree;
					}
				} else {
					return tokentree_FilterResult.GoDeeper;
				}
				break;
			case 16:
				bkDepth += 1;
				return tokentree_FilterResult.GoDeeper;
			case 17:
				bkDepth -= 1;
				return tokentree_FilterResult.GoDeeper;
			default:
				return tokentree_FilterResult.GoDeeper;
			}
		});
		if(childArrows.length > 0) {
			return tokentree_utils_BkOpenType.MapLiteral;
		}
		return tokentree_utils_BkOpenType.ArrayLiteral;
	}
	static getPOpenType(token) {
		if(token == null) {
			return tokentree_utils_POpenType.Expression;
		}
		switch(token.tok._hx_index) {
		case 20:
			break;
		case 21:
			return tokentree_utils_TokenTreeCheckUtils.getPOpenType(token.parent);
		default:
			return tokentree_utils_POpenType.Expression;
		}
		if(token.tokenTypeCache.pOpenType != null) {
			return token.tokenTypeCache.pOpenType;
		}
		let type = tokentree_utils_TokenTreeCheckUtils.determinePOpenType(token);
		token.tokenTypeCache.pOpenType = type;
		return type;
	}
	static determinePOpenType(token) {
		let parent = token.parent;
		if(parent == null || parent.tok == tokentree_TokenTreeDef.Root) {
			return tokentree_utils_POpenType.Expression;
		}
		if(tokentree_utils_TokenTreeCheckUtils.hasAtParent(token)) {
			return tokentree_utils_POpenType.At;
		}
		if(token.hasChildren() && tokentree_utils_TokenTreeCheckUtils.checkPOpenForArrowChildren(token)) {
			return tokentree_utils_POpenType.Parameter;
		}
		_hx_loop1: while(parent != null && parent.tok != tokentree_TokenTreeDef.Root) {
			let _g = parent.tok;
			switch(_g._hx_index) {
			case 3:
				switch(_g.s) {
				case "elseif":case "if":
					if(parent.getFirstChild() == token) {
						return tokentree_utils_POpenType.SharpCondition;
					}
					parent = parent.parent;
					break;
				default:
					break _hx_loop1;
				}
				break;
			case 6:
				if(_g.op._hx_index == 9) {
					parent = parent.parent;
				} else {
					break _hx_loop1;
				}
				break;
			default:
				break _hx_loop1;
			}
		}
		if(parent == null || parent.tok == tokentree_TokenTreeDef.Root) {
			return tokentree_utils_POpenType.Expression;
		}
		let _g = parent.tok;
		switch(_g._hx_index) {
		case 1:
			switch(_g.k._hx_index) {
			case 0:
				return tokentree_utils_POpenType.Parameter;
			case 3:
				let firstChild = parent.getFirstChild();
				if(firstChild == null) {
					return tokentree_utils_POpenType.IfCondition;
				}
				if(firstChild.index == token.index) {
					return tokentree_utils_POpenType.IfCondition;
				}
				return tokentree_utils_POpenType.Expression;
			case 5:
				return tokentree_utils_POpenType.WhileCondition;
			case 7:
				return tokentree_utils_POpenType.ForLoop;
			case 14:
				return tokentree_utils_POpenType.SwitchCondition;
			case 21:
				return tokentree_utils_POpenType.Catch;
			case 22:
				return tokentree_utils_POpenType.Parameter;
			default:
			}
			break;
		case 2:
			let _g1 = _g.c;
			if(_g1._hx_index == 3) {
				let _g = _g1.s;
				if(parent.parent == null || parent.parent.tok == tokentree_TokenTreeDef.Root) {
					return tokentree_utils_POpenType.Call;
				}
				let _g2 = parent.parent.tok;
				switch(_g2._hx_index) {
				case 1:
					switch(_g2.k._hx_index) {
					case 0:
						if(parent.previousSibling == null) {
							let pOpen = tokentree_TokenTreeAccessHelper.firstOf(parent,tokentree_TokenTreeDef.POpen);
							if(pOpen == null) {
								return tokentree_utils_POpenType.Parameter;
							}
							if(pOpen.index == token.index) {
								return tokentree_utils_POpenType.Parameter;
							}
							return tokentree_utils_POpenType.Expression;
						}
						return tokentree_utils_POpenType.Call;
					case 40:
						return tokentree_utils_POpenType.Parameter;
					default:
						return tokentree_utils_POpenType.Call;
					}
					break;
				case 18:
					if(tokentree_TokenTreeAccessHelper.matches(tokentree_TokenTreeAccessHelper.parent(tokentree_TokenTreeAccessHelper.parent(parent.parent)),tokentree_TokenTreeDef.Kwd(haxeparser_Keyword.KwdEnum)) != null) {
						return tokentree_utils_POpenType.Parameter;
					}
					return tokentree_utils_POpenType.Call;
				default:
					return tokentree_utils_POpenType.Call;
				}
			}
			break;
		case 20:
			return tokentree_utils_POpenType.Expression;
		default:
		}
		if(tokentree_TokenTreeAccessHelper.firstOf(token,tokentree_TokenTreeDef.Arrow) != null) {
			return tokentree_utils_POpenType.Parameter;
		}
		return tokentree_utils_POpenType.Expression;
	}
	static checkPOpenForArrowChildren(token) {
		let skip = true;
		let _g = 0;
		let _g1 = token.children;
		while(_g < _g1.length) {
			let child = _g1[_g];
			++_g;
			if(child.tok._hx_index == 21) {
				skip = false;
			}
			if(skip) {
				continue;
			}
			if(child.tok._hx_index == 14) {
				return true;
			}
		}
		return false;
	}
	static hasAtParent(token) {
		let parent = token.parent;
		while(parent.tok != tokentree_TokenTreeDef.Root) {
			let _g = parent.tok;
			switch(_g._hx_index) {
			case 1:
				let _g1 = _g.k;
				break;
			case 2:
				let _g2 = _g.c;
				break;
			case 6:
				if(_g.op._hx_index != 23) {
					return false;
				}
				break;
			case 11:
				break;
			case 12:
				break;
			case 23:
				return true;
			default:
				return false;
			}
			parent = parent.parent;
		}
		return false;
	}
	static isInsideTypedef(token) {
		if(token == null) {
			return false;
		}
		let parent = token;
		while(parent.parent != null) {
			let _g = parent.tok;
			if(_g._hx_index == 1 && _g.k._hx_index == 32) {
				return true;
			}
			parent = parent.parent;
		}
		return false;
	}
	static isDeprecated(declToken) {
		return Lambda.exists(tokentree_utils_TokenTreeCheckUtils.getMetadata(declToken),function(meta) {
			let _g = meta.tok;
			if(_g._hx_index == 2) {
				let _g1 = _g.c;
				if(_g1._hx_index == 3) {
					if(_g1.s == "deprecated") {
						return true;
					} else {
						return false;
					}
				} else {
					return false;
				}
			} else {
				return false;
			}
		});
	}
	static getArrowType(token) {
		if(token == null) {
			return tokentree_utils_ArrowType.ArrowFunction;
		}
		if(token.tokenTypeCache.arrowType != null) {
			return token.tokenTypeCache.arrowType;
		}
		let type = tokentree_utils_TokenTreeCheckUtils.determineArrowType(token);
		if(type == null) {
			type = tokentree_utils_ArrowType.ArrowFunction;
		}
		token.tokenTypeCache.arrowType = type;
		return type;
	}
	static determineArrowType(token) {
		if(token == null) {
			return tokentree_utils_ArrowType.ArrowFunction;
		}
		let child = token.getFirstChild();
		while(child != null) {
			let _g = child.tok;
			switch(_g._hx_index) {
			case 1:
				if(_g.k._hx_index != 41) {
					return tokentree_utils_ArrowType.ArrowFunction;
				}
				break;
			case 2:
				let _g1 = _g.c;
				if(_g1._hx_index == 3) {
					let _g = _g1.s;
				} else {
					return tokentree_utils_ArrowType.ArrowFunction;
				}
				break;
			case 6:
				if(_g.op._hx_index == 9) {
					child = child.nextSibling;
					continue;
				} else {
					return tokentree_utils_ArrowType.ArrowFunction;
				}
				break;
			case 7:
				let _g2 = _g.s;
				break;
			case 8:
				let _g3 = _g.s;
				break;
			case 18:
				let brClose = child.getFirstChild();
				if(brClose.tok._hx_index == 19) {
					return tokentree_utils_ArrowType.ArrowFunction;
				}
				let brType = tokentree_utils_TokenTreeCheckUtils.getBrOpenType(child);
				if(brType == null) {
					brType = tokentree_utils_BrOpenType.Unknown;
				}
				if(brType != null) {
					switch(brType._hx_index) {
					case 0:
						return tokentree_utils_ArrowType.ArrowFunction;
					case 3:
						break;
					default:
					}
				}
				child = child.nextSibling;
				continue;
			case 20:
				break;
			case 10:case 11:case 14:case 22:
				break;
			default:
				return tokentree_utils_ArrowType.ArrowFunction;
			}
			child = child.getFirstChild();
		}
		let parent = token.parent;
		if(parent == null) {
			return tokentree_utils_ArrowType.ArrowFunction;
		}
		let resultType = tokentree_utils_TokenTreeCheckUtils.checkArrowParent(parent);
		if(resultType != null) {
			return resultType;
		}
		return tokentree_utils_TokenTreeCheckUtils.checkArrowChildren(parent);
	}
	static checkArrowChildren(parent) {
		let child = parent.getFirstChild();
		if(child == null) {
			return tokentree_utils_ArrowType.ArrowFunction;
		}
		let seenArrow = false;
		while(child != null) {
			let _g = child.tok;
			switch(_g._hx_index) {
			case 1:
				let _g1 = _g.k;
				return tokentree_utils_ArrowType.ArrowFunction;
			case 2:
				let _g2 = _g.c;
				if(_g2._hx_index == 3) {
					let _g = _g2.s;
				} else {
					return tokentree_utils_ArrowType.NewFunctionType;
				}
				break;
			case 6:
				if(_g.op._hx_index == 9) {
					child = child.nextSibling;
					continue;
				} else {
					return tokentree_utils_ArrowType.NewFunctionType;
				}
				break;
			case 7:
				let _g3 = _g.s;
				break;
			case 8:
				let _g4 = _g.s;
				break;
			case 10:case 11:
				break;
			case 12:case 18:
				break;
			case 14:
				seenArrow = true;
				break;
			case 20:
				let result = tokentree_utils_TokenTreeCheckUtils.checkArrowPOpen(child);
				if(result != null) {
					return result;
				}
				child = child.nextSibling;
				continue;
			case 21:
				break;
			case 22:
				break;
			default:
				return tokentree_utils_ArrowType.NewFunctionType;
			}
			child = child.getFirstChild();
		}
		if(seenArrow) {
			return tokentree_utils_ArrowType.OldFunctionType;
		}
		return tokentree_utils_ArrowType.NewFunctionType;
	}
	static checkArrowPOpen(token) {
		if(token.children == null || token.children.length <= 1) {
			return null;
		}
		if(token.parent.isCIdent()) {
			return tokentree_utils_ArrowType.ArrowFunction;
		}
		let childArrows = token.filterCallback(function(token,index) {
			if(token.tok._hx_index == 14) {
				return tokentree_FilterResult.FoundSkipSubtree;
			} else {
				return tokentree_FilterResult.GoDeeper;
			}
		});
		if(childArrows.length <= 0) {
			return tokentree_utils_ArrowType.ArrowFunction;
		}
		let childArrows1 = token.filterCallback(function(token,index) {
			if(token.tok._hx_index == 12) {
				return tokentree_FilterResult.FoundSkipSubtree;
			} else {
				return tokentree_FilterResult.GoDeeper;
			}
		});
		if(childArrows1.length > 0) {
			return tokentree_utils_ArrowType.NewFunctionType;
		}
		return tokentree_utils_ArrowType.OldFunctionType;
	}
	static checkArrowParent(parent) {
		if(parent == null) {
			return tokentree_utils_ArrowType.ArrowFunction;
		}
		let _g = parent.tok;
		switch(_g._hx_index) {
		case 2:
			let _g1 = _g.c;
			if(_g1._hx_index == 3) {
				let _g = _g1.s;
				if(parent.parent == null || parent.parent.tok == tokentree_TokenTreeDef.Root) {
					return tokentree_utils_ArrowType.ArrowFunction;
				}
				let _g2 = parent.parent.tok;
				switch(_g2._hx_index) {
				case 6:
					switch(_g2.op._hx_index) {
					case 4:
						if(tokentree_utils_TokenTreeCheckUtils.isInsideTypedef(parent.parent)) {
							return tokentree_utils_ArrowType.OldFunctionType;
						}
						return tokentree_utils_ArrowType.ArrowFunction;
					case 22:
						return tokentree_utils_ArrowType.ArrowFunction;
					default:
					}
					break;
				case 12:
					let type = tokentree_utils_TokenTreeCheckUtils.getColonType(parent.parent);
					switch(type._hx_index) {
					case 1:
						return tokentree_utils_ArrowType.OldFunctionType;
					case 2:
						return tokentree_utils_ArrowType.OldFunctionType;
					case 0:case 3:case 4:case 5:case 6:
						return tokentree_utils_ArrowType.ArrowFunction;
					}
					break;
				case 14:
					return tokentree_utils_ArrowType.OldFunctionType;
				case 20:
					let type1 = tokentree_utils_TokenTreeCheckUtils.getPOpenType(parent.parent);
					if(type1 == null) {
						type1 = tokentree_utils_POpenType.Expression;
					}
					switch(type1._hx_index) {
					case 1:
						return tokentree_utils_ArrowType.OldFunctionType;
					case 9:
						return tokentree_utils_ArrowType.OldFunctionType;
					default:
						return tokentree_utils_ArrowType.ArrowFunction;
					}
					break;
				default:
				}
			} else {
				return tokentree_utils_ArrowType.OldFunctionType;
			}
			break;
		case 20:
			break;
		default:
			return tokentree_utils_ArrowType.OldFunctionType;
		}
		return null;
	}
	static getColonType(token) {
		if(token == null) {
			return tokentree_utils_ColonType.Unknown;
		}
		if(token.tokenTypeCache.colonType != null) {
			return token.tokenTypeCache.colonType;
		}
		let type = tokentree_utils_TokenTreeCheckUtils.determineColonType(token);
		token.tokenTypeCache.colonType = type;
		return type;
	}
	static determineColonType(token) {
		if(token == null) {
			return tokentree_utils_ColonType.Unknown;
		}
		if(tokentree_utils_TokenTreeCheckUtils.isTernary(token)) {
			return tokentree_utils_ColonType.Ternary;
		}
		let parent = token.parent;
		if(parent == null) {
			return tokentree_utils_ColonType.Unknown;
		}
		let _g = parent.tok;
		if(_g._hx_index == 3) {
			let _g1 = _g.s;
			parent = parent.parent;
			if(parent == null || parent.tok == tokentree_TokenTreeDef.Root) {
				return tokentree_utils_ColonType.Unknown;
			}
		}
		let _g1 = parent.tok;
		switch(_g1._hx_index) {
		case 1:
			switch(_g1.k._hx_index) {
			case 0:
				return tokentree_utils_ColonType.TypeHint;
			case 15:case 16:
				return tokentree_utils_ColonType.SwitchCase;
			case 22:
				return tokentree_utils_TokenTreeCheckUtils.findColonParent(parent);
			case 23:
				return tokentree_utils_TokenTreeCheckUtils.findColonParent(parent);
			case 41:
				return tokentree_utils_ColonType.TypeHint;
			default:
			}
			break;
		case 2:
			let _g2 = _g1.c;
			return tokentree_utils_TokenTreeCheckUtils.findColonParent(parent);
		case 6:
			if(_g1.op._hx_index == 9) {
				return tokentree_utils_TokenTreeCheckUtils.findColonParent(parent);
			}
			break;
		case 18:
			let brClose = tokentree_TokenTreeAccessHelper.firstOf(parent,tokentree_TokenTreeDef.BrClose);
			if(brClose == null) {
				return tokentree_utils_ColonType.Unknown;
			}
			if(brClose.pos.max <= token.pos.min) {
				return tokentree_utils_ColonType.TypeCheck;
			}
			break;
		case 20:
			return tokentree_utils_TokenTreeCheckUtils.findColonParent(token);
		case 22:
			return tokentree_utils_TokenTreeCheckUtils.findColonParent(parent);
		case 23:
			return tokentree_utils_ColonType.At;
		default:
		}
		return tokentree_utils_ColonType.Unknown;
	}
	static findColonParent(token) {
		let parent = token;
		while(parent.tok != tokentree_TokenTreeDef.Root) {
			let _g = parent.tok;
			switch(_g._hx_index) {
			case 1:
				switch(_g.k._hx_index) {
				case 0:case 2:case 42:
					return tokentree_utils_ColonType.TypeHint;
				default:
				}
				break;
			case 18:
				let brType = tokentree_utils_TokenTreeCheckUtils.getBrOpenType(parent);
				switch(brType._hx_index) {
				case 0:
					return tokentree_utils_ColonType.Unknown;
				case 1:
					return tokentree_utils_ColonType.TypeHint;
				case 2:
					return tokentree_utils_ColonType.ObjectLiteral;
				case 3:
					return tokentree_utils_ColonType.TypeHint;
				case 4:
					return tokentree_utils_ColonType.Unknown;
				}
				break;
			case 20:
				let pClose = tokentree_TokenTreeAccessHelper.firstOf(parent,tokentree_TokenTreeDef.PClose);
				if(pClose != null && pClose.pos.max <= token.pos.min) {
					return tokentree_utils_ColonType.TypeCheck;
				}
				let pType = tokentree_utils_TokenTreeCheckUtils.getPOpenType(parent);
				switch(pType._hx_index) {
				case 0:
					return tokentree_utils_ColonType.ObjectLiteral;
				case 1:
					return tokentree_utils_ColonType.TypeHint;
				case 2:
					return tokentree_utils_ColonType.Unknown;
				case 3:
					return tokentree_utils_ColonType.TypeCheck;
				case 4:
					return tokentree_utils_ColonType.Unknown;
				case 5:
					return tokentree_utils_ColonType.Unknown;
				case 6:
					return tokentree_utils_ColonType.Unknown;
				case 7:
					return tokentree_utils_ColonType.Unknown;
				case 8:
					return tokentree_utils_ColonType.TypeCheck;
				case 9:
					return tokentree_utils_ColonType.TypeCheck;
				}
				break;
			default:
			}
			parent = parent.parent;
		}
		return tokentree_utils_ColonType.Unknown;
	}
	static getLastToken(token) {
		if(token == null) {
			return null;
		}
		if(token.children == null) {
			return token;
		}
		if(token.children.length <= 0) {
			return token;
		}
		let lastChild = token.getLastChild();
		while(lastChild != null) {
			let newLast = lastChild.getLastChild();
			if(newLast == null) {
				return lastChild;
			}
			lastChild = newLast;
		}
		return null;
	}
	static isMetadata(token) {
		if(token == null || token.tok == tokentree_TokenTreeDef.Root) {
			return false;
		}
		let parent = token.parent;
		while(parent != null && parent.tok != tokentree_TokenTreeDef.Root) switch(parent.tok._hx_index) {
		case 12:
			parent = parent.parent;
			if(parent == null || parent.tok == tokentree_TokenTreeDef.Root) {
				return false;
			}
			if(parent.tok._hx_index == 23) {
				return true;
			} else {
				return false;
			}
			break;
		case 23:
			return true;
		default:
			parent = parent.parent;
		}
		return false;
	}
	static findLastBinop(token) {
		if(token == null) {
			return null;
		}
		let lastBinop = null;
		let visitSiblings = function(parent) {
			if(parent == null) {
				return null;
			}
			while(parent.nextSibling != null) {
				let _g = parent.nextSibling.tok;
				switch(_g._hx_index) {
				case 6:
					let _g1 = _g.op;
					parent = parent.nextSibling;
					lastBinop = parent;
					break;
				case 10:case 15:
					return parent;
				case 11:
					return parent.nextSibling;
				default:
					return parent;
				}
			}
			return parent;
		};
		token = visitSiblings(token);
		while(token.hasChildren()) {
			let child;
			switch(token.tok._hx_index) {
			case 16:
				child = tokentree_TokenTreeAccessHelper.firstOf(token,tokentree_TokenTreeDef.BkClose);
				break;
			case 18:
				child = tokentree_TokenTreeAccessHelper.firstOf(token,tokentree_TokenTreeDef.BrClose);
				break;
			case 20:
				let this1 = tokentree_TokenTreeAccessHelper.firstOf(token,tokentree_TokenTreeDef.PClose);
				token = visitSiblings(token);
				child = token;
				break;
			default:
				child = token.getFirstChild();
			}
			if(child == null) {
				return lastBinop;
			}
			let _g = child.tok;
			switch(_g._hx_index) {
			case 6:
				let _g1 = _g.op;
				lastBinop = child;
				token = visitSiblings(child);
				break;
			case 11:
				token = visitSiblings(child);
				break;
			case 16:
				token = tokentree_TokenTreeAccessHelper.firstOf(child,tokentree_TokenTreeDef.BkClose);
				if(token == null) {
					return lastBinop;
				}
				break;
			case 18:
				token = tokentree_TokenTreeAccessHelper.firstOf(child,tokentree_TokenTreeDef.BrClose);
				if(token == null) {
					return lastBinop;
				}
				break;
			case 20:
				token = tokentree_TokenTreeAccessHelper.firstOf(child,tokentree_TokenTreeDef.PClose);
				if(token == null) {
					return lastBinop;
				}
				token = visitSiblings(token);
				break;
			default:
				token = child;
			}
		}
		return lastBinop;
	}
}
tokentree_utils_TokenTreeCheckUtils.__name__ = true;
var tokentree_utils_BrOpenType = $hxEnums["tokentree.utils.BrOpenType"] = { __ename__:true,__constructs__:null
	,Block: {_hx_name:"Block",_hx_index:0,__enum__:"tokentree.utils.BrOpenType",toString:$estr}
	,TypedefDecl: {_hx_name:"TypedefDecl",_hx_index:1,__enum__:"tokentree.utils.BrOpenType",toString:$estr}
	,ObjectDecl: {_hx_name:"ObjectDecl",_hx_index:2,__enum__:"tokentree.utils.BrOpenType",toString:$estr}
	,AnonType: {_hx_name:"AnonType",_hx_index:3,__enum__:"tokentree.utils.BrOpenType",toString:$estr}
	,Unknown: {_hx_name:"Unknown",_hx_index:4,__enum__:"tokentree.utils.BrOpenType",toString:$estr}
};
tokentree_utils_BrOpenType.__constructs__ = [tokentree_utils_BrOpenType.Block,tokentree_utils_BrOpenType.TypedefDecl,tokentree_utils_BrOpenType.ObjectDecl,tokentree_utils_BrOpenType.AnonType,tokentree_utils_BrOpenType.Unknown];
var tokentree_utils_BkOpenType = $hxEnums["tokentree.utils.BkOpenType"] = { __ename__:true,__constructs__:null
	,ArrayAccess: {_hx_name:"ArrayAccess",_hx_index:0,__enum__:"tokentree.utils.BkOpenType",toString:$estr}
	,ArrayLiteral: {_hx_name:"ArrayLiteral",_hx_index:1,__enum__:"tokentree.utils.BkOpenType",toString:$estr}
	,Comprehension: {_hx_name:"Comprehension",_hx_index:2,__enum__:"tokentree.utils.BkOpenType",toString:$estr}
	,MapLiteral: {_hx_name:"MapLiteral",_hx_index:3,__enum__:"tokentree.utils.BkOpenType",toString:$estr}
	,Unknown: {_hx_name:"Unknown",_hx_index:4,__enum__:"tokentree.utils.BkOpenType",toString:$estr}
};
tokentree_utils_BkOpenType.__constructs__ = [tokentree_utils_BkOpenType.ArrayAccess,tokentree_utils_BkOpenType.ArrayLiteral,tokentree_utils_BkOpenType.Comprehension,tokentree_utils_BkOpenType.MapLiteral,tokentree_utils_BkOpenType.Unknown];
var tokentree_utils_POpenType = $hxEnums["tokentree.utils.POpenType"] = { __ename__:true,__constructs__:null
	,At: {_hx_name:"At",_hx_index:0,__enum__:"tokentree.utils.POpenType",toString:$estr}
	,Parameter: {_hx_name:"Parameter",_hx_index:1,__enum__:"tokentree.utils.POpenType",toString:$estr}
	,Call: {_hx_name:"Call",_hx_index:2,__enum__:"tokentree.utils.POpenType",toString:$estr}
	,SwitchCondition: {_hx_name:"SwitchCondition",_hx_index:3,__enum__:"tokentree.utils.POpenType",toString:$estr}
	,WhileCondition: {_hx_name:"WhileCondition",_hx_index:4,__enum__:"tokentree.utils.POpenType",toString:$estr}
	,IfCondition: {_hx_name:"IfCondition",_hx_index:5,__enum__:"tokentree.utils.POpenType",toString:$estr}
	,SharpCondition: {_hx_name:"SharpCondition",_hx_index:6,__enum__:"tokentree.utils.POpenType",toString:$estr}
	,Catch: {_hx_name:"Catch",_hx_index:7,__enum__:"tokentree.utils.POpenType",toString:$estr}
	,ForLoop: {_hx_name:"ForLoop",_hx_index:8,__enum__:"tokentree.utils.POpenType",toString:$estr}
	,Expression: {_hx_name:"Expression",_hx_index:9,__enum__:"tokentree.utils.POpenType",toString:$estr}
};
tokentree_utils_POpenType.__constructs__ = [tokentree_utils_POpenType.At,tokentree_utils_POpenType.Parameter,tokentree_utils_POpenType.Call,tokentree_utils_POpenType.SwitchCondition,tokentree_utils_POpenType.WhileCondition,tokentree_utils_POpenType.IfCondition,tokentree_utils_POpenType.SharpCondition,tokentree_utils_POpenType.Catch,tokentree_utils_POpenType.ForLoop,tokentree_utils_POpenType.Expression];
var tokentree_utils_ArrowType = $hxEnums["tokentree.utils.ArrowType"] = { __ename__:true,__constructs__:null
	,ArrowFunction: {_hx_name:"ArrowFunction",_hx_index:0,__enum__:"tokentree.utils.ArrowType",toString:$estr}
	,OldFunctionType: {_hx_name:"OldFunctionType",_hx_index:1,__enum__:"tokentree.utils.ArrowType",toString:$estr}
	,NewFunctionType: {_hx_name:"NewFunctionType",_hx_index:2,__enum__:"tokentree.utils.ArrowType",toString:$estr}
};
tokentree_utils_ArrowType.__constructs__ = [tokentree_utils_ArrowType.ArrowFunction,tokentree_utils_ArrowType.OldFunctionType,tokentree_utils_ArrowType.NewFunctionType];
var tokentree_utils_ColonType = $hxEnums["tokentree.utils.ColonType"] = { __ename__:true,__constructs__:null
	,SwitchCase: {_hx_name:"SwitchCase",_hx_index:0,__enum__:"tokentree.utils.ColonType",toString:$estr}
	,TypeHint: {_hx_name:"TypeHint",_hx_index:1,__enum__:"tokentree.utils.ColonType",toString:$estr}
	,TypeCheck: {_hx_name:"TypeCheck",_hx_index:2,__enum__:"tokentree.utils.ColonType",toString:$estr}
	,Ternary: {_hx_name:"Ternary",_hx_index:3,__enum__:"tokentree.utils.ColonType",toString:$estr}
	,ObjectLiteral: {_hx_name:"ObjectLiteral",_hx_index:4,__enum__:"tokentree.utils.ColonType",toString:$estr}
	,At: {_hx_name:"At",_hx_index:5,__enum__:"tokentree.utils.ColonType",toString:$estr}
	,Unknown: {_hx_name:"Unknown",_hx_index:6,__enum__:"tokentree.utils.ColonType",toString:$estr}
};
tokentree_utils_ColonType.__constructs__ = [tokentree_utils_ColonType.SwitchCase,tokentree_utils_ColonType.TypeHint,tokentree_utils_ColonType.TypeCheck,tokentree_utils_ColonType.Ternary,tokentree_utils_ColonType.ObjectLiteral,tokentree_utils_ColonType.At,tokentree_utils_ColonType.Unknown];
class tokentree_walk_WalkAbstract {
	static walkAbstract(stream,parent) {
		let typeTok = stream.consumeToken();
		let _g = stream.token();
		if(_g._hx_index == 1) {
			switch(_g.k._hx_index) {
			case 1:case 28:
				stream.addToTempStore(typeTok);
				tokentree_walk_WalkType.walkType(stream,parent);
				return;
			default:
			}
		}
		parent.addChild(typeTok);
		let name = tokentree_walk_WalkTypeNameDef.walkTypeNameDef(stream,typeTok);
		stream.applyTempStore(name);
		if(stream.tokenForMatch()._hx_index == 20) {
			tokentree_walk_WalkPOpen.walkPOpen(stream,name);
		}
		let typeParent = name;
		let typeChild;
		let progress = new tokentree_TokenStreamProgress(stream);
		_hx_loop1: while(progress.streamHasChanged()) {
			let _g = stream.token();
			switch(_g._hx_index) {
			case 2:
				let _g1 = _g.c;
				if(_g1._hx_index == 3) {
					switch(_g1.s) {
					case "from":case "to":
						let fromToken = stream.consumeToken();
						name.addChild(fromToken);
						tokentree_walk_WalkTypeNameDef.walkTypeNameDef(stream,fromToken);
						break;
					default:
						typeChild = stream.consumeToken();
						typeParent.addChild(typeChild);
						typeParent = typeChild;
					}
				} else {
					typeChild = stream.consumeToken();
					typeParent.addChild(typeChild);
					typeParent = typeChild;
				}
				break;
			case 7:
				let _g2 = _g.s;
				name.addChild(stream.consumeToken());
				break;
			case 8:
				let _g3 = _g.s;
				name.addChild(stream.consumeToken());
				break;
			case 18:
				break _hx_loop1;
			default:
				typeChild = stream.consumeToken();
				typeParent.addChild(typeChild);
				typeParent = typeChild;
			}
		}
		let block = stream.consumeTokenDef(tokentree_TokenTreeDef.BrOpen);
		name.addChild(block);
		tokentree_walk_WalkAbstract.walkAbstractBody(stream,block);
		block.addChild(stream.consumeTokenDef(tokentree_TokenTreeDef.BrClose));
	}
	static walkAbstractBody(stream,parent) {
		let progress = new tokentree_TokenStreamProgress(stream);
		_hx_loop1: while(progress.streamHasChanged()) {
			let _g = stream.token();
			switch(_g._hx_index) {
			case 1:
				switch(_g.k._hx_index) {
				case 0:
					tokentree_walk_WalkFunction.walkFunction(stream,parent);
					break;
				case 2:
					tokentree_walk_WalkVar.walkVar(stream,parent);
					break;
				case 42:
					tokentree_walk_WalkFinal.walkFinal(stream,parent);
					break;
				default:
					stream.consumeToTempStore();
				}
				break;
			case 3:
				let _g1 = _g.s;
				tokentree_walk_WalkSharp.walkSharp(stream,parent,tokentree_walk_WalkAbstract.walkAbstractBody);
				break;
			case 7:
				let _g2 = _g.s;
				parent.addChild(stream.consumeToken());
				break;
			case 8:
				let _g3 = _g.s;
				parent.addChild(stream.consumeToken());
				break;
			case 10:
				parent.addChild(stream.consumeToken());
				break;
			case 19:
				break _hx_loop1;
			case 23:
				stream.addToTempStore(tokentree_walk_WalkAt.walkAt(stream));
				break;
			default:
				stream.consumeToTempStore();
			}
		}
		stream.applyTempStore(parent);
	}
}
tokentree_walk_WalkAbstract.__name__ = true;
class tokentree_walk_WalkArrayAccess {
	static walkArrayAccess(stream,parent) {
		let bkOpen = stream.consumeTokenDef(tokentree_TokenTreeDef.BkOpen);
		parent.addChild(bkOpen);
		stream.applyTempStore(bkOpen);
		let progress = new tokentree_TokenStreamProgress(stream);
		_hx_loop1: while(progress.streamHasChanged()) {
			let _g = stream.token();
			switch(_g._hx_index) {
			case 1:
				switch(_g.k._hx_index) {
				case 0:
					tokentree_walk_WalkFunction.walkFunction(stream,bkOpen);
					break;
				case 5:
					stream.applyTempStore(bkOpen);
					tokentree_walk_WalkWhile.walkWhile(stream,bkOpen);
					break;
				case 7:
					stream.applyTempStore(bkOpen);
					tokentree_walk_WalkFor.walkFor(stream,bkOpen);
					break;
				default:
					stream.applyTempStore(bkOpen);
					tokentree_walk_WalkStatement.walkStatement(stream,bkOpen);
				}
				break;
			case 6:
				if(_g.op._hx_index == 22) {
					let child = bkOpen.getLastChild();
					if(child == null) {
						child = bkOpen;
					}
					tokentree_walk_WalkStatement.walkStatement(stream,child);
				} else {
					stream.applyTempStore(bkOpen);
					tokentree_walk_WalkStatement.walkStatement(stream,bkOpen);
				}
				break;
			case 15:
				let comma = stream.consumeToken();
				let child = bkOpen.getLastChild();
				if(child == null) {
					child = bkOpen;
				}
				child.addChild(comma);
				break;
			case 16:
				tokentree_walk_WalkArrayAccess.walkArrayAccess(stream,bkOpen);
				break;
			case 17:
				break _hx_loop1;
			case 18:
				stream.applyTempStore(bkOpen);
				tokentree_walk_WalkBlock.walkBlock(stream,bkOpen);
				break;
			case 20:
				stream.applyTempStore(bkOpen);
				tokentree_walk_WalkPOpen.walkPOpen(stream,bkOpen);
				break;
			case 23:
				stream.addToTempStore(tokentree_walk_WalkAt.walkAt(stream));
				break;
			default:
				stream.applyTempStore(bkOpen);
				tokentree_walk_WalkStatement.walkStatement(stream,bkOpen);
			}
		}
		bkOpen.addChild(stream.consumeTokenDef(tokentree_TokenTreeDef.BkClose));
		if(stream.hasMore()) {
			let _g = stream.token();
			switch(_g._hx_index) {
			case 2:
				let _g1 = _g.c;
				if(_g1._hx_index == 3) {
					if(_g1.s == "is") {
						tokentree_walk_WalkStatement.walkStatementContinue(stream,bkOpen);
					}
				}
				break;
			case 6:
				let _g2 = _g.op;
				tokentree_walk_WalkStatement.walkStatementContinue(stream,bkOpen);
				break;
			case 11:case 16:
				tokentree_walk_WalkStatement.walkStatementContinue(stream,bkOpen);
				break;
			default:
			}
		}
	}
}
tokentree_walk_WalkArrayAccess.__name__ = true;
class tokentree_walk_WalkAt {
	static walkAt(stream) {
		let atTok = stream.consumeTokenDef(tokentree_TokenTreeDef.At);
		let parent = atTok;
		if(stream.tokenForMatch()._hx_index == 12) {
			let dblDot = stream.consumeToken();
			atTok.addChild(dblDot);
			parent = dblDot;
		}
		tokentree_walk_WalkAt.walkIdent(stream,parent);
		return atTok;
	}
	static walkIdent(stream,parent) {
		let ident;
		let _g = stream.token();
		switch(_g._hx_index) {
		case 1:
			let _g1 = _g.k;
			ident = stream.consumeToken();
			break;
		case 2:
			let _g2 = _g.c;
			if(_g2._hx_index == 3) {
				let _g = _g2.s;
				ident = stream.consumeConstIdent();
			} else {
				return;
			}
			break;
		case 6:
			if(_g.op._hx_index == 23) {
				ident = stream.consumeToken();
			} else {
				return;
			}
			break;
		default:
			return;
		}
		parent.addChild(ident);
		switch(stream.token()._hx_index) {
		case 11:
			let child = stream.consumeToken();
			ident.addChild(child);
			tokentree_walk_WalkAt.walkIdent(stream,child);
			break;
		case 20:
			let pOpenPos = stream.getTokenPos();
			if(ident.pos.max == pOpenPos.min) {
				let tempStore = stream.getTempStore();
				stream.clearTempStore();
				tokentree_walk_WalkPOpen.walkPOpen(stream,ident,false);
				let _g = 0;
				while(_g < tempStore.length) {
					let temp = tempStore[_g];
					++_g;
					stream.addToTempStore(temp);
				}
			}
			break;
		default:
		}
	}
	static walkAts(stream) {
		let progress = new tokentree_TokenStreamProgress(stream);
		while(progress.streamHasChanged()) if(stream.token()._hx_index == 23) {
			stream.addToTempStore(tokentree_walk_WalkAt.walkAt(stream));
		}
	}
}
tokentree_walk_WalkAt.__name__ = true;
class tokentree_walk_WalkBinopSub {
	static walkBinopSub(stream,parent) {
		let sub = stream.consumeOpSub(parent);
		parent.addChild(sub);
		let _g = sub.tok;
		if(_g._hx_index == 2) {
			let _g1 = _g.c;
			tokentree_walk_WalkStatement.walkStatementContinue(stream,sub);
		} else {
			tokentree_walk_WalkStatement.walkStatement(stream,sub);
		}
	}
}
tokentree_walk_WalkBinopSub.__name__ = true;
class tokentree_walk_WalkBlock {
	static walkBlock(stream,parent) {
		while(stream.tokenForMatch()._hx_index == 23) stream.addToTempStore(tokentree_walk_WalkAt.walkAt(stream));
		if(stream.tokenForMatch()._hx_index == 18) {
			let openTok = stream.consumeTokenDef(tokentree_TokenTreeDef.BrOpen);
			parent.addChild(openTok);
			stream.applyTempStore(openTok);
			tokentree_walk_WalkBlock.walkBlockContinue(stream,openTok);
			stream.applyTempStore(openTok);
		} else {
			tokentree_walk_WalkStatement.walkStatement(stream,parent);
		}
	}
	static walkBlockContinue(stream,parent) {
		let progress = new tokentree_TokenStreamProgress(stream);
		_hx_loop1: while(progress.streamHasChanged()) {
			let _g = stream.token();
			switch(_g._hx_index) {
			case 1:
				switch(_g.k._hx_index) {
				case 15:case 16:
					tokentree_walk_WalkSwitch.walkSwitchCases(stream,parent);
					break;
				default:
					tokentree_walk_WalkStatement.walkStatement(stream,parent);
				}
				break;
			case 15:
				let child = stream.consumeToken();
				let lastChild = parent.getLastChild();
				if(lastChild == null) {
					parent.addChild(child);
				} else {
					lastChild.addChild(child);
				}
				break;
			case 19:
				break _hx_loop1;
			case 17:case 21:
				let child1 = stream.consumeToken();
				parent.addChild(child1);
				break;
			default:
				tokentree_walk_WalkStatement.walkStatement(stream,parent);
			}
		}
		tokentree_walk_WalkBlock.walkBlockEnd(stream,parent);
	}
	static walkBlockEnd(stream,parent) {
		parent.addChild(stream.consumeTokenDef(tokentree_TokenTreeDef.BrClose));
		if(stream.hasMore()) {
			let _g = stream.token();
			if(_g._hx_index == 6) {
				if(_g.op._hx_index == 7) {
					return;
				}
			}
			tokentree_walk_WalkBlock.walkAfterBlock(stream,parent);
			if(stream.hasMore()) {
				if(stream.token()._hx_index == 10) {
					let semicolon = stream.consumeToken();
					parent.addChild(semicolon);
				}
			}
		}
	}
	static walkAfterBlock(stream,parent) {
		if(!stream.hasMore()) {
			return;
		}
		let _g = stream.token();
		switch(_g._hx_index) {
		case 2:
			let _g1 = _g.c;
			if(_g1._hx_index == 3) {
				if(_g1.s == "is") {
					tokentree_walk_WalkStatement.walkStatementWithoutSemicolon(stream,parent);
				}
			}
			break;
		case 5:
			let _g2 = _g.op;
			if(parent.isCIdentOrCString()) {
				tokentree_walk_WalkStatement.walkStatementWithoutSemicolon(stream,parent);
			}
			break;
		case 6:
			let _g3 = _g.op;
			tokentree_walk_WalkStatement.walkStatementWithoutSemicolon(stream,parent);
			break;
		case 7:
			let _g4 = _g.s;
			let nextTokDef = stream.peekNonCommentToken();
			if(nextTokDef == null) {
				return;
			}
			if(nextTokDef != null) {
				switch(nextTokDef._hx_index) {
				case 5:
					let _g5 = nextTokDef.op;
					tokentree_walk_WalkComment.walkComment(stream,parent);
					tokentree_walk_WalkStatement.walkStatementContinue(stream,parent);
					break;
				case 6:
					let _g6 = nextTokDef.op;
					tokentree_walk_WalkComment.walkComment(stream,parent);
					tokentree_walk_WalkStatement.walkStatementContinue(stream,parent);
					break;
				case 11:case 12:case 22:
					tokentree_walk_WalkComment.walkComment(stream,parent);
					tokentree_walk_WalkStatement.walkStatementContinue(stream,parent);
					break;
				default:
				}
			}
			break;
		case 8:
			let _g7 = _g.s;
			let nextTokDef1 = stream.peekNonCommentToken();
			if(nextTokDef1 == null) {
				return;
			}
			if(nextTokDef1 != null) {
				switch(nextTokDef1._hx_index) {
				case 5:
					let _g8 = nextTokDef1.op;
					tokentree_walk_WalkComment.walkComment(stream,parent);
					tokentree_walk_WalkStatement.walkStatementContinue(stream,parent);
					break;
				case 6:
					let _g9 = nextTokDef1.op;
					tokentree_walk_WalkComment.walkComment(stream,parent);
					tokentree_walk_WalkStatement.walkStatementContinue(stream,parent);
					break;
				case 11:case 12:case 22:
					tokentree_walk_WalkComment.walkComment(stream,parent);
					tokentree_walk_WalkStatement.walkStatementContinue(stream,parent);
					break;
				default:
				}
			}
			break;
		case 10:
			return;
		case 11:
			tokentree_walk_WalkStatement.walkStatementWithoutSemicolon(stream,parent);
			break;
		case 12:
			tokentree_walk_WalkStatement.walkDblDot(stream,parent);
			break;
		case 14:
			tokentree_walk_WalkStatement.walkStatementWithoutSemicolon(stream,parent);
			break;
		case 20:
			let _g10 = parent.parent.tok;
			if(_g10._hx_index == 4) {
				let _g = _g10.s;
				tokentree_walk_WalkStatement.walkStatementWithoutSemicolon(stream,parent);
			}
			break;
		case 22:
			tokentree_walk_WalkQuestion.walkQuestion(stream,parent);
			break;
		default:
		}
	}
}
tokentree_walk_WalkBlock.__name__ = true;
class tokentree_walk_WalkClass {
	static walkClass(stream,parent) {
		let typeTok = stream.consumeToken();
		parent.addChild(typeTok);
		tokentree_walk_WalkComment.walkComment(stream,parent);
		let name = typeTok;
		let _g = stream.token();
		switch(_g._hx_index) {
		case 2:
			let _g1 = _g.c;
			if(_g1._hx_index == 3) {
				let _g = _g1.s;
				name = tokentree_walk_WalkTypeNameDef.walkTypeNameDef(stream,typeTok);
				stream.applyTempStore(name);
			}
			break;
		case 4:
			let _g2 = _g.s;
			name = tokentree_walk_WalkTypeNameDef.walkTypeNameDef(stream,typeTok);
			stream.applyTempStore(name);
			break;
		default:
		}
		tokentree_walk_WalkClass.walkClassExtends(stream,name);
		let block = stream.consumeTokenDef(tokentree_TokenTreeDef.BrOpen);
		name.addChild(block);
		tokentree_walk_WalkClass.walkClassBody(stream,block);
		block.addChild(stream.consumeTokenDef(tokentree_TokenTreeDef.BrClose));
	}
	static walkClassExtends(stream,name) {
		let progress = new tokentree_TokenStreamProgress(stream);
		while(progress.streamHasChanged()) {
			tokentree_walk_WalkExtends.walkExtends(stream,name);
			tokentree_walk_WalkImplements.walkImplements(stream,name);
			if(stream.isSharp()) {
				tokentree_walk_WalkSharp.walkSharp(stream,name,tokentree_walk_WalkClass.walkClassExtends);
			}
			tokentree_walk_WalkComment.walkComment(stream,name);
		}
	}
	static walkClassBody(stream,parent) {
		let progress = new tokentree_TokenStreamProgress(stream);
		_hx_loop1: while(stream.hasMore() && progress.streamHasChanged()) {
			let _g = stream.token();
			switch(_g._hx_index) {
			case 1:
				switch(_g.k._hx_index) {
				case 0:
					tokentree_walk_WalkFunction.walkFunction(stream,parent);
					break;
				case 2:
					tokentree_walk_WalkVar.walkVar(stream,parent);
					break;
				case 42:
					tokentree_walk_WalkFinal.walkFinal(stream,parent);
					break;
				case 17:case 18:case 19:case 25:case 31:case 33:case 35:case 40:case 41:case 44:
					stream.consumeToTempStore();
					break;
				default:
					switch(tokentree_TokenStream.MODE._hx_index) {
					case 0:
						throw haxe_Exception.thrown("invalid token tree structure - found:" + ("" + Std.string(stream.token())));
					case 1:
						tokentree_walk_WalkStatement.walkStatement(stream,parent);
						break;
					}
				}
				break;
			case 3:
				let _g1 = _g.s;
				tokentree_walk_WalkSharp.walkSharp(stream,parent,tokentree_walk_WalkClass.walkClassBody);
				tokentree_walk_WalkClass.walkClassContinueAfterSharp(stream,parent);
				break;
			case 7:
				let _g2 = _g.s;
				if(stream.hasTempStore()) {
					stream.consumeToTempStore();
				} else {
					parent.addChild(stream.consumeToken());
				}
				break;
			case 8:
				let _g3 = _g.s;
				if(stream.hasTempStore()) {
					stream.consumeToTempStore();
				} else {
					parent.addChild(stream.consumeToken());
				}
				break;
			case 10:
				parent.addChild(stream.consumeToken());
				break;
			case 19:
				break _hx_loop1;
			case 23:
				stream.addToTempStore(tokentree_walk_WalkAt.walkAt(stream));
				break;
			default:
				switch(tokentree_TokenStream.MODE._hx_index) {
				case 0:
					throw haxe_Exception.thrown("invalid token tree structure - found:" + ("" + Std.string(stream.token())));
				case 1:
					tokentree_walk_WalkStatement.walkStatement(stream,parent);
					break;
				}
			}
		}
		let tempStore = stream.getTempStore();
		if(tempStore.length > 0) {
			switch(tokentree_TokenStream.MODE._hx_index) {
			case 0:
				throw haxe_Exception.thrown("invalid token tree structure - found:" + ("" + Std.string(tempStore)));
			case 1:
				stream.applyTempStore(parent);
				break;
			}
		}
	}
	static walkClassContinueAfterSharp(stream,parent) {
		let brOpen = tokentree_TokenTreeAccessHelper.matches(tokentree_TokenTreeAccessHelper.lastChild(tokentree_TokenTreeAccessHelper.firstChild(tokentree_TokenTreeAccessHelper.lastOf(tokentree_TokenTreeAccessHelper.matches(tokentree_TokenTreeAccessHelper.lastChild(parent),tokentree_TokenTreeDef.Sharp("if")),tokentree_TokenTreeDef.Kwd(haxeparser_Keyword.KwdFunction)))),tokentree_TokenTreeDef.BrOpen);
		if(brOpen == null) {
			return;
		}
		if(tokentree_TokenTreeAccessHelper.matches(tokentree_TokenTreeAccessHelper.lastChild(brOpen),tokentree_TokenTreeDef.BrClose) != null) {
			return;
		}
		tokentree_walk_WalkBlock.walkBlockContinue(stream,parent);
	}
}
tokentree_walk_WalkClass.__name__ = true;
class tokentree_walk_WalkComment {
	static walkComment(stream,parent) {
		let progress = new tokentree_TokenStreamProgress(stream);
		while(stream.hasMore() && progress.streamHasChanged()) {
			let _g = stream.token();
			switch(_g._hx_index) {
			case 7:
				let _g1 = _g.s;
				let comment = stream.consumeToken();
				parent.addChild(comment);
				break;
			case 8:
				let _g2 = _g.s;
				let comment1 = stream.consumeToken();
				parent.addChild(comment1);
				break;
			default:
				return;
			}
		}
	}
	static tryWalkComment(stream,parent,expect) {
		let currentPos = stream.getStreamIndex();
		let progress = new tokentree_TokenStreamProgress(stream);
		let comments = [];
		while(stream.hasMore() && progress.streamHasChanged()) {
			let _g = stream.token();
			switch(_g._hx_index) {
			case 7:
				let _g1 = _g.s;
				comments.push(stream.consumeToken());
				break;
			case 8:
				let _g2 = _g.s;
				comments.push(stream.consumeToken());
				break;
			default:
				if(stream.matches(expect)) {
					let _g = 0;
					while(_g < comments.length) {
						let comment = comments[_g];
						++_g;
						parent.addChild(comment);
					}
					return;
				}
				stream.rewindTo(currentPos);
				return;
			}
		}
	}
}
tokentree_walk_WalkComment.__name__ = true;
class tokentree_walk_WalkDoWhile {
	static walkDoWhile(stream,parent) {
		let doTok = stream.consumeTokenDef(tokentree_TokenTreeDef.Kwd(haxeparser_Keyword.KwdDo));
		parent.addChild(doTok);
		stream.applyTempStore(doTok);
		tokentree_walk_WalkComment.walkComment(stream,doTok);
		tokentree_walk_WalkBlock.walkBlock(stream,doTok);
		let whileTok = stream.consumeTokenDef(tokentree_TokenTreeDef.Kwd(haxeparser_Keyword.KwdWhile));
		doTok.addChild(whileTok);
		tokentree_walk_WalkStatement.walkStatement(stream,whileTok);
		tokentree_walk_WalkComment.walkComment(stream,whileTok);
		if(stream.tokenForMatch()._hx_index == 10) {
			whileTok.addChild(stream.consumeToken());
		}
	}
}
tokentree_walk_WalkDoWhile.__name__ = true;
class tokentree_walk_WalkEnum {
	static walkEnum(stream,parent) {
		let typeTok = stream.consumeToken();
		let _g = stream.tokenForMatch();
		if(_g._hx_index == 1 && _g.k._hx_index == 40) {
			stream.addToTempStore(typeTok);
			tokentree_walk_WalkAbstract.walkAbstract(stream,parent);
			return;
		}
		parent.addChild(typeTok);
		let name = tokentree_walk_WalkTypeNameDef.walkTypeNameDef(stream,typeTok);
		stream.applyTempStore(name);
		tokentree_walk_WalkBlock.walkBlock(stream,name);
	}
}
tokentree_walk_WalkEnum.__name__ = true;
class tokentree_walk_WalkExtends {
	static walkExtends(stream,parent) {
		let _g = stream.tokenForMatch();
		if(!(_g._hx_index == 1 && _g.k._hx_index == 11)) {
			return;
		}
		let parentType = stream.consumeTokenDef(tokentree_TokenTreeDef.Kwd(haxeparser_Keyword.KwdExtends));
		parent.addChild(parentType);
		tokentree_walk_WalkComment.walkComment(stream,parent);
		tokentree_walk_WalkTypeNameDef.walkTypeNameDef(stream,parentType);
		tokentree_walk_WalkComment.walkComment(stream,parent);
		tokentree_walk_WalkExtends.walkExtends(stream,parent);
		tokentree_walk_WalkComment.walkComment(stream,parent);
	}
}
tokentree_walk_WalkExtends.__name__ = true;
class tokentree_walk_WalkFieldDef {
	static walkFieldDef(stream,parent) {
		let progress = new tokentree_TokenStreamProgress(stream);
		_hx_loop1: while(progress.streamHasChanged()) {
			let _g = stream.token();
			switch(_g._hx_index) {
			case 1:
				switch(_g.k._hx_index) {
				case 0:case 2:case 42:
					let tok = stream.consumeToken();
					parent.addChild(tok);
					parent = tok;
					break;
				default:
					break _hx_loop1;
				}
				break;
			case 7:
				let _g1 = _g.s;
				tokentree_walk_WalkComment.walkComment(stream,parent);
				break;
			case 8:
				let _g2 = _g.s;
				tokentree_walk_WalkComment.walkComment(stream,parent);
				break;
			case 23:
				stream.addToTempStore(tokentree_walk_WalkAt.walkAt(stream));
				break;
			default:
				break _hx_loop1;
			}
		}
		let name = tokentree_walk_WalkTypeNameDef.walkTypeNameDef(stream,parent);
		stream.applyTempStore(name);
		if(stream.tokenForMatch()._hx_index == 12) {
			let dblDot = stream.consumeTokenDef(tokentree_TokenTreeDef.DblDot);
			name.addChild(dblDot);
			tokentree_walk_WalkTypedefBody.walkTypedefBody(stream,dblDot);
		}
		let _g = stream.tokenForMatch();
		if(_g._hx_index == 6 && _g.op._hx_index == 4) {
			tokentree_walk_WalkStatement.walkStatement(stream,name);
		}
		switch(stream.token()._hx_index) {
		case 10:
			name.addChild(stream.consumeTokenDef(tokentree_TokenTreeDef.Semicolon));
			break;
		case 15:
			name.addChild(stream.consumeTokenDef(tokentree_TokenTreeDef.Comma));
			break;
		default:
		}
	}
}
tokentree_walk_WalkFieldDef.__name__ = true;
class tokentree_walk_WalkFile {
	static walkFile(stream,parent) {
		let progress = new tokentree_TokenStreamProgress(stream);
		while(stream.hasMore() && progress.streamHasChanged()) {
			let _g = stream.token();
			switch(_g._hx_index) {
			case 1:
				switch(_g.k._hx_index) {
				case 0:
					tokentree_walk_WalkFunction.walkFunction(stream,parent);
					break;
				case 2:
					tokentree_walk_WalkVar.walkVar(stream,parent);
					break;
				case 13:case 34:case 36:
					stream.applyTempStore(parent);
					tokentree_walk_WalkPackageImport.walkPackageImport(stream,parent);
					break;
				case 1:case 26:case 28:case 32:case 40:
					tokentree_walk_WalkType.walkType(stream,parent);
					break;
				case 42:
					tokentree_walk_WalkFinal.walkFinal(stream,parent);
					break;
				case 17:case 18:case 19:case 25:case 33:case 35:case 41:case 44:
					stream.consumeToTempStore();
					break;
				default:
					tokentree_walk_WalkBlock.walkBlock(stream,parent);
				}
				break;
			case 3:
				let _g1 = _g.s;
				tokentree_walk_WalkSharp.walkSharp(stream,parent,tokentree_walk_WalkFile.walkFile);
				if(!stream.hasMore()) {
					return;
				}
				if(stream.token()._hx_index == 18) {
					tokentree_walk_WalkBlock.walkBlock(stream,parent.children[parent.children.length - 1]);
				}
				break;
			case 7:
				let _g2 = _g.s;
				if(stream.hasTempStore()) {
					stream.consumeToTempStore();
				} else {
					tokentree_walk_WalkComment.walkComment(stream,parent);
				}
				break;
			case 8:
				let _g3 = _g.s;
				if(stream.hasTempStore()) {
					stream.consumeToTempStore();
				} else {
					tokentree_walk_WalkComment.walkComment(stream,parent);
				}
				break;
			case 10:case 15:case 17:case 19:case 21:
				parent.addChild(stream.consumeToken());
				break;
			case 23:
				stream.addToTempStore(tokentree_walk_WalkAt.walkAt(stream));
				break;
			default:
				tokentree_walk_WalkBlock.walkBlock(stream,parent);
			}
		}
		let tempStore = stream.getTempStore();
		let _g = 0;
		while(_g < tempStore.length) {
			let stored = tempStore[_g];
			++_g;
			let _g1 = stored.tok;
			switch(_g1._hx_index) {
			case 1:
				switch(_g1.k._hx_index) {
				case 18:case 19:case 25:
					switch(tokentree_TokenStream.MODE._hx_index) {
					case 0:
						throw haxe_Exception.thrown("invalid token tree structure - found:" + Std.string(stored));
					case 1:
						parent.addChild(stored);
						break;
					}
					break;
				default:
					parent.addChild(stored);
				}
				break;
			case 23:
				switch(tokentree_TokenStream.MODE._hx_index) {
				case 0:
					throw haxe_Exception.thrown("invalid token tree structure - found:" + Std.string(stored));
				case 1:
					parent.addChild(stored);
					break;
				}
				break;
			default:
				parent.addChild(stored);
			}
		}
	}
}
tokentree_walk_WalkFile.__name__ = true;
class tokentree_walk_WalkFinal {
	static walkFinal(stream,parent) {
		let name = null;
		let finalTok = stream.consumeToken();
		stream.addToTempStore(finalTok);
		tokentree_walk_WalkComment.walkComment(stream,parent);
		let progress = new tokentree_TokenStreamProgress(stream);
		_hx_loop1: while(progress.streamHasChanged()) {
			let _g = stream.token();
			switch(_g._hx_index) {
			case 1:
				switch(_g.k._hx_index) {
				case 0:
					return;
				case 17:case 18:case 19:case 25:case 31:case 33:case 35:case 41:
					stream.consumeToTempStore();
					break;
				case 1:case 28:
					return;
				default:
				}
				break;
			case 2:
				let _g1 = _g.c;
				if(_g1._hx_index == 3) {
					let _g = _g1.s;
					break _hx_loop1;
				}
				break;
			case 7:
				let _g2 = _g.s;
				stream.consumeToTempStore();
				break;
			case 8:
				let _g3 = _g.s;
				stream.consumeToTempStore();
				break;
			default:
			}
		}
		parent.addChild(finalTok);
		let progress1 = new tokentree_TokenStreamProgress(stream);
		while(progress1.streamHasChanged()) {
			tokentree_walk_WalkComment.walkComment(stream,parent);
			if(stream.token()._hx_index == 23) {
				tokentree_walk_WalkAt.walkAts(stream);
			}
			tokentree_walk_WalkComment.walkComment(stream,parent);
			let nameParent = finalTok;
			if(stream.tokenForMatch()._hx_index == 22) {
				nameParent = stream.consumeToken();
				finalTok.addChild(nameParent);
			}
			name = stream.consumeConstIdent();
			nameParent.addChild(name);
			let tempStore = stream.getTempStore();
			let _g = 0;
			while(_g < tempStore.length) {
				let stored = tempStore[_g];
				++_g;
				let _g1 = stored.tok;
				if(_g1._hx_index == 1) {
					if(_g1.k._hx_index != 42) {
						name.addChild(stored);
					}
				} else {
					name.addChild(stored);
				}
			}
			stream.clearTempStore();
			tokentree_walk_WalkComment.walkComment(stream,name);
			if(stream.tokenForMatch()._hx_index == 20) {
				tokentree_walk_WalkPOpen.walkPOpen(stream,name);
			}
			if(stream.tokenForMatch()._hx_index == 12) {
				let dblDot = stream.consumeToken();
				name.addChild(dblDot);
				tokentree_walk_WalkTypedefBody.walkTypedefAlias(stream,dblDot);
			}
			let _g1 = stream.tokenForMatch();
			if(_g1._hx_index == 6 && _g1.op._hx_index == 4) {
				tokentree_walk_WalkStatement.walkStatement(stream,name);
			}
			if(stream.tokenForMatch()._hx_index == 15) {
				let comma = stream.consumeToken();
				name.addChild(comma);
				continue;
			}
			break;
		}
		if(stream.tokenForMatch()._hx_index == 10) {
			name.addChild(stream.consumeToken());
		}
	}
}
tokentree_walk_WalkFinal.__name__ = true;
class tokentree_walk_WalkFor {
	static walkFor(stream,parent) {
		let forTok = stream.consumeTokenDef(tokentree_TokenTreeDef.Kwd(haxeparser_Keyword.KwdFor));
		parent.addChild(forTok);
		stream.applyTempStore(forTok);
		tokentree_walk_WalkComment.walkComment(stream,forTok);
		tokentree_walk_WalkFor.walkForPOpen(stream,forTok);
		tokentree_walk_WalkComment.walkComment(stream,forTok);
		tokentree_walk_WalkBlock.walkBlock(stream,forTok);
	}
	static walkForPOpen(stream,parent) {
		let pOpen = stream.consumeTokenDef(tokentree_TokenTreeDef.POpen);
		parent.addChild(pOpen);
		tokentree_walk_WalkComment.walkComment(stream,pOpen);
		let identifier = null;
		let _g = stream.token();
		if(_g._hx_index == 4) {
			let _g1 = _g.s;
			tokentree_walk_WalkStatement.walkStatement(stream,pOpen);
			identifier = pOpen.getLastChild();
		} else {
			identifier = stream.consumeConstIdent();
			pOpen.addChild(identifier);
		}
		tokentree_walk_WalkComment.walkComment(stream,identifier);
		let _g1 = stream.tokenForMatch();
		if(_g1._hx_index == 6 && _g1.op._hx_index == 22) {
			let arrowTok = stream.consumeToken();
			identifier.addChild(arrowTok);
			let _g = stream.token();
			if(_g._hx_index == 4) {
				let _g1 = _g.s;
				tokentree_walk_WalkStatement.walkStatement(stream,arrowTok);
			} else {
				arrowTok.addChild(stream.consumeConstIdent());
			}
		}
		let inTok = null;
		let _g2 = stream.token();
		switch(_g2._hx_index) {
		case 1:
			if(_g2.k._hx_index == 27) {
				inTok = stream.consumeToken();
				identifier.addChild(inTok);
				tokentree_walk_WalkComment.walkComment(stream,inTok);
				tokentree_walk_WalkStatement.walkStatement(stream,inTok);
				tokentree_walk_WalkComment.walkComment(stream,pOpen);
				pOpen.addChild(stream.consumeTokenDef(tokentree_TokenTreeDef.PClose));
				tokentree_walk_WalkComment.walkComment(stream,parent);
			}
			break;
		case 6:
			if(_g2.op._hx_index == 23) {
				inTok = stream.consumeToken();
				identifier.addChild(inTok);
				tokentree_walk_WalkComment.walkComment(stream,inTok);
				tokentree_walk_WalkStatement.walkStatement(stream,inTok);
				tokentree_walk_WalkComment.walkComment(stream,pOpen);
				pOpen.addChild(stream.consumeTokenDef(tokentree_TokenTreeDef.PClose));
				tokentree_walk_WalkComment.walkComment(stream,parent);
			}
			break;
		case 21:
			pOpen.addChild(stream.consumeToken());
			tokentree_walk_WalkComment.walkComment(stream,parent);
			return;
		default:
		}
	}
}
tokentree_walk_WalkFor.__name__ = true;
class tokentree_walk_WalkFunction {
	static walkFunction(stream,parent) {
		let funcTok = stream.consumeTokenDef(tokentree_TokenTreeDef.Kwd(haxeparser_Keyword.KwdFunction));
		parent.addChild(funcTok);
		tokentree_walk_WalkComment.walkComment(stream,funcTok);
		let name = funcTok;
		let _g = stream.token();
		switch(_g._hx_index) {
		case 1:
			if(_g.k._hx_index == 22) {
				name = tokentree_walk_WalkTypeNameDef.walkTypeNameDef(stream,funcTok);
			} else {
				name = tokentree_walk_WalkTypeNameDef.walkTypeNameDef(stream,funcTok);
			}
			break;
		case 6:
			if(_g.op._hx_index == 9) {
				tokentree_walk_WalkLtGt.walkLtGt(stream,funcTok);
				name = funcTok.getLastChild();
			} else {
				name = tokentree_walk_WalkTypeNameDef.walkTypeNameDef(stream,funcTok);
			}
			break;
		case 20:
			break;
		default:
			name = tokentree_walk_WalkTypeNameDef.walkTypeNameDef(stream,funcTok);
		}
		stream.applyTempStore(name);
		tokentree_walk_WalkComment.walkComment(stream,name);
		tokentree_walk_WalkFunction.walkFunctionParameters(stream,name);
		tokentree_walk_WalkComment.walkComment(stream,name);
		let _g1 = stream.token();
		if(_g1._hx_index == 3) {
			let _g = _g1.s;
			tokentree_walk_WalkSharp.walkSharp(stream,name,tokentree_walk_WalkStatement.walkStatement);
			switch(stream.token()._hx_index) {
			case 12:case 18:
				break;
			default:
				return;
			}
		}
		if(stream.tokenForMatch()._hx_index == 12) {
			let dblDot = stream.consumeToken();
			name.addChild(dblDot);
			tokentree_walk_WalkTypeNameDef.walkTypeNameDef(stream,dblDot);
		}
		tokentree_walk_WalkBlock.walkBlock(stream,name);
	}
	static walkFunctionParameters(stream,parent) {
		let pOpen = stream.consumeTokenDef(tokentree_TokenTreeDef.POpen);
		parent.addChild(pOpen);
		let progress = new tokentree_TokenStreamProgress(stream);
		while(progress.streamHasChanged()) {
			tokentree_walk_WalkComment.walkComment(stream,pOpen);
			if(stream.tokenForMatch()._hx_index == 21) {
				break;
			}
			tokentree_walk_WalkFieldDef.walkFieldDef(stream,pOpen);
		}
		pOpen.addChild(stream.consumeTokenDef(tokentree_TokenTreeDef.PClose));
	}
}
tokentree_walk_WalkFunction.__name__ = true;
class tokentree_walk_WalkIf {
	static walkIf(stream,parent) {
		let ifTok = stream.consumeTokenDef(tokentree_TokenTreeDef.Kwd(haxeparser_Keyword.KwdIf));
		parent.addChild(ifTok);
		stream.applyTempStore(ifTok);
		tokentree_walk_WalkStatement.walkStatement(stream,ifTok);
		if(stream.tokenForMatch()._hx_index == 12) {
			return;
		}
		tokentree_walk_WalkBlock.walkBlock(stream,ifTok);
		tokentree_walk_WalkComment.tryWalkComment(stream,ifTok,tokentree_TokenTreeDef.Kwd(haxeparser_Keyword.KwdElse));
		let _g = stream.tokenForMatch();
		if(_g._hx_index == 1 && _g.k._hx_index == 4) {
			let elseTok = stream.consumeTokenDef(tokentree_TokenTreeDef.Kwd(haxeparser_Keyword.KwdElse));
			ifTok.addChild(elseTok);
			tokentree_walk_WalkBlock.walkBlock(stream,elseTok);
		}
	}
}
tokentree_walk_WalkIf.__name__ = true;
class tokentree_walk_WalkImplements {
	static walkImplements(stream,parent) {
		let _g = stream.tokenForMatch();
		if(!(_g._hx_index == 1 && _g.k._hx_index == 12)) {
			return;
		}
		let interfacePart = stream.consumeTokenDef(tokentree_TokenTreeDef.Kwd(haxeparser_Keyword.KwdImplements));
		parent.addChild(interfacePart);
		tokentree_walk_WalkComment.walkComment(stream,parent);
		tokentree_walk_WalkTypeNameDef.walkTypeNameDef(stream,interfacePart);
		tokentree_walk_WalkComment.walkComment(stream,parent);
		tokentree_walk_WalkImplements.walkImplements(stream,parent);
		tokentree_walk_WalkComment.walkComment(stream,parent);
	}
}
tokentree_walk_WalkImplements.__name__ = true;
class tokentree_walk_WalkInterface {
	static walkInterface(stream,parent) {
		let typeTok = stream.consumeToken();
		parent.addChild(typeTok);
		let name = tokentree_walk_WalkTypeNameDef.walkTypeNameDef(stream,typeTok);
		stream.applyTempStore(name);
		tokentree_walk_WalkClass.walkClassExtends(stream,name);
		let block = stream.consumeTokenDef(tokentree_TokenTreeDef.BrOpen);
		name.addChild(block);
		tokentree_walk_WalkInterface.walkInterfaceBody(stream,block);
		block.addChild(stream.consumeTokenDef(tokentree_TokenTreeDef.BrClose));
	}
	static walkInterfaceBody(stream,parent) {
		let progress = new tokentree_TokenStreamProgress(stream);
		_hx_loop1: while(progress.streamHasChanged()) {
			let _g = stream.token();
			switch(_g._hx_index) {
			case 1:
				switch(_g.k._hx_index) {
				case 0:
					tokentree_walk_WalkFunction.walkFunction(stream,parent);
					break;
				case 2:
					tokentree_walk_WalkVar.walkVar(stream,parent);
					break;
				case 17:case 18:case 19:case 25:case 31:case 33:case 35:case 41:
					stream.consumeToTempStore();
					break;
				case 42:
					tokentree_walk_WalkFinal.walkFinal(stream,parent);
					break;
				default:
					stream.consumeToTempStore();
				}
				break;
			case 3:
				let _g1 = _g.s;
				tokentree_walk_WalkSharp.walkSharp(stream,parent,tokentree_walk_WalkInterface.walkInterfaceBody);
				break;
			case 7:
				let _g2 = _g.s;
				if(stream.hasTempStore()) {
					stream.consumeToTempStore();
				} else {
					parent.addChild(stream.consumeToken());
				}
				break;
			case 8:
				let _g3 = _g.s;
				if(stream.hasTempStore()) {
					stream.consumeToTempStore();
				} else {
					parent.addChild(stream.consumeToken());
				}
				break;
			case 10:
				parent.addChild(stream.consumeToken());
				break;
			case 19:
				break _hx_loop1;
			case 23:
				stream.addToTempStore(tokentree_walk_WalkAt.walkAt(stream));
				break;
			default:
				stream.consumeToTempStore();
			}
		}
		stream.applyTempStore(parent);
	}
}
tokentree_walk_WalkInterface.__name__ = true;
class tokentree_walk_WalkLtGt {
	static walkLtGt(stream,parent) {
		let ltTok = stream.consumeTokenDef(tokentree_TokenTreeDef.Binop(haxe_macro_Binop.OpLt));
		parent.addChild(ltTok);
		let progress = new tokentree_TokenStreamProgress(stream);
		_hx_loop1: while(progress.streamHasChanged()) {
			let _g = stream.token();
			switch(_g._hx_index) {
			case 6:
				switch(_g.op._hx_index) {
				case 4:
					let equals = stream.consumeToken();
					ltTok.getLastChild().addChild(equals);
					tokentree_walk_WalkTypeNameDef.walkTypeNameDef(stream,equals);
					break;
				case 7:
					break _hx_loop1;
				default:
					tokentree_walk_WalkTypeNameDef.walkTypeNameDef(stream,ltTok);
				}
				break;
			case 12:
				let dblDot = stream.consumeToken();
				ltTok.addChild(dblDot);
				tokentree_walk_WalkTypeNameDef.walkTypeNameDef(stream,dblDot);
				break;
			case 15:
				let comma = stream.consumeToken();
				ltTok.addChild(comma);
				tokentree_walk_WalkTypeNameDef.walkTypeNameDef(stream,ltTok);
				break;
			case 20:
				tokentree_walk_WalkPOpen.walkPOpen(stream,ltTok);
				break;
			default:
				tokentree_walk_WalkTypeNameDef.walkTypeNameDef(stream,ltTok);
			}
		}
		ltTok.addChild(stream.consumeTokenDef(tokentree_TokenTreeDef.Binop(haxe_macro_Binop.OpGt)));
	}
}
tokentree_walk_WalkLtGt.__name__ = true;
class tokentree_walk_WalkNew {
	static walkNew(stream,parent) {
		let newTok = stream.consumeTokenDef(tokentree_TokenTreeDef.Kwd(haxeparser_Keyword.KwdNew));
		parent.addChild(newTok);
		let name = tokentree_walk_WalkTypeNameDef.walkTypeNameDef(stream,newTok);
		let pOpen = null;
		tokentree_walk_WalkComment.walkComment(stream,name);
		let _g = stream.token();
		switch(_g._hx_index) {
		case 3:
			let _g1 = _g.s;
			tokentree_walk_WalkSharp.walkSharp(stream,parent,tokentree_walk_WalkStatement.walkStatement);
			break;
		case 20:
			pOpen = tokentree_walk_WalkPOpen.walkPOpen(stream,name);
			break;
		default:
		}
		tokentree_walk_WalkComment.walkComment(stream,name);
		let _g2 = stream.token();
		switch(_g2._hx_index) {
		case 2:
			let _g3 = _g2.c;
			if(_g3._hx_index == 3) {
				if(_g3.s == "is") {
					if(pOpen != null) {
						tokentree_walk_WalkStatement.walkStatement(stream,pOpen);
					} else {
						tokentree_walk_WalkStatement.walkStatement(stream,name);
					}
				}
			}
			break;
		case 6:
			let _g4 = _g2.op;
			if(pOpen != null) {
				tokentree_walk_WalkStatement.walkStatement(stream,pOpen);
			} else {
				tokentree_walk_WalkStatement.walkStatement(stream,name);
			}
			break;
		case 11:case 16:
			if(pOpen != null) {
				tokentree_walk_WalkStatement.walkStatement(stream,pOpen);
			} else {
				tokentree_walk_WalkStatement.walkStatement(stream,name);
			}
			break;
		default:
		}
	}
}
tokentree_walk_WalkNew.__name__ = true;
class tokentree_walk_WalkPOpen {
	static walkPOpen(stream,parent,walkTrailingComments) {
		if(walkTrailingComments == null) {
			walkTrailingComments = true;
		}
		let pOpen = stream.consumeTokenDef(tokentree_TokenTreeDef.POpen);
		parent.addChild(pOpen);
		tokentree_walk_WalkPOpen.walkPOpenParts(stream,pOpen);
		pOpen.addChild(stream.consumeTokenDef(tokentree_TokenTreeDef.PClose));
		if(walkTrailingComments) {
			tokentree_walk_WalkComment.walkComment(stream,parent);
		}
		if(stream.hasMore()) {
			if(stream.token()._hx_index == 14) {
				let arrow = stream.consumeToken();
				pOpen.addChild(arrow);
				tokentree_walk_WalkBlock.walkBlock(stream,arrow);
			}
		}
		return pOpen;
	}
	static walkPOpenParts(stream,parent) {
		let progress = new tokentree_TokenStreamProgress(stream);
		_hx_loop1: while(progress.streamHasChanged()) {
			let _g = stream.token();
			switch(_g._hx_index) {
			case 3:
				let _g1 = _g.s;
				tokentree_walk_WalkSharp.walkSharp(stream,parent,tokentree_walk_WalkPOpen.walkPOpenParts);
				break;
			case 15:
				let comma = stream.consumeToken();
				let child = parent.getLastChild();
				if(child == null) {
					child = parent;
				}
				child.addChild(comma);
				break;
			case 16:
				tokentree_walk_WalkArrayAccess.walkArrayAccess(stream,parent);
				break;
			case 18:
				tokentree_walk_WalkBlock.walkBlock(stream,parent);
				break;
			case 21:
				break _hx_loop1;
			default:
				tokentree_walk_WalkStatement.walkStatement(stream,parent);
			}
		}
	}
}
tokentree_walk_WalkPOpen.__name__ = true;
class tokentree_walk_WalkPackageImport {
	static walkPackageImport(stream,parent) {
		let progress = new tokentree_TokenStreamProgress(stream);
		while(stream.hasMore() && progress.streamHasChanged()) {
			let _g = stream.token();
			switch(_g._hx_index) {
			case 3:
				let _g1 = _g.s;
				tokentree_walk_WalkSharp.walkSharp(stream,parent,tokentree_walk_WalkPackageImport.walkPackageImport);
				break;
			case 10:
				let newChild = stream.consumeToken();
				parent.addChild(newChild);
				return;
			default:
				let newChild1 = stream.consumeToken();
				parent.addChild(newChild1);
				parent = newChild1;
			}
		}
	}
}
tokentree_walk_WalkPackageImport.__name__ = true;
class tokentree_walk_WalkQuestion {
	static walkQuestion(stream,parent) {
		let ternary = tokentree_walk_WalkQuestion.isTernary(stream,parent);
		if(!ternary) {
			tokentree_walk_WalkFieldDef.walkFieldDef(stream,parent);
			return;
		}
		let question = stream.consumeTokenDef(tokentree_TokenTreeDef.Question);
		parent.addChild(question);
		tokentree_walk_WalkComment.walkComment(stream,question);
		tokentree_walk_WalkStatement.walkStatement(stream,question);
		tokentree_walk_WalkComment.walkComment(stream,question);
		if(stream.tokenForMatch()._hx_index != 12) {
			return;
		}
		let dblDotTok = stream.consumeTokenDef(tokentree_TokenTreeDef.DblDot);
		question.addChild(dblDotTok);
		tokentree_walk_WalkStatement.walkStatement(stream,dblDotTok);
	}
	static isTernary(stream,parent) {
		let lastChild = parent.getLastChild();
		if(lastChild == null) {
			let _g = parent.tok;
			switch(_g._hx_index) {
			case 1:
				switch(_g.k._hx_index) {
				case 23:
					return true;
				case 37:case 38:case 39:
					return true;
				default:
					return false;
				}
				break;
			case 2:
				let _g1 = _g.c;
				return true;
			case 4:
				let _g2 = _g.s;
				return true;
			case 21:
				return true;
			default:
				return false;
			}
		}
		let _g = lastChild.tok;
		switch(_g._hx_index) {
		case 1:
			switch(_g.k._hx_index) {
			case 0:
				return true;
			case 22:
				return true;
			case 23:case 29:
				return true;
			case 30:
				return true;
			case 37:case 38:case 39:
				return true;
			case 41:
				return lastChild.index + 1 != stream.getStreamIndex();
			default:
				return false;
			}
			break;
		case 2:
			let _g1 = _g.c;
			return true;
		case 4:
			let _g2 = _g.s;
			return true;
		case 5:
			let _g3 = _g.op;
			return true;
		case 6:
			switch(_g.op._hx_index) {
			case 0:case 3:
				return true;
			default:
				return false;
			}
			break;
		case 12:
			return true;
		case 16:
			return true;
		case 18:
			return true;
		case 20:
			return true;
		case 21:
			return true;
		default:
			return false;
		}
	}
}
tokentree_walk_WalkQuestion.__name__ = true;
class tokentree_walk_WalkSharp {
	static walkSharp(stream,parent,walker) {
		let _g = stream.token();
		if(_g._hx_index == 3) {
			switch(_g.s) {
			case "else":
				tokentree_walk_WalkSharp.walkSharpElse(stream,parent);
				break;
			case "elseif":
				tokentree_walk_WalkSharp.walkSharpElseIf(stream,parent);
				break;
			case "end":
				tokentree_walk_WalkSharp.walkSharpEnd(stream,parent);
				break;
			case "error":
				let errorToken = stream.consumeToken();
				parent.addChild(errorToken);
				let _g1 = stream.token();
				if(_g1._hx_index == 2) {
					let _g = _g1.c;
					if(_g._hx_index == 2) {
						let _g1 = _g.s;
						let _g2 = _g.kind;
						errorToken.addChild(stream.consumeToken());
					}
				}
				break;
			case "if":
				tokentree_walk_WalkSharp.walkSharpIf(stream,parent,walker);
				break;
			default:
				parent.addChild(stream.consumeToken());
			}
		}
	}
	static walkSharpIf(stream,parent,walker) {
		let ifToken = stream.consumeToken();
		parent.addChild(ifToken);
		tokentree_walk_WalkSharp.walkSharpIfExpr(stream,ifToken);
		stream.pushSharpIf(ifToken);
		let newParent = ifToken;
		let progress = new tokentree_TokenStreamProgress(stream);
		while(progress.streamHasChanged()) try {
			walker(stream,newParent);
			switch(stream.token()._hx_index) {
			case 15:case 19:case 21:
				let newChild = stream.consumeToken();
				newParent.addChild(newChild);
				break;
			default:
			}
		} catch( _g ) {
			let _g1 = haxe_Exception.caught(_g).unwrap();
			if(((_g1) instanceof tokentree_walk_SharpElseException)) {
				let e = _g1;
				newParent = e.token;
			} else if(((_g1) instanceof tokentree_walk_SharpEndException)) {
				stream.popSharpIf();
				return;
			} else {
				throw _g;
			}
		}
	}
	static walkSharpElse(stream,parent) {
		let sharpIfParent = stream.peekSharpIf();
		let ifToken = stream.consumeToken();
		sharpIfParent.addChild(ifToken);
		stream.applyTempStore(sharpIfParent);
		throw haxe_Exception.thrown(new tokentree_walk_SharpElseException(ifToken));
	}
	static walkSharpElseIf(stream,parent) {
		let sharpIfParent = stream.peekSharpIf();
		let ifToken = stream.consumeToken();
		sharpIfParent.addChild(ifToken);
		stream.applyTempStore(sharpIfParent);
		tokentree_walk_WalkSharp.walkSharpIfExpr(stream,ifToken);
		throw haxe_Exception.thrown(new tokentree_walk_SharpElseException(ifToken));
	}
	static walkSharpEnd(stream,parent) {
		let sharpIfParent = stream.peekSharpIf();
		let endToken = stream.consumeToken();
		stream.applyTempStore(sharpIfParent);
		sharpIfParent.addChild(endToken);
		throw haxe_Exception.thrown(new tokentree_walk_SharpEndException());
	}
	static walkSharpIfExpr(stream,parent) {
		let childToken;
		let progress = new tokentree_TokenStreamProgress(stream);
		while(progress.streamHasChanged()) {
			let _g = stream.token();
			switch(_g._hx_index) {
			case 1:
				let _g1 = _g.k;
				childToken = stream.consumeToken();
				parent.addChild(childToken);
				if(!stream.hasMore()) {
					return;
				}
				if(stream.token()._hx_index != 11) {
					return;
				}
				let pos = stream.getTokenPos();
				if(pos == null) {
					return;
				}
				if(pos.min == childToken.pos.max + 1) {
					continue;
				}
				let dot = stream.consumeToken();
				childToken.addChild(dot);
				tokentree_walk_WalkSharp.walkSharpIfExpr(stream,dot);
				return;
			case 2:
				let _g2 = _g.c;
				if(_g2._hx_index == 3) {
					let _g = _g2.s;
					childToken = stream.consumeToken();
					parent.addChild(childToken);
					if(!stream.hasMore()) {
						return;
					}
					if(stream.token()._hx_index != 11) {
						return;
					}
					let pos = stream.getTokenPos();
					if(pos == null) {
						return;
					}
					if(pos.min == childToken.pos.max + 1) {
						continue;
					}
					let dot = stream.consumeToken();
					childToken.addChild(dot);
					tokentree_walk_WalkSharp.walkSharpIfExpr(stream,dot);
					return;
				} else {
					return;
				}
				break;
			case 5:
				if(_g.op._hx_index == 2) {
					childToken = stream.consumeToken();
					parent.addChild(childToken);
					tokentree_walk_WalkSharp.walkSharpIfExpr(stream,childToken);
					return;
				} else {
					return;
				}
				break;
			case 20:
				tokentree_walk_WalkPOpen.walkPOpen(stream,parent);
				return;
			default:
				return;
			}
		}
	}
}
tokentree_walk_WalkSharp.__name__ = true;
class tokentree_walk_SharpElseException {
	constructor(token) {
		this.token = token;
	}
}
tokentree_walk_SharpElseException.__name__ = true;
class tokentree_walk_SharpEndException {
	constructor() {
	}
}
tokentree_walk_SharpEndException.__name__ = true;
class tokentree_walk_WalkStatement {
	static walkStatement(stream,parent) {
		tokentree_walk_WalkStatement.walkStatementWithoutSemicolon(stream,parent);
		if(stream.tokenForMatch()._hx_index == 10) {
			let semicolon = stream.consumeToken();
			let lastChild;
			let _g = parent.tok;
			if(_g._hx_index == 6) {
				switch(_g.op._hx_index) {
				case 0:case 3:case 14:case 15:
					lastChild = parent.parent.getLastChild();
					break;
				default:
					lastChild = parent.getLastChild();
				}
			} else {
				lastChild = parent.getLastChild();
			}
			if(lastChild == null) {
				lastChild = parent;
			}
			switch(lastChild.tok._hx_index) {
			case 17:case 19:case 21:
				lastChild = parent;
				break;
			default:
			}
			lastChild.addChild(semicolon);
		}
	}
	static walkStatementWithoutSemicolon(stream,parent) {
		tokentree_walk_WalkComment.walkComment(stream,parent);
		let wantMore = true;
		tokentree_walk_WalkAt.walkAts(stream);
		let _g = stream.token();
		switch(_g._hx_index) {
		case 1:
			let _g1 = _g.k;
			if(tokentree_walk_WalkStatement.walkKeyword(stream,parent)) {
				wantMore = true;
			} else {
				return;
			}
			break;
		case 2:
			let _g2 = _g.c;
			if(_g2._hx_index == 3) {
				switch(_g2.s) {
				case "final":
					if(tokentree_walk_WalkStatement.walkKeyword(stream,parent)) {
						wantMore = true;
					} else {
						return;
					}
					break;
				case "is":
					wantMore = true;
					break;
				default:
					wantMore = false;
				}
			} else {
				wantMore = false;
			}
			break;
		case 3:
			let _g3 = _g.s;
			tokentree_walk_WalkSharp.walkSharp(stream,parent,tokentree_walk_WalkStatement.walkStatement);
			tokentree_walk_WalkStatement.walkStatementContinueAfterSharp(stream,parent);
			return;
		case 4:
			let name = _g.s;
			tokentree_walk_WalkStatement.walkDollarStatement(stream,parent);
			return;
		case 5:
			let _g4 = _g.op;
			if(parent.isCIdentOrCString()) {
				let newChild = stream.consumeToken();
				parent.addChild(newChild);
				if(!stream.hasMore()) {
					return;
				}
				let _g = stream.token();
				switch(_g._hx_index) {
				case 2:
					let _g1 = _g.c;
					if(_g1._hx_index == 3) {
						if(_g1.s == "is") {
							tokentree_walk_WalkStatement.walkStatementWithoutSemicolon(stream,newChild);
						}
					}
					break;
				case 6:
					let _g2 = _g.op;
					tokentree_walk_WalkStatement.walkStatementWithoutSemicolon(stream,newChild);
					break;
				case 11:
					tokentree_walk_WalkStatement.walkStatementWithoutSemicolon(stream,newChild);
					break;
				default:
				}
				return;
			}
			break;
		case 6:
			switch(_g.op._hx_index) {
			case 3:
				tokentree_walk_WalkBinopSub.walkBinopSub(stream,parent);
				return;
			case 7:
				let gtTok = stream.consumeOpGt();
				parent.addChild(gtTok);
				tokentree_walk_WalkStatement.walkStatementWithoutSemicolon(stream,gtTok);
				return;
			case 9:
				if(stream.isTypedParam()) {
					tokentree_walk_WalkLtGt.walkLtGt(stream,parent);
					if(stream.tokenForMatch()._hx_index == 14) {
						tokentree_walk_WalkStatement.walkStatementWithoutSemicolon(stream,parent);
					}
					if(stream.tokenForMatch()._hx_index == 20) {
						tokentree_walk_WalkStatement.walkStatementWithoutSemicolon(stream,parent);
					}
					return;
				}
				wantMore = true;
				break;
			case 12:
				if(parent.parent != null && parent.parent.tok != tokentree_TokenTreeDef.Root) {
					let _g = parent.parent.tok;
					if(_g._hx_index == 1) {
						if(_g.k._hx_index == 15) {
							let orTok = stream.consumeToken();
							parent.addChild(orTok);
							tokentree_walk_WalkStatement.walkStatementWithoutSemicolon(stream,parent.parent);
							return;
						}
					}
				}
				wantMore = true;
				break;
			default:
				wantMore = true;
			}
			break;
		case 9:
			let _g5 = _g.s;
			wantMore = true;
			break;
		case 10:
			return;
		case 12:
			let _g6 = parent.tok;
			switch(_g6._hx_index) {
			case 1:
				if(_g6.k._hx_index == 41) {
					tokentree_walk_WalkStatement.walkDblDot(stream,parent);
					return;
				}
				break;
			case 11:
				return;
			default:
			}
			if(parent.tok._hx_index == 11) {
				return;
			}
			if(tokentree_walk_WalkQuestion.isTernary(stream,parent)) {
				tokentree_walk_WalkStatement.walkStatementContinue(stream,parent);
				return;
			}
			wantMore = true;
			break;
		case 11:case 13:
			wantMore = true;
			break;
		case 14:
			wantMore = true;
			break;
		case 15:
			return;
		case 16:
			tokentree_walk_WalkArrayAccess.walkArrayAccess(stream,parent);
			tokentree_walk_WalkStatement.walkStatementContinue(stream,parent);
			return;
		case 17:case 19:case 21:
			return;
		case 18:
			tokentree_walk_WalkBlock.walkBlock(stream,parent);
			return;
		case 20:
			tokentree_walk_WalkStatement.walkPOpen(stream,parent);
			return;
		case 22:
			tokentree_walk_WalkQuestion.walkQuestion(stream,parent);
			return;
		case 25:
			wantMore = true;
			break;
		default:
			wantMore = false;
		}
		let newChild = stream.consumeToken();
		parent.addChild(newChild);
		stream.applyTempStore(newChild);
		tokentree_walk_WalkStatement.walkTrailingComment(stream,newChild);
		if(wantMore) {
			tokentree_walk_WalkStatement.walkStatementWithoutSemicolon(stream,newChild);
		}
		tokentree_walk_WalkStatement.walkStatementContinue(stream,newChild);
		tokentree_walk_WalkStatement.walkTrailingComment(stream,newChild);
	}
	static walkTrailingComment(stream,parent) {
		if(!stream.hasMore()) {
			return;
		}
		let _g = stream.token();
		if(_g._hx_index == 8) {
			let _g1 = _g.s;
			let currentPos = stream.getStreamIndex();
			let commentTok = stream.consumeToken();
			let _g2 = stream.tokenForMatch();
			if(!(_g2._hx_index == 1 && _g2.k._hx_index == 4)) {
				stream.rewindTo(currentPos);
				return;
			}
			parent.addChild(commentTok);
		}
	}
	static walkStatementContinue(stream,parent) {
		if(!stream.hasMore()) {
			return;
		}
		let _g = stream.token();
		switch(_g._hx_index) {
		case 2:
			let _g1 = _g.c;
			if(_g1._hx_index == 3) {
				if(_g1.s == "is") {
					tokentree_walk_WalkStatement.walkStatementWithoutSemicolon(stream,parent);
				}
			}
			break;
		case 5:
			let _g2 = _g.op;
			if(parent.isCIdentOrCString()) {
				tokentree_walk_WalkStatement.walkStatementWithoutSemicolon(stream,parent);
			}
			break;
		case 6:
			switch(_g.op._hx_index) {
			case 0:case 3:
				tokentree_walk_WalkStatement.walkOpAdd(stream,parent);
				break;
			case 7:
				let ltParent = parent;
				_hx_loop1: while(true) {
					let _g = ltParent.tok;
					switch(_g._hx_index) {
					case 0:
						break _hx_loop1;
					case 2:
						let _g1 = _g.c;
						ltParent = ltParent.parent;
						break;
					case 4:
						let _g2 = _g.s;
						ltParent = ltParent.parent;
						break;
					case 6:
						switch(_g.op._hx_index) {
						case 7:
							ltParent = ltParent.parent;
							break;
						case 9:
							return;
						default:
							break _hx_loop1;
						}
						break;
					case 11:case 12:case 14:case 15:case 16:case 18:case 20:
						ltParent = ltParent.parent;
						break;
					default:
						break _hx_loop1;
					}
				}
				tokentree_walk_WalkStatement.walkStatementWithoutSemicolon(stream,parent);
				break;
			case 14:case 15:
				tokentree_walk_WalkStatement.walkOpBool(stream,parent);
				break;
			default:
				tokentree_walk_WalkStatement.walkStatementWithoutSemicolon(stream,parent);
			}
			break;
		case 7:
			let _g3 = _g.s;
			let nextTokDef = stream.peekNonCommentToken();
			if(nextTokDef == null) {
				return;
			}
			if(nextTokDef != null) {
				switch(nextTokDef._hx_index) {
				case 5:
					let _g4 = nextTokDef.op;
					tokentree_walk_WalkComment.walkComment(stream,parent);
					tokentree_walk_WalkStatement.walkStatementContinue(stream,parent);
					break;
				case 6:
					let _g5 = nextTokDef.op;
					tokentree_walk_WalkComment.walkComment(stream,parent);
					tokentree_walk_WalkStatement.walkStatementContinue(stream,parent);
					break;
				case 11:case 12:case 22:
					tokentree_walk_WalkComment.walkComment(stream,parent);
					tokentree_walk_WalkStatement.walkStatementContinue(stream,parent);
					break;
				default:
				}
			}
			break;
		case 8:
			let _g6 = _g.s;
			let nextTokDef1 = stream.peekNonCommentToken();
			if(nextTokDef1 == null) {
				return;
			}
			if(nextTokDef1 != null) {
				switch(nextTokDef1._hx_index) {
				case 5:
					let _g7 = nextTokDef1.op;
					tokentree_walk_WalkComment.walkComment(stream,parent);
					tokentree_walk_WalkStatement.walkStatementContinue(stream,parent);
					break;
				case 6:
					let _g8 = nextTokDef1.op;
					tokentree_walk_WalkComment.walkComment(stream,parent);
					tokentree_walk_WalkStatement.walkStatementContinue(stream,parent);
					break;
				case 11:case 12:case 22:
					tokentree_walk_WalkComment.walkComment(stream,parent);
					tokentree_walk_WalkStatement.walkStatementContinue(stream,parent);
					break;
				default:
				}
			}
			break;
		case 10:
			return;
		case 12:
			tokentree_walk_WalkStatement.walkDblDot(stream,parent);
			break;
		case 11:case 13:
			tokentree_walk_WalkStatement.walkStatementWithoutSemicolon(stream,parent);
			break;
		case 14:
			tokentree_walk_WalkStatement.walkStatementWithoutSemicolon(stream,parent);
			break;
		case 16:
			tokentree_walk_WalkStatement.walkStatementWithoutSemicolon(stream,parent);
			break;
		case 20:
			tokentree_walk_WalkStatement.walkStatementWithoutSemicolon(stream,parent);
			break;
		case 22:
			tokentree_walk_WalkQuestion.walkQuestion(stream,parent);
			break;
		case 25:
			tokentree_walk_WalkStatement.walkStatementWithoutSemicolon(stream,parent);
			break;
		default:
		}
	}
	static walkKeyword(stream,parent) {
		let _g = stream.token();
		if(_g._hx_index == 1) {
			switch(_g.k._hx_index) {
			case 0:
				tokentree_walk_WalkFunction.walkFunction(stream,parent);
				break;
			case 1:
				tokentree_walk_WalkClass.walkClass(stream,parent);
				break;
			case 2:
				tokentree_walk_WalkVar.walkVar(stream,parent);
				break;
			case 3:
				tokentree_walk_WalkIf.walkIf(stream,parent);
				break;
			case 5:
				let tmp;
				if(parent.tok._hx_index != 18) {
					let _g = parent.parent.tok;
					tmp = _g._hx_index == 1 && _g.k._hx_index == 6;
				} else {
					tmp = false;
				}
				if(tmp) {
					return false;
				}
				tokentree_walk_WalkWhile.walkWhile(stream,parent);
				break;
			case 6:
				tokentree_walk_WalkDoWhile.walkDoWhile(stream,parent);
				break;
			case 7:
				tokentree_walk_WalkFor.walkFor(stream,parent);
				break;
			case 10:case 41:
				return true;
			case 14:
				tokentree_walk_WalkSwitch.walkSwitch(stream,parent);
				break;
			case 15:
				return false;
			case 16:
				if(parent.tok._hx_index == 18) {
					return false;
				}
				return true;
			case 17:case 18:case 19:
				stream.addToTempStore(stream.consumeToken());
				return false;
			case 20:
				tokentree_walk_WalkTry.walkTry(stream,parent);
				break;
			case 22:
				if(parent.tok._hx_index == 11) {
					let newChild = stream.consumeToken();
					parent.addChild(newChild);
					tokentree_walk_WalkStatement.walkStatementContinue(stream,newChild);
				} else {
					tokentree_walk_WalkNew.walkNew(stream,parent);
				}
				break;
			case 23:
				let newChild = stream.consumeToken();
				parent.addChild(newChild);
				tokentree_walk_WalkStatement.walkStatementContinue(stream,newChild);
				return false;
			case 30:
				let newChild1 = stream.consumeToken();
				parent.addChild(newChild1);
				tokentree_walk_WalkStatement.walkStatementWithoutSemicolon(stream,newChild1);
				return false;
			case 35:
				return tokentree_walk_WalkStatement.walkInline(stream,parent);
			case 37:case 38:case 39:
				let newChild2 = stream.consumeToken();
				parent.addChild(newChild2);
				let _g1 = stream.token();
				switch(_g1._hx_index) {
				case 6:
					switch(_g1.op._hx_index) {
					case 14:case 15:
						tokentree_walk_WalkStatement.walkOpBool(stream,newChild2);
						break;
					default:
						tokentree_walk_WalkStatement.walkStatementWithoutSemicolon(stream,newChild2);
					}
					break;
				case 22:
					tokentree_walk_WalkQuestion.walkQuestion(stream,newChild2);
					break;
				default:
				}
				return false;
			case 42:
				tokentree_walk_WalkFinal.walkFinal(stream,parent);
				break;
			default:
				return true;
			}
		} else {
			return true;
		}
		return false;
	}
	static walkInline(stream,parent) {
		stream.addToTempStore(stream.consumeToken());
		let _g = stream.token();
		switch(_g._hx_index) {
		case 1:
			switch(_g.k._hx_index) {
			case 0:
				tokentree_walk_WalkFunction.walkFunction(stream,parent);
				return false;
			case 22:
				return true;
			default:
				return false;
			}
			break;
		case 2:
			let _g1 = _g.c;
			return true;
		default:
			return false;
		}
	}
	static walkDblDot(stream,parent) {
		let question = tokentree_walk_WalkStatement.findQuestionParent(stream,parent);
		if(question != null) {
			return;
		}
		let dblDotTok = stream.consumeToken();
		parent.addChild(dblDotTok);
		if(parent.isCIdentOrCString() && parent.parent.tok._hx_index == 18) {
			tokentree_walk_WalkStatement.walkStatementWithoutSemicolon(stream,dblDotTok);
			return;
		}
		let _g = stream.tokenForMatch();
		if(_g._hx_index == 1 && _g.k._hx_index == 22) {
			tokentree_walk_WalkNew.walkNew(stream,dblDotTok);
			return;
		}
		if(!tokentree_walk_WalkStatement.walkKeyword(stream,dblDotTok)) {
			return;
		}
		tokentree_walk_WalkTypeNameDef.walkTypeNameDef(stream,dblDotTok);
		let _g1 = stream.tokenForMatch();
		if(_g1._hx_index == 6 && _g1.op._hx_index == 4) {
			tokentree_walk_WalkStatement.walkStatementWithoutSemicolon(stream,parent);
		}
		if(stream.tokenForMatch()._hx_index == 14) {
			tokentree_walk_WalkStatement.walkStatementWithoutSemicolon(stream,parent);
		}
	}
	static walkPOpen(stream,parent) {
		let pOpen = tokentree_walk_WalkPOpen.walkPOpen(stream,parent);
		if(parent.tok == tokentree_TokenTreeDef.Root) {
			return;
		}
		if(parent.isCIdent()) {
			tokentree_walk_WalkStatement.walkStatementContinue(stream,parent);
		} else {
			let _g = parent.tok;
			if(_g._hx_index == 1) {
				switch(_g.k._hx_index) {
				case 3:case 5:case 7:case 14:
					let _g1 = stream.token();
					switch(_g1._hx_index) {
					case 6:
						if(_g1.op._hx_index == 3) {
							return;
						}
						break;
					case 11:
						break;
					default:
						return;
					}
					break;
				default:
				}
			}
			tokentree_walk_WalkStatement.walkStatementContinue(stream,pOpen);
		}
	}
	static findQuestionParent(stream,token) {
		let parent = token;
		while(parent != null && parent.tok != tokentree_TokenTreeDef.Root) {
			let _g = parent.tok;
			switch(_g._hx_index) {
			case 1:
				switch(_g.k._hx_index) {
				case 10:
					return parent;
				case 15:
					return parent;
				case 16:
					return parent;
				case 41:
					if(parent.index + 1 == stream.getStreamIndex()) {
						return null;
					}
					parent = tokentree_walk_WalkStatement.findQuestionParent(stream,parent.parent);
					if(parent == null) {
						return null;
					}
					let _g1 = parent.tok;
					switch(_g1._hx_index) {
					case 1:
						switch(_g1.k._hx_index) {
						case 15:case 16:
							return parent;
						default:
							return null;
						}
						break;
					case 22:
						return parent;
					default:
						return null;
					}
					break;
				default:
				}
				break;
			case 6:
				let _g2 = _g.op;
				return parent;
			case 12:
				let type = tokentree_utils_TokenTreeCheckUtils.determineColonType(parent);
				switch(type._hx_index) {
				case 0:case 5:
					return null;
				case 1:case 2:case 3:case 4:case 6:
					break;
				}
				break;
			case 15:
				return null;
			case 18:
				if(tokentree_TokenTreeAccessHelper.firstOf(parent,tokentree_TokenTreeDef.BrClose) == null) {
					return null;
				}
				break;
			case 20:
				if(tokentree_TokenTreeAccessHelper.firstOf(parent,tokentree_TokenTreeDef.PClose) == null) {
					return null;
				}
				break;
			case 22:
				if(tokentree_walk_WalkQuestion.isTernary(stream,parent)) {
					return parent;
				}
				return null;
			default:
			}
			parent = parent.parent;
		}
		return null;
	}
	static walkStatementContinueAfterSharp(stream,parent) {
		let _g = stream.token();
		if(_g._hx_index == 1) {
			switch(_g.k._hx_index) {
			case 15:case 16:
				let lastChild = parent.getLastChild();
				if(lastChild == null) {
					lastChild = parent;
				}
				tokentree_walk_WalkSwitch.walkSwitchCases(stream,lastChild);
				break;
			default:
			}
		}
	}
	static walkOpBool(stream,token) {
		let parent = token.parent;
		_hx_loop1: while(parent.tok != tokentree_TokenTreeDef.Root) {
			let _g = parent.tok;
			switch(_g._hx_index) {
			case 1:
				switch(_g.k._hx_index) {
				case 0:
					break _hx_loop1;
				case 14:case 15:case 16:
					break _hx_loop1;
				case 3:case 5:case 10:case 24:case 29:
					break _hx_loop1;
				default:
					token = parent;
					parent = parent.parent;
				}
				break;
			case 6:
				let _g1 = _g.op;
				switch(_g1._hx_index) {
				case 4:
					break _hx_loop1;
				case 14:case 15:
					token = parent.parent;
					break _hx_loop1;
				case 20:
					let _g2 = _g1.op;
					break _hx_loop1;
				default:
					token = parent;
					parent = parent.parent;
				}
				break;
			case 12:
				token = parent;
				break _hx_loop1;
			case 20:
				if(token.tok._hx_index == 20) {
					token = parent;
				}
				break _hx_loop1;
			case 14:case 22:
				break _hx_loop1;
			default:
				token = parent;
				parent = parent.parent;
			}
		}
		tokentree_walk_WalkStatement.walkStatementWithoutSemicolon(stream,token);
	}
	static walkOpAdd(stream,token) {
		let parent = token.parent;
		_hx_loop1: while(parent.tok != tokentree_TokenTreeDef.Root) {
			let _g = parent.tok;
			switch(_g._hx_index) {
			case 1:
				switch(_g.k._hx_index) {
				case 0:
					break _hx_loop1;
				case 3:case 5:case 10:case 24:case 29:
					break _hx_loop1;
				default:
					token = parent;
					parent = parent.parent;
				}
				break;
			case 6:
				let _g1 = _g.op;
				switch(_g1._hx_index) {
				case 1:case 2:
					token = parent;
					parent = parent.parent;
					break;
				case 0:case 3:
					token = parent.parent;
					break _hx_loop1;
				case 4:
					break _hx_loop1;
				case 20:
					let _g2 = _g1.op;
					break _hx_loop1;
				default:
					break _hx_loop1;
				}
				break;
			case 9:
				let _g3 = _g.s;
				break _hx_loop1;
			case 12:
				break _hx_loop1;
			case 16:case 18:
				break _hx_loop1;
			case 20:
				let pClose = tokentree_TokenTreeAccessHelper.firstOf(parent,tokentree_TokenTreeDef.PClose);
				if(pClose == null) {
					token = parent;
					break _hx_loop1;
				}
				token = parent;
				parent = parent.parent;
				break;
			case 14:case 22:
				break _hx_loop1;
			default:
				token = parent;
				parent = parent.parent;
			}
		}
		tokentree_walk_WalkStatement.walkStatementWithoutSemicolon(stream,token);
	}
	static walkDollarStatement(stream,parent) {
		let dollarTok = stream.consumeToken();
		parent.addChild(dollarTok);
		let _g = stream.token();
		switch(_g._hx_index) {
		case 2:
			let _g1 = _g.c;
			if(_g1._hx_index == 3) {
				if(_g1.s == "is") {
					tokentree_walk_WalkBlock.walkBlock(stream,dollarTok);
				}
			}
			break;
		case 6:
			let _g2 = _g.op;
			tokentree_walk_WalkBlock.walkBlock(stream,dollarTok);
			break;
		case 11:case 16:case 18:case 20:
			tokentree_walk_WalkBlock.walkBlock(stream,dollarTok);
			break;
		default:
		}
	}
}
tokentree_walk_WalkStatement.__name__ = true;
class tokentree_walk_WalkSwitch {
	static walkSwitch(stream,parent) {
		let switchTok = stream.consumeTokenDef(tokentree_TokenTreeDef.Kwd(haxeparser_Keyword.KwdSwitch));
		parent.addChild(switchTok);
		stream.applyTempStore(switchTok);
		tokentree_walk_WalkComment.walkComment(stream,switchTok);
		tokentree_walk_WalkStatement.walkStatement(stream,switchTok);
		tokentree_walk_WalkComment.walkComment(stream,switchTok);
		let _g = stream.token();
		if(_g._hx_index == 3) {
			let _g1 = _g.s;
			tokentree_walk_WalkSharp.walkSharp(stream,parent,tokentree_walk_WalkSwitch.walkSwitchCases);
		}
		if(stream.tokenForMatch()._hx_index == 18) {
			let brOpen = stream.consumeToken();
			switchTok.addChild(brOpen);
			tokentree_walk_WalkSwitch.walkSwitchCases(stream,brOpen);
			brOpen.addChild(stream.consumeTokenDef(tokentree_TokenTreeDef.BrClose));
		}
	}
	static walkSwitchCases(stream,parent) {
		let progress = new tokentree_TokenStreamProgress(stream);
		_hx_loop1: while(progress.streamHasChanged()) {
			let _g = stream.token();
			switch(_g._hx_index) {
			case 1:
				switch(_g.k._hx_index) {
				case 15:case 16:
					tokentree_walk_WalkSwitch.walkCase(stream,parent);
					break;
				default:
					tokentree_walk_WalkStatement.walkStatement(stream,parent);
				}
				break;
			case 3:
				let _g1 = _g.s;
				tokentree_walk_WalkSharp.walkSharp(stream,parent,tokentree_walk_WalkSwitch.walkSwitchCases);
				break;
			case 7:
				let _g2 = _g.s;
				tokentree_walk_WalkComment.walkComment(stream,parent);
				break;
			case 8:
				let _g3 = _g.s;
				tokentree_walk_WalkComment.walkComment(stream,parent);
				break;
			case 19:
				break _hx_loop1;
			default:
				tokentree_walk_WalkStatement.walkStatement(stream,parent);
			}
		}
	}
	static walkCase(stream,parent) {
		tokentree_walk_WalkComment.walkComment(stream,parent);
		let caseTok = stream.consumeToken();
		parent.addChild(caseTok);
		tokentree_walk_WalkSwitch.walkCaseExpr(stream,caseTok);
		let dblDot = stream.consumeTokenDef(tokentree_TokenTreeDef.DblDot);
		caseTok.addChild(dblDot);
		let progress = new tokentree_TokenStreamProgress(stream);
		while(progress.streamHasChanged()) {
			let _g = stream.token();
			switch(_g._hx_index) {
			case 1:
				switch(_g.k._hx_index) {
				case 15:case 16:
					return;
				default:
					tokentree_walk_WalkStatement.walkStatement(stream,dblDot);
				}
				break;
			case 3:
				let _g1 = _g.s;
				tokentree_walk_WalkSharp.walkSharp(stream,parent,tokentree_walk_WalkSwitch.walkSwitchCases);
				tokentree_walk_WalkSwitch.relocateSharpTree(parent,dblDot);
				break;
			case 7:
				let _g2 = _g.s;
				let _g3 = stream.peekNonCommentToken();
				if(_g3 != null) {
					if(_g3._hx_index == 1) {
						switch(_g3.k._hx_index) {
						case 15:case 16:
							if(stream.getStreamIndex() > dblDot.index + 1) {
								return;
							}
							break;
						default:
						}
					}
				}
				tokentree_walk_WalkComment.walkComment(stream,dblDot);
				break;
			case 8:
				let _g4 = _g.s;
				let _g5 = stream.peekNonCommentToken();
				if(_g5 != null) {
					if(_g5._hx_index == 1) {
						switch(_g5.k._hx_index) {
						case 15:case 16:
							if(stream.getStreamIndex() > dblDot.index + 1) {
								return;
							}
							break;
						default:
						}
					}
				}
				tokentree_walk_WalkComment.walkComment(stream,dblDot);
				break;
			case 18:
				tokentree_walk_WalkBlock.walkBlock(stream,dblDot);
				break;
			case 19:
				return;
			default:
				tokentree_walk_WalkStatement.walkStatement(stream,dblDot);
			}
		}
	}
	static relocateSharpTree(parent,dblDot) {
		let sharp = parent.getLastChild();
		if(sharp.children.length < 2) {
			return;
		}
		let body = sharp.children[1];
		let _g = body.tok;
		if(_g._hx_index == 1 && _g.k._hx_index == 15) {
			return;
		}
		parent.children.pop();
		dblDot.addChild(sharp);
	}
	static walkCaseExpr(stream,parent) {
		let progress = new tokentree_TokenStreamProgress(stream);
		while(progress.streamHasChanged()) {
			let _g = stream.token();
			switch(_g._hx_index) {
			case 1:
				if(_g.k._hx_index == 2) {
					let varTok = stream.consumeToken();
					parent.addChild(varTok);
					tokentree_walk_WalkStatement.walkStatement(stream,varTok);
				} else {
					tokentree_walk_WalkStatement.walkStatement(stream,parent);
				}
				break;
			case 10:case 12:case 17:case 19:case 21:
				return;
			case 15:
				let comma = stream.consumeToken();
				let child = parent.getLastChild();
				if(child == null) {
					child = parent;
				}
				child.addChild(comma);
				break;
			default:
				tokentree_walk_WalkStatement.walkStatement(stream,parent);
			}
		}
	}
}
tokentree_walk_WalkSwitch.__name__ = true;
class tokentree_walk_WalkTry {
	static walkTry(stream,parent) {
		let tryTok = stream.consumeTokenDef(tokentree_TokenTreeDef.Kwd(haxeparser_Keyword.KwdTry));
		parent.addChild(tryTok);
		stream.applyTempStore(tryTok);
		tokentree_walk_WalkBlock.walkBlock(stream,tryTok);
		let currentPos = stream.getStreamIndex();
		let progress = new tokentree_TokenStreamProgress(stream);
		let comments = [];
		while(stream.hasMore() && progress.streamHasChanged()) {
			let _g = stream.token();
			switch(_g._hx_index) {
			case 1:
				if(_g.k._hx_index == 21) {
					let _g = 0;
					while(_g < comments.length) {
						let comment = comments[_g];
						++_g;
						tryTok.addChild(comment);
					}
					comments = [];
					tokentree_walk_WalkTry.walkCatch(stream,tryTok);
					currentPos = stream.getStreamIndex();
				} else {
					stream.rewindTo(currentPos);
					return;
				}
				break;
			case 7:
				let _g1 = _g.s;
				comments.push(stream.consumeToken());
				break;
			case 8:
				let _g2 = _g.s;
				comments.push(stream.consumeToken());
				break;
			default:
				stream.rewindTo(currentPos);
				return;
			}
		}
	}
	static walkCatch(stream,parent) {
		let catchTok = stream.consumeTokenDef(tokentree_TokenTreeDef.Kwd(haxeparser_Keyword.KwdCatch));
		parent.addChild(catchTok);
		tokentree_walk_WalkPOpen.walkPOpen(stream,catchTok);
		tokentree_walk_WalkComment.walkComment(stream,catchTok);
		tokentree_walk_WalkBlock.walkBlock(stream,catchTok);
	}
}
tokentree_walk_WalkTry.__name__ = true;
class tokentree_walk_WalkType {
	static walkType(stream,parent) {
		let _g = stream.token();
		if(_g._hx_index == 1) {
			switch(_g.k._hx_index) {
			case 1:
				tokentree_walk_WalkClass.walkClass(stream,parent);
				break;
			case 26:
				tokentree_walk_WalkEnum.walkEnum(stream,parent);
				break;
			case 28:
				tokentree_walk_WalkInterface.walkInterface(stream,parent);
				break;
			case 32:
				tokentree_walk_WalkTypedef.walkTypedef(stream,parent);
				break;
			case 40:
				tokentree_walk_WalkAbstract.walkAbstract(stream,parent);
				break;
			default:
			}
		}
	}
}
tokentree_walk_WalkType.__name__ = true;
class tokentree_walk_WalkTypeNameDef {
	static walkTypeNameDef(stream,parent) {
		tokentree_walk_WalkComment.walkComment(stream,parent);
		tokentree_walk_WalkAt.walkAts(stream);
		if(stream.tokenForMatch()._hx_index == 22) {
			let questTok = stream.consumeTokenDef(tokentree_TokenTreeDef.Question);
			parent.addChild(questTok);
			parent = questTok;
			tokentree_walk_WalkComment.walkComment(stream,parent);
		}
		let name;
		let bAdd = true;
		let _g = stream.token();
		switch(_g._hx_index) {
		case 1:
			switch(_g.k._hx_index) {
			case 22:case 25:case 41:
				name = stream.consumeToken();
				break;
			default:
				name = stream.consumeToken();
			}
			break;
		case 2:
			let _g1 = _g.c;
			name = stream.consumeConst();
			break;
		case 3:
			let _g2 = _g.s;
			tokentree_walk_WalkSharp.walkSharp(stream,parent,tokentree_walk_WalkStatement.walkStatement);
			if(!stream.hasMore()) {
				return parent.getFirstChild();
			}
			let _g3 = stream.token();
			if(_g3._hx_index == 2) {
				let _g = _g3.c;
				name = stream.consumeConst();
			} else {
				return parent.getFirstChild();
			}
			break;
		case 4:
			let _g4 = _g.s;
			name = stream.consumeToken();
			break;
		case 16:
			tokentree_walk_WalkArrayAccess.walkArrayAccess(stream,parent);
			return parent.getFirstChild();
		case 18:
			tokentree_walk_WalkTypedefBody.walkTypedefBody(stream,parent);
			return parent.getFirstChild();
		case 20:
			name = tokentree_walk_WalkPOpen.walkPOpen(stream,parent);
			if(stream.tokenForMatch()._hx_index == 22) {
				tokentree_walk_WalkQuestion.walkQuestion(stream,name);
			}
			bAdd = false;
			break;
		default:
			name = stream.consumeToken();
		}
		stream.applyTempStore(name);
		if(bAdd) {
			parent.addChild(name);
		}
		tokentree_walk_WalkTypeNameDef.walkTypeNameDefContinue(stream,name);
		return name;
	}
	static walkTypeNameDefContinue(stream,parent) {
		tokentree_walk_WalkTypeNameDef.walkTypeNameDefComment(stream,parent);
		if(stream.tokenForMatch()._hx_index == 11) {
			let dot = stream.consumeToken();
			parent.addChild(dot);
			tokentree_walk_WalkTypeNameDef.walkTypeNameDef(stream,dot);
			return;
		}
		let _g = stream.tokenForMatch();
		if(_g._hx_index == 6 && _g.op._hx_index == 9) {
			tokentree_walk_WalkLtGt.walkLtGt(stream,parent);
		}
		if(stream.tokenForMatch()._hx_index == 14) {
			let arrow = stream.consumeToken();
			parent.addChild(arrow);
			tokentree_walk_WalkTypeNameDef.walkTypeNameDef(stream,arrow);
			return;
		}
		if(stream.tokenForMatch()._hx_index == 16) {
			tokentree_walk_WalkArrayAccess.walkArrayAccess(stream,parent);
		}
		tokentree_walk_WalkTypeNameDef.walkTypeNameDefComment(stream,parent);
	}
	static walkTypeNameDefComment(stream,parent) {
		let currentPos = stream.getStreamIndex();
		let progress = new tokentree_TokenStreamProgress(stream);
		let comments = [];
		while(stream.hasMore() && progress.streamHasChanged()) {
			let _g = stream.token();
			switch(_g._hx_index) {
			case 6:
				let _g1 = _g.op;
				let _g2 = 0;
				while(_g2 < comments.length) {
					let comment = comments[_g2];
					++_g2;
					parent.addChild(comment);
				}
				return;
			case 7:
				let _g3 = _g.s;
				comments.push(stream.consumeToken());
				break;
			case 8:
				let _g4 = _g.s;
				comments.push(stream.consumeToken());
				break;
			case 10:case 11:case 12:case 15:case 16:case 18:case 20:
				let _g5 = 0;
				while(_g5 < comments.length) {
					let comment = comments[_g5];
					++_g5;
					parent.addChild(comment);
				}
				return;
			default:
				stream.rewindTo(currentPos);
				return;
			}
		}
	}
}
tokentree_walk_WalkTypeNameDef.__name__ = true;
class tokentree_walk_WalkTypedef {
	static walkTypedef(stream,parent) {
		let typeTok = stream.consumeToken();
		parent.addChild(typeTok);
		let name = tokentree_walk_WalkTypeNameDef.walkTypeNameDef(stream,typeTok);
		stream.applyTempStore(name);
		let _g = stream.tokenForMatch();
		if(_g._hx_index == 6 && _g.op._hx_index == 4) {
			let assign = stream.consumeTokenDef(tokentree_TokenTreeDef.Binop(haxe_macro_Binop.OpAssign));
			name.addChild(assign);
			name = assign;
		}
		tokentree_walk_WalkTypedefBody.walkTypedefBody(stream,name);
	}
}
tokentree_walk_WalkTypedef.__name__ = true;
class tokentree_walk_WalkTypedefBody {
	static walkTypedefBody(stream,parent) {
		if(stream.tokenForMatch()._hx_index == 18) {
			let openTok = stream.consumeToken();
			parent.addChild(openTok);
			tokentree_walk_WalkTypedefBody.walkTypedefCurlyBody(stream,openTok);
			openTok.addChild(stream.consumeTokenDef(tokentree_TokenTreeDef.BrClose));
		} else {
			tokentree_walk_WalkTypedefBody.walkTypedefAlias(stream,parent);
		}
		let _g = stream.tokenForMatch();
		if(_g._hx_index == 6 && _g.op._hx_index == 11) {
			let and = stream.consumeTokenDef(tokentree_TokenTreeDef.Binop(haxe_macro_Binop.OpAnd));
			parent.getLastChild().addChild(and);
			tokentree_walk_WalkTypedefBody.walkTypedefBody(stream,parent);
		}
		if(stream.tokenForMatch()._hx_index == 14) {
			tokentree_walk_WalkStatement.walkStatement(stream,parent);
		}
	}
	static walkTypedefCurlyBody(stream,openTok) {
		let progress = new tokentree_TokenStreamProgress(stream);
		_hx_loop1: while(progress.streamHasChanged()) {
			let _g = stream.token();
			switch(_g._hx_index) {
			case 1:
				switch(_g.k._hx_index) {
				case 0:
					tokentree_walk_WalkFunction.walkFunction(stream,openTok);
					break;
				case 2:
					tokentree_walk_WalkVar.walkVar(stream,openTok);
					break;
				case 17:case 18:case 19:case 25:case 31:case 33:case 35:case 41:
					stream.consumeToTempStore();
					break;
				case 42:
					tokentree_walk_WalkFinal.walkFinal(stream,openTok);
					break;
				default:
					tokentree_walk_WalkFieldDef.walkFieldDef(stream,openTok);
				}
				break;
			case 3:
				let _g1 = _g.s;
				tokentree_walk_WalkSharp.walkSharp(stream,openTok,tokentree_walk_WalkTypedefBody.walkTypedefCurlyBody);
				break;
			case 6:
				if(_g.op._hx_index == 7) {
					tokentree_walk_WalkTypedefBody.walkStructureExtension(stream,openTok);
				} else {
					tokentree_walk_WalkFieldDef.walkFieldDef(stream,openTok);
				}
				break;
			case 7:
				let _g2 = _g.s;
				if(stream.hasTempStore()) {
					stream.consumeToTempStore();
				} else {
					tokentree_walk_WalkComment.walkComment(stream,openTok);
				}
				break;
			case 8:
				let _g3 = _g.s;
				if(stream.hasTempStore()) {
					stream.consumeToTempStore();
				} else {
					tokentree_walk_WalkComment.walkComment(stream,openTok);
				}
				break;
			case 19:
				break _hx_loop1;
			case 23:
				stream.addToTempStore(tokentree_walk_WalkAt.walkAt(stream));
				break;
			default:
				tokentree_walk_WalkFieldDef.walkFieldDef(stream,openTok);
			}
		}
		let tempStore = stream.getTempStore();
		if(tempStore.length > 0) {
			switch(tokentree_TokenStream.MODE._hx_index) {
			case 0:
				throw haxe_Exception.thrown("invalid token tree structure - found:" + ("" + Std.string(tempStore)));
			case 1:
				stream.applyTempStore(openTok);
				break;
			}
		}
	}
	static walkTypedefAlias(stream,parent) {
		let newParent;
		if(stream.tokenForMatch()._hx_index == 20) {
			newParent = tokentree_walk_WalkPOpen.walkPOpen(stream,parent);
		} else {
			newParent = tokentree_walk_WalkTypeNameDef.walkTypeNameDef(stream,parent);
		}
		if(stream.tokenForMatch()._hx_index == 14) {
			let arrowTok = stream.consumeToken();
			newParent.addChild(arrowTok);
			tokentree_walk_WalkTypedefBody.walkTypedefAlias(stream,arrowTok);
		}
		if(stream.tokenForMatch()._hx_index == 10) {
			newParent.addChild(stream.consumeToken());
		}
	}
	static walkStructureExtension(stream,parent) {
		let gt = stream.consumeTokenDef(tokentree_TokenTreeDef.Binop(haxe_macro_Binop.OpGt));
		parent.addChild(gt);
		let name = tokentree_walk_WalkTypeNameDef.walkTypeNameDef(stream,parent);
		gt.addChild(name);
		if(stream.tokenForMatch()._hx_index == 15) {
			name.addChild(stream.consumeToken());
		}
	}
}
tokentree_walk_WalkTypedefBody.__name__ = true;
class tokentree_walk_WalkVar {
	static walkVar(stream,parent) {
		let name = null;
		let varTok = stream.consumeTokenDef(tokentree_TokenTreeDef.Kwd(haxeparser_Keyword.KwdVar));
		parent.addChild(varTok);
		tokentree_walk_WalkComment.walkComment(stream,parent);
		let progress = new tokentree_TokenStreamProgress(stream);
		while(progress.streamHasChanged()) {
			let _g = stream.tokenForMatch();
			if(_g._hx_index == 1 && _g.k._hx_index == 2) {
				return;
			}
			tokentree_walk_WalkComment.walkComment(stream,parent);
			if(stream.token()._hx_index == 23) {
				tokentree_walk_WalkAt.walkAts(stream);
			}
			tokentree_walk_WalkComment.walkComment(stream,parent);
			let nameParent = varTok;
			if(stream.tokenForMatch()._hx_index == 22) {
				nameParent = stream.consumeToken();
				varTok.addChild(nameParent);
			}
			name = stream.consumeConstIdent();
			nameParent.addChild(name);
			stream.applyTempStore(name);
			tokentree_walk_WalkComment.walkComment(stream,name);
			if(stream.tokenForMatch()._hx_index == 20) {
				tokentree_walk_WalkPOpen.walkPOpen(stream,name);
			}
			if(stream.tokenForMatch()._hx_index == 12) {
				let dblDot = stream.consumeToken();
				name.addChild(dblDot);
				tokentree_walk_WalkTypedefBody.walkTypedefAlias(stream,dblDot);
			}
			let _g1 = stream.tokenForMatch();
			if(_g1._hx_index == 6 && _g1.op._hx_index == 4) {
				tokentree_walk_WalkStatement.walkStatement(stream,name);
			}
			if(stream.tokenForMatch()._hx_index == 15) {
				let comma = stream.consumeToken();
				name.addChild(comma);
				continue;
			}
			break;
		}
		if(stream.tokenForMatch()._hx_index == 10) {
			name.addChild(stream.consumeToken());
		}
	}
}
tokentree_walk_WalkVar.__name__ = true;
class tokentree_walk_WalkWhile {
	static walkWhile(stream,parent) {
		let whileTok = stream.consumeTokenDef(tokentree_TokenTreeDef.Kwd(haxeparser_Keyword.KwdWhile));
		parent.addChild(whileTok);
		stream.applyTempStore(whileTok);
		tokentree_walk_WalkComment.walkComment(stream,whileTok);
		tokentree_walk_WalkStatement.walkStatement(stream,whileTok);
		tokentree_walk_WalkComment.walkComment(stream,whileTok);
		tokentree_walk_WalkBlock.walkBlock(stream,whileTok);
	}
}
tokentree_walk_WalkWhile.__name__ = true;
function $getIterator(o) { if( o instanceof Array ) return new haxe_iterators_ArrayIterator(o); else return o.iterator(); }
function $bind(o,m) { if( m == null ) return null; if( m.__id__ == null ) m.__id__ = $global.$haxeUID++; var f; if( o.hx__closures__ == null ) o.hx__closures__ = {}; else f = o.hx__closures__[m.__id__]; if( f == null ) { f = m.bind(o); o.hx__closures__[m.__id__] = f; } return f; }
$global.$haxeUID |= 0;
if(typeof(performance) != "undefined" ? typeof(performance.now) == "function" : false) {
	HxOverrides.now = performance.now.bind(performance);
}
if( String.fromCodePoint == null ) String.fromCodePoint = function(c) { return c < 0x10000 ? String.fromCharCode(c) : String.fromCharCode((c>>10)+0xD7C0)+String.fromCharCode((c&0x3FF)+0xDC00); }
{
	String.__name__ = true;
	Array.__name__ = true;
	Date.__name__ = "Date";
}
js_Boot.__toStr = ({ }).toString;
hxparse_LexEngine.MAX_CODE = 255;
hxparse_LexEngine.EMPTY = [];
hxparse_LexEngine.ALL_CHARS = [new hxparse__$LexEngine_CharRange(0,255)];
haxeparser_HaxeLexer.keywords = (function($this) {
	var $r;
	let _g = new haxe_ds_StringMap();
	_g.h["function"] = haxeparser_Keyword.KwdFunction;
	_g.h["class"] = haxeparser_Keyword.KwdClass;
	_g.h["var"] = haxeparser_Keyword.KwdVar;
	_g.h["if"] = haxeparser_Keyword.KwdIf;
	_g.h["else"] = haxeparser_Keyword.KwdElse;
	_g.h["while"] = haxeparser_Keyword.KwdWhile;
	_g.h["do"] = haxeparser_Keyword.KwdDo;
	_g.h["for"] = haxeparser_Keyword.KwdFor;
	_g.h["break"] = haxeparser_Keyword.KwdBreak;
	_g.h["continue"] = haxeparser_Keyword.KwdContinue;
	_g.h["return"] = haxeparser_Keyword.KwdReturn;
	_g.h["extends"] = haxeparser_Keyword.KwdExtends;
	_g.h["implements"] = haxeparser_Keyword.KwdImplements;
	_g.h["import"] = haxeparser_Keyword.KwdImport;
	_g.h["switch"] = haxeparser_Keyword.KwdSwitch;
	_g.h["case"] = haxeparser_Keyword.KwdCase;
	_g.h["default"] = haxeparser_Keyword.KwdDefault;
	_g.h["static"] = haxeparser_Keyword.KwdStatic;
	_g.h["public"] = haxeparser_Keyword.KwdPublic;
	_g.h["private"] = haxeparser_Keyword.KwdPrivate;
	_g.h["try"] = haxeparser_Keyword.KwdTry;
	_g.h["catch"] = haxeparser_Keyword.KwdCatch;
	_g.h["new"] = haxeparser_Keyword.KwdNew;
	_g.h["this"] = haxeparser_Keyword.KwdThis;
	_g.h["throw"] = haxeparser_Keyword.KwdThrow;
	_g.h["extern"] = haxeparser_Keyword.KwdExtern;
	_g.h["enum"] = haxeparser_Keyword.KwdEnum;
	_g.h["in"] = haxeparser_Keyword.KwdIn;
	_g.h["interface"] = haxeparser_Keyword.KwdInterface;
	_g.h["untyped"] = haxeparser_Keyword.KwdUntyped;
	_g.h["cast"] = haxeparser_Keyword.KwdCast;
	_g.h["override"] = haxeparser_Keyword.KwdOverride;
	_g.h["typedef"] = haxeparser_Keyword.KwdTypedef;
	_g.h["dynamic"] = haxeparser_Keyword.KwdDynamic;
	_g.h["package"] = haxeparser_Keyword.KwdPackage;
	_g.h["inline"] = haxeparser_Keyword.KwdInline;
	_g.h["using"] = haxeparser_Keyword.KwdUsing;
	_g.h["null"] = haxeparser_Keyword.KwdNull;
	_g.h["true"] = haxeparser_Keyword.KwdTrue;
	_g.h["false"] = haxeparser_Keyword.KwdFalse;
	_g.h["abstract"] = haxeparser_Keyword.KwdAbstract;
	_g.h["macro"] = haxeparser_Keyword.KwdMacro;
	_g.h["final"] = haxeparser_Keyword.KwdFinal;
	_g.h["operator"] = haxeparser_Keyword.KwdOperator;
	_g.h["overload"] = haxeparser_Keyword.KwdOverload;
	$r = _g;
	return $r;
}(this));
haxeparser_HaxeLexer.buf = new StringBuf();
haxeparser_HaxeLexer.ident = "_*[a-z][a-zA-Z0-9_]*|_+|_+[0-9][_a-zA-Z0-9]*";
haxeparser_HaxeLexer.sharp_ident = "[a-z_][a-zA-Z0-9_]*(\\.[a-z_][a-zA-Z0-9_]*)*";
haxeparser_HaxeLexer.idtype = "_*[A-Z][a-zA-Z0-9_]*";
haxeparser_HaxeLexer.integer_digits = "([0-9](_?[0-9])*)+";
haxeparser_HaxeLexer.integer = "([1-9](_?[0-9])*)|0";
haxeparser_HaxeLexer.hex_digits = "([0-9a-fA-F](_?[0-9a-fA-F])*)+";
haxeparser_HaxeLexer.bin_digits = "([01](_?[01])*)+";
haxeparser_HaxeLexer.integer_suffix = "(_?[iu](([1-9](_?[0-9])*)|0)+)?";
haxeparser_HaxeLexer.float_suffix = "(_?f(([1-9](_?[0-9])*)|0)+)?";
haxeparser_HaxeLexer.xml_name = "[$|:A-Z_a-z\\u{x00C0}-\\u{x00D6}\\u{x00D8}-\\u{x00F6}\\u{x00F8}-\\u{x002FF}\\u{x00370}-\\u{x0037D}\\u{x0037F}-\\u{x001FFF}\\u{x00200C}-\\u{x00200D}\\u{x002070}-\\u{x00218F}\\u{x002C00}-\\u{x002FEF}\\u{x003001}-\\u{x00D7FF}\\u{x00F900}-\\u{x00FDCF}\\u{x00FDF0}-\\u{x00FFFD}\\u{x0010000}-\\u{x00EFFFF}][$|:A-Z_a-z\\u{x00C0}-\\u{x00D6}\\u{x00D8}-\\u{x00F6}\\u{x00F8}-\\u{x002FF}\\u{x00370}-\\u{x0037D}\\u{x0037F}-\\u{x001FFF}\\u{x00200C}-\\u{x00200D}\\u{x002070}-\\u{x00218F}\\u{x002C00}-\\u{x002FEF}\\u{x003001}-\\u{x00D7FF}\\u{x00F900}-\\u{x00FDCF}\\u{x00FDF0}-\\u{x00FFFD}\\u{x0010000}-\\u{x00EFFFF}\\-.0-9\\u{x00B7}\\u{x0300}-\\u{x036F}\\u{x203F}-\\u{x2040}]*";
haxeparser_HaxeLexer.tok = hxparse_Lexer.buildRuleset([{ rule : "", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Eof);
}},{ rule : "[\r\n\t ]+", func : function(lexer) {
	return lexer.token(haxeparser_HaxeLexer.tok);
}},{ rule : "((0x)(([0-9a-fA-F](_?[0-9a-fA-F])*)+))((_?[iu](([1-9](_?[0-9])*)|0)+)?)", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_HaxeLexer.splitIntSuffix(lexer.current));
}},{ rule : "((0b)(([01](_?[01])*)+))((_?[iu](([1-9](_?[0-9])*)|0)+)?)", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_HaxeLexer.splitIntSuffix(lexer.current));
}},{ rule : "(([1-9](_?[0-9])*)|0)((_?[iu](([1-9](_?[0-9])*)|0)+)?)", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_HaxeLexer.splitIntSuffix(lexer.current));
}},{ rule : "(([1-9](_?[0-9])*)|0)((_?f(([1-9](_?[0-9])*)|0)+)?)", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_HaxeLexer.splitFloatSuffix(lexer.current));
}},{ rule : "(((([1-9](_?[0-9])*)|0)(\\.))(([0-9](_?[0-9])*)+))((_?f(([1-9](_?[0-9])*)|0)+)?)", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_HaxeLexer.splitFloatSuffix(lexer.current));
}},{ rule : "((\\.)(([0-9](_?[0-9])*)+))((_?f(([1-9](_?[0-9])*)|0)+)?)", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_HaxeLexer.splitFloatSuffix(lexer.current));
}},{ rule : "(((([1-9](_?[0-9])*)|0)([eE][\\+\\-]?))(([0-9](_?[0-9])*)+))((_?f(([1-9](_?[0-9])*)|0)+)?)", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_HaxeLexer.splitFloatSuffix(lexer.current));
}},{ rule : "(((([1-9](_?[0-9])*)|0)(\\.[0-9]*[eE][\\+\\-]?))(([0-9](_?[0-9])*)+))((_?f(([1-9](_?[0-9])*)|0)+)?)", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_HaxeLexer.splitFloatSuffix(lexer.current));
}},{ rule : "(([1-9](_?[0-9])*)|0)(\\.\\.\\.)", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.IntInterval(HxOverrides.substr(lexer.current,0,-3)));
}},{ rule : "//[^\n\r]*", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.CommentLine(HxOverrides.substr(lexer.current,2,null)));
}},{ rule : "+\\+", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Unop(haxe_macro_Unop.OpIncrement));
}},{ rule : "--", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Unop(haxe_macro_Unop.OpDecrement));
}},{ rule : "~", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Unop(haxe_macro_Unop.OpNegBits));
}},{ rule : "%=", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Binop(haxe_macro_Binop.OpAssignOp(haxe_macro_Binop.OpMod)));
}},{ rule : "&=", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Binop(haxe_macro_Binop.OpAssignOp(haxe_macro_Binop.OpAnd)));
}},{ rule : "|=", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Binop(haxe_macro_Binop.OpAssignOp(haxe_macro_Binop.OpOr)));
}},{ rule : "^=", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Binop(haxe_macro_Binop.OpAssignOp(haxe_macro_Binop.OpXor)));
}},{ rule : "+=", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Binop(haxe_macro_Binop.OpAssignOp(haxe_macro_Binop.OpAdd)));
}},{ rule : "-=", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Binop(haxe_macro_Binop.OpAssignOp(haxe_macro_Binop.OpSub)));
}},{ rule : "*=", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Binop(haxe_macro_Binop.OpAssignOp(haxe_macro_Binop.OpMult)));
}},{ rule : "/=", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Binop(haxe_macro_Binop.OpAssignOp(haxe_macro_Binop.OpDiv)));
}},{ rule : "<<=", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Binop(haxe_macro_Binop.OpAssignOp(haxe_macro_Binop.OpShl)));
}},{ rule : "|\\|=", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Binop(haxe_macro_Binop.OpAssignOp(haxe_macro_Binop.OpBoolOr)));
}},{ rule : "&&=", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Binop(haxe_macro_Binop.OpAssignOp(haxe_macro_Binop.OpBoolAnd)));
}},{ rule : "?\\?=", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Binop(haxe_macro_Binop.OpAssignOp(haxe_macro_Binop.OpNullCoal)));
}},{ rule : "==", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Binop(haxe_macro_Binop.OpEq));
}},{ rule : "!=", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Binop(haxe_macro_Binop.OpNotEq));
}},{ rule : "<=", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Binop(haxe_macro_Binop.OpLte));
}},{ rule : "&&", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Binop(haxe_macro_Binop.OpBoolAnd));
}},{ rule : "|\\|", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Binop(haxe_macro_Binop.OpBoolOr));
}},{ rule : "<<", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Binop(haxe_macro_Binop.OpShl));
}},{ rule : "->", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Arrow);
}},{ rule : "\\.\\.\\.", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Spread);
}},{ rule : "=>", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Binop(haxe_macro_Binop.OpArrow));
}},{ rule : "!", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Unop(haxe_macro_Unop.OpNot));
}},{ rule : "(<)([$|:A-Z_a-z\\u{x00C0}-\\u{x00D6}\\u{x00D8}-\\u{x00F6}\\u{x00F8}-\\u{x002FF}\\u{x00370}-\\u{x0037D}\\u{x0037F}-\\u{x001FFF}\\u{x00200C}-\\u{x00200D}\\u{x002070}-\\u{x00218F}\\u{x002C00}-\\u{x002FEF}\\u{x003001}-\\u{x00D7FF}\\u{x00F900}-\\u{x00FDCF}\\u{x00FDF0}-\\u{x00FFFD}\\u{x0010000}-\\u{x00EFFFF}][$|:A-Z_a-z\\u{x00C0}-\\u{x00D6}\\u{x00D8}-\\u{x00F6}\\u{x00F8}-\\u{x002FF}\\u{x00370}-\\u{x0037D}\\u{x0037F}-\\u{x001FFF}\\u{x00200C}-\\u{x00200D}\\u{x002070}-\\u{x00218F}\\u{x002C00}-\\u{x002FEF}\\u{x003001}-\\u{x00D7FF}\\u{x00F900}-\\u{x00FDCF}\\u{x00FDF0}-\\u{x00FFFD}\\u{x0010000}-\\u{x00EFFFF}\\-.0-9\\u{x00B7}\\u{x0300}-\\u{x036F}\\u{x203F}-\\u{x2040}]*)", func : function(lexer) {
	return haxeparser_HaxeLexer.inlineMarkup(lexer);
}},{ rule : "<", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Binop(haxe_macro_Binop.OpLt));
}},{ rule : ">", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Binop(haxe_macro_Binop.OpGt));
}},{ rule : ";", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Semicolon);
}},{ rule : ":", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.DblDot);
}},{ rule : ",", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Comma);
}},{ rule : "?\\.", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.QuestionDot);
}},{ rule : "\\.", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Dot);
}},{ rule : "%", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Binop(haxe_macro_Binop.OpMod));
}},{ rule : "&", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Binop(haxe_macro_Binop.OpAnd));
}},{ rule : "|", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Binop(haxe_macro_Binop.OpOr));
}},{ rule : "^", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Binop(haxe_macro_Binop.OpXor));
}},{ rule : "+", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Binop(haxe_macro_Binop.OpAdd));
}},{ rule : "*", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Binop(haxe_macro_Binop.OpMult));
}},{ rule : "/", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Binop(haxe_macro_Binop.OpDiv));
}},{ rule : "-", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Binop(haxe_macro_Binop.OpSub));
}},{ rule : "=", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Binop(haxe_macro_Binop.OpAssign));
}},{ rule : "[", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.BkOpen);
}},{ rule : "]", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.BkClose);
}},{ rule : "{", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.BrOpen);
}},{ rule : "}", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.BrClose);
}},{ rule : "\\(", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.POpen);
}},{ rule : "\\)", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.PClose);
}},{ rule : "?\\?", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Binop(haxe_macro_Binop.OpNullCoal));
}},{ rule : "?", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Question);
}},{ rule : "@", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.At);
}},{ rule : "\"", func : function(lexer) {
	haxeparser_HaxeLexer.buf = new StringBuf();
	let pmin = new hxparse_Position(lexer.source,lexer.pos - lexer.current.length,lexer.pos);
	let pmax;
	try {
		pmax = lexer.token(haxeparser_HaxeLexer.string);
	} catch( _g ) {
		if(((haxe_Exception.caught(_g).unwrap()) instanceof haxe_io_Eof)) {
			throw haxe_Exception.thrown(new haxeparser_LexerError(haxeparser_LexerErrorMsg.UnterminatedString,haxeparser_HaxeLexer.mkPos(pmin)));
		} else {
			throw _g;
		}
	}
	let token = haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Const(haxeparser_Constant.CString(haxeparser_HaxeLexer.unescape(haxeparser_HaxeLexer.buf.b,haxeparser_HaxeLexer.mkPos(pmin)),haxe_macro_StringLiteralKind.DoubleQuotes)));
	token.pos.min = pmin.pmin;
	return token;
}},{ rule : "'", func : function(lexer) {
	haxeparser_HaxeLexer.buf = new StringBuf();
	let pmin = new hxparse_Position(lexer.source,lexer.pos - lexer.current.length,lexer.pos);
	let pmax;
	try {
		pmax = lexer.token(haxeparser_HaxeLexer.string2);
	} catch( _g ) {
		if(((haxe_Exception.caught(_g).unwrap()) instanceof haxe_io_Eof)) {
			throw haxe_Exception.thrown(new haxeparser_LexerError(haxeparser_LexerErrorMsg.UnterminatedString,haxeparser_HaxeLexer.mkPos(pmin)));
		} else {
			throw _g;
		}
	}
	let token = haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Const(haxeparser_Constant.CString(haxeparser_HaxeLexer.unescape(haxeparser_HaxeLexer.buf.b,haxeparser_HaxeLexer.mkPos(pmin)),haxe_macro_StringLiteralKind.SingleQuotes)));
	token.pos.min = pmin.pmin;
	return token;
}},{ rule : "~/", func : function(lexer) {
	haxeparser_HaxeLexer.buf = new StringBuf();
	let pmin = new hxparse_Position(lexer.source,lexer.pos - lexer.current.length,lexer.pos);
	let info;
	try {
		info = lexer.token(haxeparser_HaxeLexer.regexp);
	} catch( _g ) {
		if(((haxe_Exception.caught(_g).unwrap()) instanceof haxe_io_Eof)) {
			throw haxe_Exception.thrown(new haxeparser_LexerError(haxeparser_LexerErrorMsg.UnterminatedRegExp,haxeparser_HaxeLexer.mkPos(pmin)));
		} else {
			throw _g;
		}
	}
	let token = haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Const(haxeparser_Constant.CRegexp(haxeparser_HaxeLexer.buf.b,info.opt)));
	token.pos.min = pmin.pmin;
	return token;
}},{ rule : "/\\*", func : function(lexer) {
	haxeparser_HaxeLexer.buf = new StringBuf();
	let pmin = new hxparse_Position(lexer.source,lexer.pos - lexer.current.length,lexer.pos);
	let pmax;
	try {
		pmax = lexer.token(haxeparser_HaxeLexer.comment);
	} catch( _g ) {
		if(((haxe_Exception.caught(_g).unwrap()) instanceof haxe_io_Eof)) {
			throw haxe_Exception.thrown(new haxeparser_LexerError(haxeparser_LexerErrorMsg.UnclosedComment,haxeparser_HaxeLexer.mkPos(pmin)));
		} else {
			throw _g;
		}
	}
	let token = haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Comment(haxeparser_HaxeLexer.buf.b));
	token.pos.min = pmin.pmin;
	return token;
}},{ rule : "(#)(_*[a-z][a-zA-Z0-9_]*|_+|_+[0-9][_a-zA-Z0-9]*)", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Sharp(HxOverrides.substr(lexer.current,1,null)));
}},{ rule : "$[_a-zA-Z0-9]*", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Dollar(HxOverrides.substr(lexer.current,1,null)));
}},{ rule : "_*[a-z][a-zA-Z0-9_]*|_+|_+[0-9][_a-zA-Z0-9]*", func : function(lexer) {
	let kwd = haxeparser_HaxeLexer.keywords.h[lexer.current];
	if(kwd != null) {
		return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Kwd(kwd));
	} else {
		return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Const(haxeparser_Constant.CIdent(lexer.current)));
	}
}},{ rule : "_*[A-Z][a-zA-Z0-9_]*", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Const(haxeparser_Constant.CIdent(lexer.current)));
}}],"tok");
haxeparser_HaxeLexer.string = hxparse_Lexer.buildRuleset([{ rule : "\\\\\\\\", func : function(lexer) {
	haxeparser_HaxeLexer.buf.b += "\\\\";
	return lexer.token(haxeparser_HaxeLexer.string);
}},{ rule : "\\\\", func : function(lexer) {
	haxeparser_HaxeLexer.buf.b += "\\";
	return lexer.token(haxeparser_HaxeLexer.string);
}},{ rule : "\\\\\"", func : function(lexer) {
	haxeparser_HaxeLexer.buf.b += "\"";
	return lexer.token(haxeparser_HaxeLexer.string);
}},{ rule : "\"", func : function(lexer) {
	return new hxparse_Position(lexer.source,lexer.pos - lexer.current.length,lexer.pos).pmax;
}},{ rule : "[^\\\\\"]+", func : function(lexer) {
	haxeparser_HaxeLexer.buf.b += Std.string(lexer.current);
	return lexer.token(haxeparser_HaxeLexer.string);
}}],"string");
haxeparser_HaxeLexer.string2 = hxparse_Lexer.buildRuleset([{ rule : "\\\\\\\\", func : function(lexer) {
	haxeparser_HaxeLexer.buf.b += "\\\\";
	return lexer.token(haxeparser_HaxeLexer.string2);
}},{ rule : "\\\\", func : function(lexer) {
	haxeparser_HaxeLexer.buf.b += "\\";
	return lexer.token(haxeparser_HaxeLexer.string2);
}},{ rule : "\\\\'", func : function(lexer) {
	haxeparser_HaxeLexer.buf.b += "'";
	return lexer.token(haxeparser_HaxeLexer.string2);
}},{ rule : "'", func : function(lexer) {
	return new hxparse_Position(lexer.source,lexer.pos - lexer.current.length,lexer.pos).pmax;
}},{ rule : "($$)|(\\$)|$", func : function(lexer) {
	haxeparser_HaxeLexer.buf.b += "$";
	return lexer.token(haxeparser_HaxeLexer.string2);
}},{ rule : "${", func : function(lexer) {
	let pmin = new hxparse_Position(lexer.source,lexer.pos - lexer.current.length,lexer.pos);
	haxeparser_HaxeLexer.buf.b += Std.string(lexer.current);
	try {
		lexer.token(haxeparser_HaxeLexer.codeString);
	} catch( _g ) {
		if(((haxe_Exception.caught(_g).unwrap()) instanceof haxe_io_Eof)) {
			throw haxe_Exception.thrown(new haxeparser_LexerError(haxeparser_LexerErrorMsg.UnclosedCode,haxeparser_HaxeLexer.mkPos(pmin)));
		} else {
			throw _g;
		}
	}
	return lexer.token(haxeparser_HaxeLexer.string2);
}},{ rule : "[^$\\\\']+", func : function(lexer) {
	haxeparser_HaxeLexer.buf.b += Std.string(lexer.current);
	return lexer.token(haxeparser_HaxeLexer.string2);
}}],"string2");
haxeparser_HaxeLexer.codeString = hxparse_Lexer.buildRuleset([{ rule : "{|/", func : function(lexer) {
	haxeparser_HaxeLexer.buf.b += Std.string(lexer.current);
	lexer.token(haxeparser_HaxeLexer.codeString);
}},{ rule : "}", func : function(lexer) {
	haxeparser_HaxeLexer.buf.b += Std.string(lexer.current);
}},{ rule : "\"", func : function(lexer) {
	haxeparser_HaxeLexer.buf.b += String.fromCodePoint(34);
	let pmin = new hxparse_Position(lexer.source,lexer.pos - lexer.current.length,lexer.pos);
	try {
		lexer.token(haxeparser_HaxeLexer.string);
	} catch( _g ) {
		if(((haxe_Exception.caught(_g).unwrap()) instanceof haxe_io_Eof)) {
			throw haxe_Exception.thrown(new haxeparser_LexerError(haxeparser_LexerErrorMsg.UnterminatedString,haxeparser_HaxeLexer.mkPos(pmin)));
		} else {
			throw _g;
		}
	}
	haxeparser_HaxeLexer.buf.b += String.fromCodePoint(34);
	lexer.token(haxeparser_HaxeLexer.codeString);
}},{ rule : "'", func : function(lexer) {
	haxeparser_HaxeLexer.buf.b += String.fromCodePoint(39);
	let pmin = new hxparse_Position(lexer.source,lexer.pos - lexer.current.length,lexer.pos);
	try {
		lexer.token(haxeparser_HaxeLexer.string2);
	} catch( _g ) {
		if(((haxe_Exception.caught(_g).unwrap()) instanceof haxe_io_Eof)) {
			throw haxe_Exception.thrown(new haxeparser_LexerError(haxeparser_LexerErrorMsg.UnterminatedString,haxeparser_HaxeLexer.mkPos(pmin)));
		} else {
			throw _g;
		}
	}
	haxeparser_HaxeLexer.buf.b += String.fromCodePoint(39);
	lexer.token(haxeparser_HaxeLexer.codeString);
}},{ rule : "/\\*", func : function(lexer) {
	let pmin = new hxparse_Position(lexer.source,lexer.pos - lexer.current.length,lexer.pos);
	try {
		lexer.token(haxeparser_HaxeLexer.comment);
	} catch( _g ) {
		if(((haxe_Exception.caught(_g).unwrap()) instanceof haxe_io_Eof)) {
			throw haxe_Exception.thrown(new haxeparser_LexerError(haxeparser_LexerErrorMsg.UnclosedComment,haxeparser_HaxeLexer.mkPos(pmin)));
		} else {
			throw _g;
		}
	}
	lexer.token(haxeparser_HaxeLexer.codeString);
}},{ rule : "//[^\n\r]*", func : function(lexer) {
	haxeparser_HaxeLexer.buf.b += Std.string(lexer.current);
	lexer.token(haxeparser_HaxeLexer.codeString);
}},{ rule : "[^/\"'{}\n\r]+", func : function(lexer) {
	haxeparser_HaxeLexer.buf.b += Std.string(lexer.current);
	lexer.token(haxeparser_HaxeLexer.codeString);
}},{ rule : "[\r\n\t ]+", func : function(lexer) {
	haxeparser_HaxeLexer.buf.b += Std.string(lexer.current);
	lexer.token(haxeparser_HaxeLexer.codeString);
}}],"codeString");
haxeparser_HaxeLexer.comment = hxparse_Lexer.buildRuleset([{ rule : "*/", func : function(lexer) {
	return new hxparse_Position(lexer.source,lexer.pos - lexer.current.length,lexer.pos).pmax;
}},{ rule : "*", func : function(lexer) {
	haxeparser_HaxeLexer.buf.b += "*";
	return lexer.token(haxeparser_HaxeLexer.comment);
}},{ rule : "[^\\*]+", func : function(lexer) {
	haxeparser_HaxeLexer.buf.b += Std.string(lexer.current);
	return lexer.token(haxeparser_HaxeLexer.comment);
}}],"comment");
haxeparser_HaxeLexer.regexp = hxparse_Lexer.buildRuleset([{ rule : "\\\\/", func : function(lexer) {
	haxeparser_HaxeLexer.buf.b += "/";
	return lexer.token(haxeparser_HaxeLexer.regexp);
}},{ rule : "\\\\r", func : function(lexer) {
	haxeparser_HaxeLexer.buf.b += "\r";
	return lexer.token(haxeparser_HaxeLexer.regexp);
}},{ rule : "\\\\n", func : function(lexer) {
	haxeparser_HaxeLexer.buf.b += "\n";
	return lexer.token(haxeparser_HaxeLexer.regexp);
}},{ rule : "\\\\t", func : function(lexer) {
	haxeparser_HaxeLexer.buf.b += "\t";
	return lexer.token(haxeparser_HaxeLexer.regexp);
}},{ rule : "\\\\[\\\\$\\.*+\\^|{}\\[\\]()?\\-0-9]", func : function(lexer) {
	haxeparser_HaxeLexer.buf.b += Std.string(lexer.current);
	return lexer.token(haxeparser_HaxeLexer.regexp);
}},{ rule : "\\\\[wWbBsSdDx]", func : function(lexer) {
	haxeparser_HaxeLexer.buf.b += Std.string(lexer.current);
	return lexer.token(haxeparser_HaxeLexer.regexp);
}},{ rule : "\\\\[uU][0-9a-fA-F][0-9a-fA-F][0-9a-fA-F][0-9a-fA-F]", func : function(lexer) {
	haxeparser_HaxeLexer.buf.b += Std.string(lexer.current);
	return lexer.token(haxeparser_HaxeLexer.regexp);
}},{ rule : "\\[^\\]", func : function(lexer) {
	let pmin = new hxparse_Position(lexer.source,lexer.pos - lexer.current.length,lexer.pos);
	throw haxe_Exception.thrown(new haxeparser_LexerError(haxeparser_LexerErrorMsg.UnterminatedRegExp,haxeparser_HaxeLexer.mkPos(pmin)));
}},{ rule : "/", func : function(lexer) {
	return lexer.token(haxeparser_HaxeLexer.regexp_options);
}},{ rule : "[^\\\\/\r\n]+", func : function(lexer) {
	haxeparser_HaxeLexer.buf.b += Std.string(lexer.current);
	return lexer.token(haxeparser_HaxeLexer.regexp);
}}],"regexp");
haxeparser_HaxeLexer.regexp_options = hxparse_Lexer.buildRuleset([{ rule : "[gimsu]*", func : function(lexer) {
	return { pmax : new hxparse_Position(lexer.source,lexer.pos - lexer.current.length,lexer.pos).pmax, opt : lexer.current};
}}],"regexp_options");
haxeparser_HaxeLexer.sharp_token = hxparse_Lexer.buildRuleset([{ rule : "[a-z_][a-zA-Z0-9_]*(\\.[a-z_][a-zA-Z0-9_]*)*", func : function(lexer) {
	return haxeparser_HaxeLexer.mk(lexer,haxeparser_TokenDef.Const(haxeparser_Constant.CIdent(lexer.current)));
}},{ rule : "[\r\n\t ]+", func : function(lexer) {
	return lexer.token(haxeparser_HaxeLexer.sharp_token);
}},{ rule : "/\\*", func : function(lexer) {
	let pmin = new hxparse_Position(lexer.source,lexer.pos - lexer.current.length,lexer.pos);
	try {
		lexer.token(haxeparser_HaxeLexer.comment);
	} catch( _g ) {
		if(((haxe_Exception.caught(_g).unwrap()) instanceof haxe_io_Eof)) {
			throw haxe_Exception.thrown(new haxeparser_LexerError(haxeparser_LexerErrorMsg.UnclosedComment,haxeparser_HaxeLexer.mkPos(pmin)));
		} else {
			throw _g;
		}
	}
	return lexer.token(haxeparser_HaxeLexer.sharp_token);
}},{ rule : "[.]*", func : function(lexer) {
	return lexer.token(haxeparser_HaxeLexer.tok);
}}],"sharp_token");
haxeparser_HaxeLexer.generatedRulesets = [haxeparser_HaxeLexer.tok,haxeparser_HaxeLexer.string,haxeparser_HaxeLexer.string2,haxeparser_HaxeLexer.codeString,haxeparser_HaxeLexer.comment,haxeparser_HaxeLexer.regexp,haxeparser_HaxeLexer.regexp_options,haxeparser_HaxeLexer.sharp_token];
tokentree_TokenStream.NO_MORE_TOKENS = "no more tokens";
tokentree_TokenStream.MODE = tokentree_TokenStreamMode.Strict;
tokentree_TokenTree.MAX_LEVEL = 9999;
refactor_Cli.main();
})(typeof window != "undefined" ? window : typeof global != "undefined" ? global : typeof self != "undefined" ? self : this);
